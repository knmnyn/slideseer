
Para 1 Page 1
Approximate XML Query Answers

Para 2 Page 1
Neoklis Polyzotis
Minos Garofalakis
Yannis Ioannidis

Para 3 Page 1
University of California, Santa Cruz
Bell Labs, Lucent Technologies
University of Athens, Hellas

Para 4 Page 1
alkis@cs.ucsc.edu
minos@research.bell-labs.com
yannis@di.uoa.gr

Para 5 Page 1
ABSTRACT

Para 6 Page 1
The rapid adoption of XML as the standard for data representation and exchange foreshadows a massive increase in the amounts of XML data collected, maintained, and queried over the Internet or in large corporate datastores. Inevitably, this will result in the development of on-line decision
support systems, where users and analysts interactively explore large XML
data sets through a declarative query interface (e.g., XQuery or XSLT).
Given the importance of remaining interactive, such on-line systems can
employ approximate query answers as an effective mechanism for reducing response time and providing users with early feedback. This approach
has been successfully used in relational systems and it becomes even more
compelling in the XML world, where the evaluation of complex queries
over massive tree-structured data is inherently more expensive.

Para 7 Page 1
In this paper, we initiate a study of approximate query answering techniques for large XML databases. Our approach is based on a novel, conceptually simple, yet very effective XML-summarization mechanism:
T
REE
S
KETCH
synopses. We demonstrate that, unlike earlier techniques
focusing solely on selectivity estimation, our T
REE
S
KETCH
synopses are
much more effective in capturing the complete tree structure of the underlying XML database. We propose novel construction algorithms for building
T
REE
S
KETCH
summaries of limited size, and describe schemes for processing general XML twig queries over a concise T
REE
S
KETCH
in order to
produce very fast, approximate tree-structured query answers. To quantify
the quality of such approximate answers, we propose a novel, intuitive error
metric that captures the quality of the approximation in terms of both the
overall structure of the XML tree and the distribution of document edges.
Experimental results on real-life and synthetic data sets verify the effectiveness of our T
REE
S
KETCH
synopses in producing fast, accurate approximate
answers and demonstrate their benefits over previously proposed techniques
that focus solely on selectivity estimation. In particular, T
REE
S
KETCH
es
yield faster, more accurate approximate answers and selectivity estimates,
and are more efficient to construct. To the best of our knowledge, ours is
the first work to address the timely problem of producing fast, approximate
tree-structured answers for complex XML queries.

Para 8 Page 1
1. INTRODUCTION

Para 9 Page 1
Since its introduction six years ago, XML has evolved from a
mark-up language for web documents to an emerging standard for
data exchange and integration over the Internet. Being self-describing
and hierarchical in nature, the XML data model is suitable for representing a diverse range of data sources and promises to enable
the next-generation of search applications that will allow users to
query effectively the information available on the Web.

Para 10 Page 1
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage, and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
SIGMOD 2004 June 13-18, 2004, Paris, France.
Copyright 2004 ACM 1-58113-859-8/04/06 . . .
$
5.00.

Para 11 Page 1
With the rapid growth of available XML data, one can expect
a proliferation of on-line decision support systems that enable the
interactive exploration of large-scale XML repositories. In a typical exploratory session, a domain expert poses successive queries
in a declarative language, such as XQuery [4] or XSLT [7], and
uses an appropriate visualization of the results in order to detect
interesting patterns in the stored data. Obviously, the successful
deployment of decision-support systems depends crucially on their
ability to provide timely feedback to users' queries. This requirement, however, conflicts with the inherently expensive evaluation
of XML queries which involve complex traversals of the data hierarchy, coupled with non-trivial predicates on the path structure and
the value content.

Para 12 Page 1
Generating approximate answers is a cost-effective solution for
offsetting the high evaluation cost of XML queries. In short, the
system processes the query over a concise synopsis of the XML
data and returns an approximation of the true result. Ideally, this
approximate answer is computed very fast and is accurate in the
sense that it preserves with low error the statistical traits of the true
result. The user can then examine this "preview", assess the information content of the true answer, and decide whether it needs to
be retrieved by executing the query over the base data. Overall, by
providing the user with fast and accurate feedback on the form of
the results, the system can reduce the number of queries that need
to be evaluated in order to support effectively the data exploration
task.

Para 13 Page 1
In a typical scenario, the result of an XML query is an XML
fragment that is constructed by appropriate projections on the original data; an approximate answer, therefore, is an XML document
that resembles the true answer in terms of hierarchical structure
and value content. Clearly, the effectiveness of an approximate
answering system hinges upon the existence of accurate synopsis
structures that capture the key statistical characteristics of the base
XML data and can thus produce low-error approximate answers
to queries that project parts of it. Note that the problem of efficient XML summarization also arises in the context of selectivity
estimation, where the synopsis is only used to estimate the size of
the result. Approximating the structure of the result, however, is
a strictly more complex problem since there are documents where
the same query produces results of equal size but with very different structure. Summarizing, therefore, an XML document in order
to compute approximate answers is more involved than building
synopses for selectivity estimation, which in itself is known to be a
hard problem [18].

Para 14 Page 1
Related Work
1
. Previous studies on approximate query answering [3, 10] have focused on the relational model, where the result

Para 15 Page 1
1
Due to space constraints, a more detailed overview of related work
can be found in the full version of this paper [17]
of a query is typically a multi-set of values. The key idea is to
process a query over an appropriate relational synopsis (such as,
histograms, wavelets, or sample-based summaries) and compute an
approximation of the true value set. The proposed techniques and
summarization methods, however, are suitable for flat relational
data and are not easily extended to the case of general XML hierarchies.

Para 16 Page 2
As noted earlier, approximate XML query answering is closely
tied to the problem of building effective XML synopses. Recent
studies have looked at the related problem of summarizing XML
data for estimating the selectivity of single XPath expressions [1,
12, 15, 16, 21, 22], or the number of binding tuples for
twig queries [6, 9, 18]. Even though a selectivity estimate is essentially an approximate answer to an aggregate query (COUNT), the
proposed summarization techniques do not store detailed enough
information in order to approximate the structure of the query result.

Para 17 Page 2
Buneman et al. [2] have recently introduced a query-able compression scheme for tree-structured XML data. The proposed technique compresses the XML tree by using an appropriate bisimulation relation and evaluates an XPath query directly over the compressed instance. The goal, therefore, is to compute an exact answer to a path query, whereas our focus is on computing an approximate </i>answer to a <i>twig query, which typically involves the joint
evaluation of multiple path expressions.

Para 18 Page 2
Our Contributions. In this paper, we initiate the study of approximate query answering for XML queries. In order to gain intuition on the complexity of the problem, this initial study focuses
on approximate answers for twig queries with branching path expressions, i.e., we consider the structural part of the problem and
ignore for now the value content of the document. As we show in
this paper, even this constrained version is quite complex and requires non-trivial solutions. Our approach is based on a novel type
of structural XML synopses, termed T
REE
S
KETCH
es, that capture,
in limited space, the key properties of the underlying path distribution and enable low-error approximate answers for a large class
of interesting XML queries. We develop a systematic query evaluation framework for generating approximate answers over concise
T
REE
S
KETCH
synopses and describe an efficient construction algorithm for building an accurate T
REE
S
KETCH
summary within
the constraints of a limited space budget. Finally, we present experimental results on real-life and synthetic data sets that demonstrate
the effectiveness of our approach and its benefits over previously
proposed techniques, not only for generating approximate answers,
but also for enabling accurate selectivity estimation. To the best of
our knowledge, ours is the first study to look into the problem of
computing approximate answers for complex XML queries. More
concretely, the key contributions of our work can be summarized
as follows:

Para 19 Page 2
 
T
REE
S
KETCH
Summarization Model and Query Evaluation
Framework. Our T
REE
S
KETCH
summarization model is based
on the novel concept of count-stability which captures very effectively the intrinsic similarity of sub-structures in an XML document. Briefly, a T
REE
S
KETCH
summary represents a clustering of document elements, where each cluster represents elements
with similarly structured sub-trees. We develop an efficient evaluation algorithm that processes a query over a concise T
REE
S
KETCH
and produces another T
REE
S
KETCH
synopsis that summarizes the
structure of the result. Futhermore, we discuss how the same algorithm can be used to estimate the result size of a complex twig
query.

Para 20 Page 2
 
Efficient T
REE
S
KETCH
Construction Algorithm. We describe
an efficient heuristic algorithm that starts from a detailed summary
and incrementally merges element clusters that are "close" in terms
of element sub-structure. To make our algorithm applicable on
large data sets, we devise an effective heuristic that limits the number of possible merges in every step, without compromising the
quality of the resulting synopsis.

Para 21 Page 2
 
New Distance Metric for XML Documents. We argue that traditional graph-theoretic distance metrics, such as tree-edit distance,
are not suitable for evaluating the quality of an approximate answer
relative to the true result. To overcome this difficulty, we introduce
a novel distance metric that quantifies the differences between two
trees in terms of both the overall path structure and the distribution
of document edges.

Para 22 Page 2
 
Experimental Study Verifying the Effectiveness of
T
REE
S
KETCH
es. We validate our approach experimentally with
an extensive study on real-life and synthetic data sets. Our results demonstrate that T
REE
S
KETCH
es perform consistently better
than previously proposed summarization techniques: they enable
more accurate approximate answers and selectivity estimates, and
at the same time are more efficient to construct. Moreover, our
scaling experiments with large data sets show that even small-size
T
REE
S
KETCH
es are extremely effective in enabling low error selectivity estimates to complex twig queries (e.g., less than 5% estimation error for a 10KB summary of a 100MB input document).
Combined with the affordable construction times of T
REE
S
KETCH
summaries, these results indicate that T
REE
S
KETCH
es constitute
an effective and viable in practice solution for the structural summarization of large XML data sets.

Para 23 Page 2
2. BACKGROUND

Para 24 Page 2
XML Data Model. Following common practice, we model an
XML document as a large, node-labeled tree
¡£¢¥¤§¦©¨£
. Each node

Para 25 Page 2

¤
corresponds to an XML element and is characterized by
a unique object identifier (oid) </i>and a <i>label </i>(or, <i>tag) assigned from
some alphabet of string literals, that captures the element's semantics. Edges
¢©¦© 

¨
are used to capture the containment of
(sub)element


under


in the database. (We use label
¢


,

Para 26 Page 2
children
¢¥
to denote the label and set of child nodes for element node



¤
.) As an example, Figure 1 depicts a sample
XML data tree containing bibliographical data. The document consists of author elements, each comprising a name, and several

Para 27 Page 2
paper
and book sub-elements. Each paper contains a title,
a year of publication and one or more keywords, whereas a

Para 28 Page 2
book
just gives its title. Note that element nodes in the tree are
named with the first letter of the element's tag plus a unique identifier. Leaf elements in
¡
typically contain values, but our primary
focus in this work is on approximately capturing and querying the
label structure of an XML data tree, rather than the relevant value
distributions.

Para 29 Page 2
!#&quot;

Para 30 Page 2
vvlll
lll
lll
((
W
W
W

Para 31 Page 2
BB













Para 32 Page 2
$%

Para 33 Page 2
yyss
ss
s
((
W
W
W

Para 34 Page 2

$'&amp;

Para 35 Page 2
ÒÒÕÕ
Õ

Para 36 Page 2

((
W
W
W
$'(

Para 37 Page 2
ÒÒÕÕ
Õ

Para 38 Page 2

((
W
W
W

Para 39 Page 2
)#0

Para 40 Page 2
ÒÒÖÖ
Ö

((
V
V
V
12
13
45

1
%
&quot;
4
%6&amp;

Para 41 Page 2

7 %8(@9
%A0CB
%8D
)D

Para 42 Page 2
ÒÒÖÖ
Ö

((
V
V
V
77
u
u
u
u
u
)E

Para 43 Page 2
ÒÒÖÖ
Ö

((
V
V
V
9
&amp;(
)
5
ÒÒÖÖ
Ö

((
V
V
V
9
&amp;¥E

Para 44 Page 2
7
%
2
9
%
3
B
%6E
B
%
5
7
&amp;
&quot;
9
&amp;F%GB
&amp;&amp;
7
&amp;60
9
&amp;DHB
&amp;
2
Figure 1: Example XML Document.
XML Query Model. We focus on XML twig queries, which represent the basic building block of declarative query languages for
XML (including the XQuery [4] and XSLT [7] standards). Briefly,
a twig query describes a complex traversal of the XML data tree
and returns a tree-structured XML result constructed through the
intertwined evaluation (i.e., structural join) of multiple path expressions (expressed in XPath [8]). Figure 2(a) depicts an example twig
query over the document of Figure 1, where the
I

's denote variable
names that are bound to specific data elements during query evaluation. We model a twig query
P
as a node-labeled query tree
¡RQ
,
where (1) each node of
¡
Q
is labeled with a variable name
I

in
P
(with
I#S
being a distinguished root node always bound to the XML
document root); and, (2) each edge
¢
I

¦
I


of
¡TQ
is annotated with
an XPath expression
UWVYXa`
¢
I

¦
I


that describes the specific structural constraints specified in
P
between the data elements bound
to
I

and
I

during evaluation. For instance, the query tree corresponding to our example twig query above is shown in Figure 2(b).
Following the generalized tree pattern notation [5], we use dashed
edges to separate paths that are specified in the twig's
return clause
and can thus have empty results without nullifying the result of the
query.

Para 45 Page 3
for
b'cd
in //a[//b]
for
b'cfe
in
b'cd
//p
return

Para 46 Page 3
b'cd
//n
,
for
b'cg
in
b'c
e
//k
return
b'cg
chS
ii©p©q
ihisrFt


Para 47 Page 3
c
d
iivu

ihisw
''

Para 48 Page 3
ce
iisx

cy

Para 49 Page 3
c
g
!
S

Para 50 Page 3
ÓÓ××
××
''
U
U
U
U

Para 51 Page 3
$
e

Para 52 Page 3

''
U
U
U
U
$
g

Para 53 Page 3

((
X
X
X
X
X

Para 54 Page 3
) 

Para 55 Page 3


)
5

Para 56 Page 3


d
S

Para 57 Page 3

e©e

es
(a)
(b)
(c)

Para 58 Page 3
Figure 2: (a) Twig Query, (b) Query Tree, (c) Nesting Tree.

Para 59 Page 3
We consider twig queries using XPath expressions involving only
the child and descendant-or-self axes (i.e., "/" and "//" operators)
and may include existential branching predicates of the form "

l

",
where

l
is, in general, a label path whose existence is required under a given parent node in the XPath expression. As an example, the
"//a[//b]" predicate in Figure 2 specifies author tree nodes
that are located at any depth under the current binding of variable
I
S
(the document root) and have at least one book descendant. Intuitively, the evaluation of a twig query
P
proceeds by jointly evaluating all XPath expressions in
P
over the XML tree, and generating
the full set of binding element tuples for
P
's variables. Each such
binding tuple essentially specifies an assignment of element nodes
to all the
I

query variables such that all structural constraints specified in the query's
¢
I
¦
I
a
edges are met. We will represent the
binding tuples of a query
P
with a nesting tree
£
¢
P

, which contains all the elements of
¡
that appear in the bindings of different
variables and in addition preserves their ancestor/descendant relationships as specified by the query paths. Figure 2(c) shows the
nesting tree for the example query of Figure 2(b). Obviously, the
nesting tree can be used to reproduce the binding tuples of a query
and ultimately its result.

Para 60 Page 3
3. T
REE
S
KETCH
SYNOPSIS MODEL

Para 61 Page 3
3.1 General Graph-Synopsis Model

Para 62 Page 3
Abstractly, our general graph-synopsis model for an XML data
tree
¡£¢¥¤§¦©¨
is defined by a partitioning of the element nodes in
¤
(or, equivalently, by an equivalence relation

¤¤
) that
respects element labels; that is, if
¢ ©¦©Y


then label
¢ ¥ed
label
¢


. The graph synopsis defined for
¡
by such an equivalence relation

, denoted by
fhg
¢8¡i
, can be represented as a graph,
where: (1) each node
j
in
f
g
¢8¡i
corresponds to an equivalence
class of

, i.e., a subset of (identically-labeled) data elements in

Para 63 Page 3
¡
(termed the extent of
j
and denoted by extent
¢
j

); and, (2)
an edge
¢

¦
j

exists in
f
g
¢8¡k
if and only if some element node in

Para 64 Page 3
extent
¢


has a child element in extent
¢
j

. (We use label
¢
j

to denote the common label of all data elements in extent
¢
j

.)

Para 65 Page 3
At a high level, several recently-proposed techniques for building path-index structures for XML (including
l
-indexes [14] and
A(
m
)-indexes [11]), as well as statistical summaries for XML databases
(including XS
KETCH
es [15, 16] and twig-XS
KETCH
es [18]) are all
based on the abstract "node-partitioning" idea described above. As
an example, the basic twig-XS
KETCH
summary mechanism, which
targets selectivity-estimation of complex twig queries, augments
our general graph-synopsis model with (1) per-node count information that records the size of each synopsis node's extent, (2) localized per-edge stability information, indicating whether the synopsis
edge is backward- and/or forward-stable</i>, and (3) <i>edge distribution
information, that captures the distribution of child counts for the
elements in the node's extent, across different stable ancestor or descendant edges. These localized edge distributions are maintained
selectively on a per-node basis in the form of edge histograms, and
essentially enable the computation of selectivity estimates for twig
queries. For a simple example, consider a synopsis node

and two
emanating synopsis edges
on
j
and
pnrq
. A two-dimensional
edge histogram
sut
¢6v
d
¦v
e

would capture the fraction of data elements in extent
¢


that have exactly
v
d
children in extent
¢
j

and
v
e
children in extent
¢
q

.

Para 66 Page 3
Limitations of Selectivity-Estimation Synopses. Given the amount
of earlier work on XML summarization and the number of alreadyexisting synopsis data structures for XML, a natural question that
arises is whether there is a real need for a new summarization mechanism for approximate XML query answering. Our key observation
here is that the focus of all earlier work in the area has been on the
problem of selectivity estimation (for XPath expressions [15, 16]
or twig queries [6, 18]) and, unfortunately, even the state-of-the-art
solutions for XML selectivity estimates prove to be inadequate in
accurately capturing the complete tree structure of the underlying
document.

Para 67 Page 3
We illustrate our observation with a simple example on twigXS
KETCH
synopses (we focus on the twig-XS
KETCH
model since
it also uses a graph-synopsis and it is applicable in the general
case of schema-less documents.) Consider the two XML document trees
¡
d
and
¡
e
shown in Figure 3(a,b). Both documents
have the same set of distinct label-paths and differ only in the number of
v
children for the different
w
elements (the corresponding
counts/multiplicities are shown along the edge). It is straightforward to verify that any twig query will have the same selectivity
in either of the two documents and, in effect, both documents map
to the same, zero-error twigXSKETCH
synopsis, shown in Figure 3(c), with the (exact) edge histograms for nodes
x
and
y
depicted in Figure 3(d). Consider, for instance, the twig query
P
shown in Figure 3(e). Using the twig-XS
KETCH
and the methodology in [18], we can estimate its selectivity s
zv¢
P

with the expression s
zv¢
P
hd|{
extent
¢
x
'{}'~@©

su
¢
w
h}
s
¢6vk{
w
h}
w
}#v
,
which yields the same (accurate) estimate of
l'
for both documents

Para 68 Page 3
¡
d
and
¡
e
. Note, however, that the tree structure for the binding
tuples of
P
is in fact very different across our two example documents. For example, looking at the edge distribution in the query
result, for document
¡
d
, each
x
element appears in

binding tuples, while for document
¡
e
, one element (

d
) appears in

tuples
and the other (

e
) appears in

tuples. This type of information
is not captured by the twig-XS
KETCH
synopsis, since it does not
affect the overall selectivity estimate.

Para 69 Page 4


Para 70 Page 4
ÔÔØØ
Ø
''
T
T
T

Para 71 Page 4

d
ÔÔÙÙ
Ù


e

&amp;&amp;
S
S
S

Para 72 Page 4


Para 73 Page 4
d



Para 74 Page 4
y



Para 75 Page 4
d



Para 76 Page 4
y




d


Para 77 Page 4
ÔÔØØ
Ø
''
T
T
T

Para 78 Page 4

d
ÔÔÙÙ
Ù


e

&amp;&amp;
S
S
S

Para 79 Page 4


Para 80 Page 4
d



Para 81 Page 4
d



Para 82 Page 4
y



Para 83 Page 4
y




e
¥

Para 84 Page 4
B
i
F


8

Para 85 Page 4
B
i
F

kA 

Para 86 Page 4
B
i
F


¥h
(a)
(b)
(c)

Para 87 Page 4






2
1

Para 88 Page 4





f


2
1
1/2
2
4
1/2
c
S

Para 89 Page 4
iis


Para 90 Page 4
c#d

Para 91 Page 4
 


Para 92 Page 4
ce

Para 93 Page 4
¡


Para 94 Page 4
chg


Para 95 Page 4
e



Para 96 Page 4
d

d
((
V
V
V
V

Para 97 Page 4


Para 98 Page 4
d



Para 99 Page 4
y
ÒÒÖÖ
ÖÖ

Para 100 Page 4



Para 101 Page 4
d

d
((
X
X
X
X

Para 102 Page 4


Para 103 Page 4
e



Para 104 Page 4
e



Para 105 Page 4
d



Para 106 Page 4
y
ÒÒÕÕ
ÕÕ

Para 107 Page 4

¢
g
£
d

¢
g

e


Para 108 Page 4
(d)
(e)
(f)

Para 109 Page 4
Figure 3:
(a) Document

d
, (b) Document

e
, (c) TwigXSKETCH
, (d)
Edge-histograms, (e) Twig query
¤
, (f) Count-Stable Synopses.

Para 110 Page 4
Again, the key observation here is that, while twig-XS
KETCH
es
and edge histograms provide an accurate summarization mechanism for twig selectivity estimation, they cannot model the details
of the tree structure for the twig query's binding tuples; thus, we
expect them to be inadequate as a general-purpose approximate
query answering tool (the results of our empirical study in Section 6 clearly verify our expectations.) Furthermore, as this paper
demonstrates, our new synopses are also conceptually simpler, significantly easier to build, and provide more accurate results than
twig-XS
KETCH
es even for the simpler selectivity estimation problem.

Para 111 Page 4
3.2 Count-Stability and the T
REE
S
KETCH
Synopsis

Para 112 Page 4
Our proposed T
REE
S
KETCH
synopsis data structure is a specific
instantiation of the generic graph-synopsis model outlined earlier
in this section. T
REE
S
KETCH
es rely on a novel, intuitive concept
of localized stability, termed count stability, defined formally as
follows.

Para 113 Page 4
D
EFINITION
3.1. Let
¥
¤¦¤
denote a (label-respecting)
equivalence relation over the nodes of
¡£¢¥¤§¦¨£
, and let
¢

¦
j

denote a pair of equivalence classes (i.e., element-node partitions)
induced by

. We say that the pair
¢

¦
j

is
m
-stable (where
m¨§©
)
if and only if each element

ª
has exactly
m
child elements in

Para 114 Page 4
j
. The relation

and the graph synopsis
fhg
¢8¡i
resulting from
the corresponding element partitioning are said to be count stable
if and only if, for every possible pair of element partitions
¢

¦
j

there exists some
m¨§©
such that
¢

¦
j

is
m
-stable.

Para 115 Page 4
Note that the element partitions

,
j
in the above definition essentially correspond to the extents of synopsis nodes in
fhg
¢8¡k
;
furthermore, for
m
-stability, we treat the special case
m
d

as
the absence of child elements (i.e., no synopsis edge between

and
j
). As an example, the count stable summaries for the XML
trees of Figure 3(a,b) are shown in Figure 3(f), where the summary
edges are annotated with the corresponding
m
. It is easy to see that
our notion of count stability is a refinement of the traditional Fstability relation for trees employed by both XS
KETCH
es [15, 16]
and twig-XS
KETCH
es [18]; in other words, the equivalence classes
for the count-stability relation are generated by further partitioning
the equivalence classes for F-stability.

Para 116 Page 4
Intuitively, our concept of count stability tries to define a class
of equivalence relations where element nodes are grouped together
only if the data sub-tree structures underneath them are identical.
As the following lemma shows, the count-stable graph-synopsis for
a data tree
¡
is uniquely defined and, furthermore, it accurately
captures the structure of
¡
.

Para 117 Page 4
L
EMMA
3.1. Given a data tree
¡£¢¥¤§¦©¨
, there exists a unique
minimal (in terms of the number of equivalence classes) countstable equivalence relation
«
¤¬¤
. Furthermore, there exists
a function
¯®W°²±Y³µ´
from stable relations to XML trees, such that

Para 118 Page 4
h®¶°²±Y³²´
¢


is isomorphic to the original document tree
¡
.

Para 119 Page 4
Thus, the tree structure of the original document
¡
can be retrieved with zero-error from a synopsis
·
g
¢8¡k
if

is stable. The
problem, of course, is that the size of a count-stable synopsis can
become very large ­ it can easily be in the order of the original
document size. Given the stringent time and storage limitations
typically associated with interactive approximate query answering,
it is clear that perfect count-stable summaries cannot be very useful
as a data-approximation tool for real-time XML data exploration.
Instead, our proposed T
REE
S
KETCH
synopses try to approximately
capture the underlying document-tree structure within a predefined
space budget. Intuitively, the key idea behind T
REE
S
KETCH
es is
to locally approximate count-stable relations in the graph-synopsis
wherever structural correlations exist in the underlying data, while
relaxing the count-stability requirement where such correlations are
not dominant and independence/uniformity assumptions are sufficient. Our T
REE
S
KETCH
synopsis model is simply defined as follows.

Para 120 Page 4
D
EFINITION
3.2. A T
REE
S
KETCH
synopsis
¸if
for an XML
data tree
¡
is a node- and edge-labeled graph-synopsis for
¡
,
where: (1) each node

in
¸¹f
stores an element count count
¢

§d
{
extent
¢

'{
; and, (2) each edge
¢

¦
j

in
¸if
stores an (average)
child count count
¢

¦
j

equal to the average number of children
in extent
¢
j

for each element in extent
¢


.

Para 121 Page 4
Thus, instead of storing complex histograms for edge combinations in a B/F-stable neighborhood of a node (like twig-XS
KETCH
es
[18]), our T
REE
S
KETCH
es simply maintain a localized average
child count for each edge in the synopsis (without requiring any
stability properties for that edge). The interpretation of the stored
average is simple: all elements in the extent of

have count
¢

¦
j

child elements in the extent of
j
. Obviously, this is trivially satisfied in a stable synopsis where each edge
¢

¦
j

is count stable for

Para 122 Page 4
m
d
count
¢

¦
j

.

Para 123 Page 4
There is an interesting and intuitive connection between T
REE
S
KETCH
es and the clustering of points in multi-dimensional spaces.
More specifically, let

be a synopsis node with outgoing edges

Para 124 Page 4
Cn
j
d
, . . . ,
Cn
jaº
. The set of outgoing edges defines a
»
dimensional space, where an element

ª
is mapped to a point

Para 125 Page 4
¢6v
d
¢ ¦¼'¼#¼'¦©v
º
¢ ©
if it has
v

¢ 
children to node
j

,
l¾½C¿k½«»
.
The recorded average edge counts essentially map all points in this
space to point
¢
count
¢

¦
j
d
¦f¼'¼'¼'¦
count
¢

¦
jaº
©
, which actually represents the centroid of the cluster. We can thus characterize
the quality of a T
REE
S
KETCH
synopsis by using a metric that quantifies the quality of the induced clustering. The metric that we adopt
in our work is the squared error of the clustering, which essentially
measures the euclidean distance between points and their corresponding centroid. The squared error for a single cluster

is defined as
À#I
¢

¯d
~HÁÂ
t
~
d©Ã

Ã
º
¢6v

¢ RÄ
count
¢

¦
j

©
e
, while

Para 126 Page 5
the squared error
À'I
¢
¸if

for a synopsis
¸if
is simply the sum of
squared errors for all the induced clusters. Note, of course, that
the squared error for a count-stable synopsis is zero since all edgecount centroids are exact, i.e., the child counts for any element in a
given synopsis-node extent are identical (and equal to the corresponding edge counts). We have chosen the squared error metric
since it captures a notion of weighted variance, but it is possible
to use other metrics such as the Manhattan distance or the pairwise intra-cluster distance. Irrespective of the actual choice, the
existence of a workload-independent T
REE
S
KETCH
-quality metric is a major difference from earlier summarization techniques
which are also based on graph synopses, but quantify the quality
of summaries on a per-workload basis (examples include both XS
Para 127 Page 5
KETCH
es and twig-XS
KETCH
es.) As we will see later, this feature
will enable fast construction times, since the quality of a summary
in the space of possible T
REE
S
KETCH
es can be determined very
efficiently, without requiring the costly evaluation of a query workload (as in the case of XS
KETCH
and twig-XS
KETCH
construction).

Para 128 Page 5
4. SYNOPSIS CONSTRUCTION AND QUERY

Para 129 Page 5
PROCESSING

Para 130 Page 5
In this section, we start by describing novel, efficient bottom-up
construction procedures for count-stable summaries and our
T
REE
S
KETCH
synopses (for a given space budget). We then introduce algorithms for approximating the results as well as the selectivities of XML twig queries over T
REE
S
KETCH
synopses.

Para 131 Page 5
4.1 Building the Count-Stable Summary

Para 132 Page 5
Our algorithm for constructing the complete count-stable summary of an input XML tree
¡
(termed B
UILD
S
TABLE
) is depicted
in Figure 4. In a nutshell, B
UILD
S
TABLE
processes element nodes
in a post-order traversal of
¡
and constructs the count-stable synopsis graph
f
in a bottom-up fashion. A hash table
sÅ
zF¦hÆ

is used to
maintain the collection of equivalence classes (i.e., synopsis nodes)
built thus far, hashed on the (common) class label
z
and the identifying tuple of child counts
Æ
to other equivalence classes. The key
observation here is that, by virtue of the post-order traversal, when
visiting an element node

, its children in
¡
have already been assigned to equivalence classes in
f
; thus, the equivalence clas for

can be determined (with the help of
sÅ

) based on its label and the
classes and counts of its children (Step 3). If a class for

does not
already exist, a new class/synopsis node is created and the appropriate edges and counts are added to
f
(Steps 4­8). Finally,

is
added to the extent of the corresponding synopsis node (Step 9).

Para 133 Page 5
Algorithm B
UILD
S
TABLE
constructs the count-stable summary
of an XML tree in linear
Ç
¢{
¡{

time; note that, for building the
"child-count signature" in Step 3, only the element's child classes
are necessary, and these can be easily accessed using a stack during
the post-order traversal.

Para 134 Page 5
4.2 Building T
REE
S
KETCH
Synopses

Para 135 Page 5
As already mentioned in Section 3.2, the size of an exact countstable synopsis typically renders it useless in the context of a realProcedure B
UILD
S
TABLE
(

)
Input: XML Document

.
Output: Count-Stable synopsis
È
of

.
begin
1.

:=
É
;
È
:=
É
2.
for each element
ÊÌË

in post-order
do
3.

:=
Í
AÎ




hÏ'Î

is a node in
È
and
Ð
children

Ê
µÑ
extent
Î


ÐÒ

hÓ
 Ô
4.
if

¬Õ
label

Ê

©×Ö
Ò
É

then
5.
Add node
Î
to
È
with label
Î¶
Ò
label

Ê

6.
¬Õ
label

Ê

s×Ö
:=
Î
7.
for
AÎ





Ë

do add edge
Î
sØ

Para 136 Page 5
ÙÚ
Î

to
È
8.
endif
9.
Î
:=
¬Õ
label

Ê

©×Ö
; extent
AÎ¶
:= extent
Î¶²Û
ÍfÊ
Ô
10.
endfor
end

Para 137 Page 5
Figure 4: Algorithm B
UILD
S
TABLE
.

Para 138 Page 5
life approximate query processing system. Such systems usually
place tight limits on the space budget for building synopses of
the underlying data collection. Thus, there is a clear need for effectively constructing compressed T
REE
S
KETCH
synopses under
a given space budget, while maintaining a high-quality XML-data
approximation in order to enable meaningful approximate answers.

Para 139 Page 5
Given
the
aforementioned
natural
analogy
between
T
REE
S
KETCH
es and data clustering (Section 3.2), our goal of constructing an effective synopsis can be translated to computing an
effective clustering of the XML elements. Here, of course, an element cluster is "tight" if it encompasses data elements with similar
sub-trees, and "tightness" can be quantified using the squared error
for the clustering (as discussed in Section 3.2). Thus, our goal is to
build a T
REE
S
KETCH
synopsis
¸if
that fits within a given space
budget, such that the overall square error
À'I
¢
¸if

for the synopsis
is minimized. The analogy with clustering also highlights the difficulty of T
REE
S
KETCH
construction, since such clustering problems are known to be
ÜÞÝ
-hard even in the simple case of points
in a low-dimensional space [19, 23]. Furthermore, T
REE
S
KETCH
construction typically deals with a high-dimensional space which is
defined by the clustering itself (i.e., the space itself changes as elements are assigned to clusters)! Thus, the problem is significantly
more complex and existing clustering algorithms are not directly
applicable.

Para 140 Page 5
Our approach is based on a generic bottom-up clustering paradigm:
starting from the count-stable synopsis, our algorithm (termed TSB
UILD
) incrementally reduces the synopsis size by merging nodes
with similar sub-structures, until the budget constraint is met. This
resembles agglomerative hierarchical clustering algorithms, which
start with one cluster per input data point and successively reduce
the number of clusters by merging neighboring groups (according
to some appropriate distance metric). Another possible option is
a top-down approach that starts from a coarse summary and gradually expands it by splitting nodes (this is actually the approach
taken in the XS
KETCH
work [15, 16, 18]). In the clustering literature, however, bottom-up algorithms have been shown to perform better than their top-down counterparts; in addition, we have
experimentally verified that bottom-up T
REE
S
KETCH
construction
yields much better results, without significantly increasing construction time.

Para 141 Page 5
The TSB
UILD
Algorithm. We now describe our T
REE
S
KETCH
construction algorithm in more detail. In a nutshell, TSB
UILD
maintains a pool of candidate operations to be applied to the working T
REE
S
KETCH
synopsis
¸if
(initialized to the count-stable graph),
where each operation
ß
in the pool merges two nodes of
¸¹f
(deProcedure TSB
UILD
(
à
,
¢
,
áTâ
,
ãäâ
)
Input: XML document
à
; space budget
¢
; upper/lower bounds for
heap size

áTâ

ãäâ

Output: T
REE
S
KETCH
synopsis
åÌÈ
of

of size
æ
¢
begin
1.
åÌÈ
:= B
UILD
S
TABLE
(

)
// Start with the count-stable summary
2.
çéè¥É
3.
while (size

åÌÈ

Ó
¢
)
do
4.
ç
:= C
REATE
P
OOL
(
å¯È
,
á
â
)
5.
while

size

åÌÈ

Ó
¢
and size

ç

Ó
ã
â

do
6.
ê@èëçµì
íWîví¶ïñð

8
7.
åÌÈ
:=
ê

åÈ

// Apply
ê
on
åÈ
8.
Let
Î¶ò
be the new synopsis node
9.
for each
êóôËõç
do
10.
if (
ê
ó
ì

îfö Êf÷
Ñ
ê¬ì

î'öÊ'÷kø
Ò
É
)
then
11.
Remove
ê
ó
from
ç
12.
Add a merge between
ê
ó
ì

î'öÊf÷
Ù
ê¾ì

î'öÊ'÷
and
Î
ò
to
ç
13.
endif
14.
Recompute
ê
ó
ì
Ê
'hù

ê
ó
ì
÷hð6úÊ
ù
for all
ê
ó
Ë
affected

ç

ê

15.
endwhile
16.
endwhile
17.
return
åÌÈ
end

Para 142 Page 6
Figure 5: Algorithm TSB
UILD
.

Para 143 Page 6
noted by
ß
¼
»üûYý

À
). If
ß
¢
¸if

denotes the resulting synopsis after
applying the merge
ß
on
¸if
, we define
ß
¼
#þYþ
ù
d
À'I
¢
ß
¢
¸kf
©Ä

Para 144 Page 6
À'I
¢
¸if

to be the increase in squared error from
¸if
to
ß
¢
¸if

,
and
ß
¼
À#¿¥ÿ

ù
d
size
¢
¸if
Ä
size
¢
ß
¢
¸if
©
to be the corresponding decrease in synopsis size. The pool of candidate operations is organized in a min-heap </i>according to the <i>marginal-gain
ratio
ß
¼
#þYþ
ù¡ 
ß
¼
À'¿¥ÿ

ù
, i.e., the operation at the top of the heap
offers the least increase in squared error per unit of space that is
saved. At each step of the construction algorithm, the operation at
the top of the heap is applied, the pool is updated with new merge
operations for the new node, and the
þ þ
ù
¦
À'¿Fÿ

ù
metrics are recomputed for the new pool of candidate merge operations. This
process is repeated until the heap is exhausted (i.e., no merge operations are possible) or the size of the
¸¹f
synopsis drops below the
allotted space budget.

Para 145 Page 6
The pseudo-code for our TSB
UILD
algorithm is shown in Figure 5. TSB
UILD
initializes the min-heap
¢
of candidate merge
operations through function C
REATE
P
OOL
(discussed below), and
then applies successive merges according to our marginal-gain criterion (Steps 5-15). In order to limit the memory requirements
of the algorithm and increase efficiency, the size of the operations
heap is bounded by the supplied parameter
£
â
. As operations are
performed, the size of the heap is gradually reduced and when it
drops below a supplied threshold
¤
â
, the heap is re-generated and
the process repeated.

Para 146 Page 6
A potential performance bottleneck for the construction process
is the re-computation of the
#þ þ
ù
and
À'¿¥ÿ

ù
metrics for the merge
operations in the heap. To make this more efficient, our TSB
UILD
algorithm employs two key techniques. First, re-computation is
performed only for a limited subset of the candidate merge operations. The key observation here is that the
#þYþ
ù
and
À'¿¥ÿ

ù
metrics
measure differences in the characteristics of the synopsis (rather
than absolute quantities) and, thus, most of them can be preserved
across merges. More specifically, if
ß
is the merge that was performed last and

ò
is the newly created node, then TSB
UILD
only
needs to compute the metrics for operations that merge parent or
child nodes of

ò
(we denote this set of operations as affected
¢¦¥¬
);
for the remaining operations, the
#þ þ
ù
,
À'¿Fÿ

ù
metrics remain unchanged.
Procedure C
REATE
P
OOL
(
å×È
,
áTâ
)
Input: Synopsis
åÌÈ
; heap-size upper bound
áRâ
.
Output: Double-ended heap
ç
containing
æáRâ
merge operations.
begin
1.
çéè
É
,
§£Ê©¨ Ê§
:=

2.
while

§£Ê©¨ Ê§
height

åÈ

and size

ç

ñá
â

do
3.
§£Ê©¨ Ê§
:=
§£Ê©¨ Ê§¡

4.
for all
Î

¨£ËåÈ
Ï
label
AÎ¶
Ò
label

¨

do
5.
if

ÍföÊví ç
Î²

ö ÊFí ç

¨
vÔ
Ò
§£Ê©¨ Ê©§

then
6.
Let
ê
be the operation that merges
Î
,
¨
7.
çµì
í
Î
÷hç

ê

8.
if

size

ç

Ó
á
â

then
çµì
í
îsíWï
&quot;!
8
9.
endif
10.
endfor
11.
endwhile
12.
return
ç
end

Para 147 Page 6
Figure 6: Algorithm C
REATE
P
OOL
.

Para 148 Page 6
Our second technique makes the computation of
#þYþ
ù
more efficient by storing "sufficient" statistics in each synopsis node. Briefly,
each node stores the sum and the sum of squares for the child
counts of its elements along each outgoing edge in the synopsis.
It is straightforward to show that these statistics are sufficient in order to compute the squared-error metric for the synopsis
À'I
¢
¸if

without accessing the base data. In addition, in certain cases, these
statistics can be combined in order to derive the statistics of new
nodes (created through merge operations). The complete details
are beyond the scope of this presentation and can be found in the
full paper [17]. Note that this idea is similar to the one proposed
in the BIRCH clustering algorithm [23], where clusters are represented only by a collection of similar sufficient statistics throughout
the computation. In our case, however, the stored statistics do not
obviate the need to access a small subset of the base data (although
this can be done very efficiently, by accessing only the relevant
parts of the count-stable summary). Again, we defer the details to
the full version of this paper [17].

Para 149 Page 6
Generation of Candidate Operations. We now discuss the de
Para 150 Page 6
tails of our C
REATE
P
OOL
algorithm for initializing a heap of at
most
£
â
merge operations. An obvious approach would be to generate all possible pair-wise merges and keep the top
£
â
operations
according to our ratio metric
#þYþ
ù
 
À'¿¥ÿ

ù
. Unfortunately, such a
solution requires evaluating
Ç
¢

e

merge operations, where

is
the number of nodes in the count-stable summary and, thus, becomes prohibitively expensive as the size and complexity of the
data grows. Given that C
REATE
P
OOL
is invoked repeatedly during
the T
REE
S
KETCH
-construction process, this increased complexity
has a significant negative impact on construction times. On the
other hand, reducing the number of operations considered increases
the efficiency of the candidate-generation stage, but it also runs the
risk of "polluting" the heap with less effective merge operations
that can affect the quality of the generated T
REE
S
KETCH
es.

Para 151 Page 6
To overcome this difficult problem, we adopt a heuristic that limits the number of merge operations considered while ensuring that
the heap only contains operations that are likely to be beneficial.
The key observation here is that a merge of two nodes

and
j
leads to a "good" clustering of the elements involved only if

and

Para 152 Page 6
j
have similarly structured sub-trees. Thus, our T
REE
S
KETCH
construction algorithm is much more likely to apply merge operations on the children of

and
j
first, before merging

and
j
themselves. This observation suggests a bottom-up approach for populating the heap with merge operations, starting with nodes close
to the leaves of the current synopsis and proceeding upward to the
root.

Para 153 Page 7
Figure 6 shows the pseudo-code for our C
REATE
P
OOL
algorithm
that implements the aforementioned heuristic. C
REATE
P
OOL
uses
the concept of a node's depth in order to examine merge operations in a bottom-up fashion. More specifically, let

be a document element. The depth of

is defined as

if

is a leaf, and
l$#
¥
±®&amp;%ý
('&amp;)
¢
¢

10
otherwise, where the maximum is taken over all

Para 154 Page 7



children
¢ 
. Intuitively, the depth of an element is the
longest path that leads to a leaf descendant. The depth of a synopsis node

is defined as
¥
±®
ÁhÂ
t
%ý
('&amp;)
¢
¢ 10
. C
REATE
P
OOL
evaluates merge operations at increasing depths in the current synopsis

Para 155 Page 7
¸¹f
and only records the best
£
â
of the operations seen thus far
(this can be implemented efficiently through a double-ended heap).
Candidate generation terminates when the current depth has been
exhausted and the heap holds the maximum allowed number of operations.

Para 156 Page 7
4.3 Approximate Query Processing

Para 157 Page 7
We now turn our attention to the problem of generating approximate answers from a concise T
REE
S
KETCH
synopsis. At an abstract level, our query evaluation algorithm, termed E
VAL
Q
UERY
,
processes the input query
P
over an input T
REE
S
KETCH
¸¹f
and
produces an output T
REE
S
KETCH
¸if
Q
that summarizes the nesting tree
é
¢
P

(the full nesting tree can be retrieved by expanding

Para 158 Page 7
¸¹f
Q
). As noted in Section 2, the full nesting tree can be used to
reconstruct the binding tuples of
P
and ultimately its result. The
evaluation algorithm uses the structure information of
¸if
in order
to identify matches of the query's path expressions, while the stored
edge counts are used to approximate the cardinalities of the corresponding result sets. Similar to any summarization method, the
use of the stored information is coupled with a set of appropriate
statistical assumptions that compensate the lack of detailed distribution information at certain parts of the synopsis. As we will see,
the validity of these assumptions depends on the quality of element
clustering within each synopsis node and is thus directly linked to
the heuristics of the TSB
UILD
algorithm. Intuitively, this direct
relationship between the build algorithm and the query processing framework leads to the construction of summaries that compute
highly accurate approximate answers.

Para 159 Page 7
Figure 7 shows the pseudo-code for algorithm E
VAL
Q
UERY
.
The algorithm processes query
P
over the input synopsis
¸¹f
and
incrementally builds the result T
REE
S
KETCH
¸if
Q
. Each node

Para 160 Page 7

Q

¸if
Q
corresponds to a set of elements with tag label
¢

Q§
,
which come from the extent of a node


¸if
and will appear
in the bindings of query variable
I

P
. We will use the notation

Q
¢

¦
I

to denote this association and the shorthand

Q
¢
I

when no confusion arises. In addition,
w¿¥»üý
I
will denote the set
of nodes in
¸if
Q
that contain bindings for
I
.

Para 161 Page 7
Initially, the approximate T
REE
S
KETCH
contains a root node

Para 162 Page 7
þ QÌ¢¦24353
X
¢
¸¹f
¦
I#S

which specifies the binding of the topmost variable
I
S
to the root of the document. The algorithm processes the
query nodes in a pre-order traversal and, for each node
I
, evaluates the path expressions to the children of
I
, relative to the computed bindings in
wf¿»üý
I
. More specifically, for each child
I

and binding

Q¢

¦
I


wf¿»üý
I
, the algorithm computes a list
of bindings
y
¢
I

¦

Q§¬d76
¢
j
¦
m
98
for variable
I

(lines 4-9),
where
j

¸if
and
m
8

is a descendant count. Essentially,
each
¢
j
¦
m


y
¢
I

¦

Q

specifies that every element in

Q
(the
current binding for
I
) has exactly
m
descendants in
j
along path

Para 163 Page 7
U
VYXa`
¢
I
¦
I


. The new bindings are recorded with the insertion of
a node
j
Q
¢
j
¦
I


and an edge

Q
n
j
Q
. Since an element in

Q
can have descendants in the same node
j
through multiple paths
procedure E
VAL
Q
UERY
(
å¯È
,
¤
)
Input: T
REE
S
KETCH
åÌÈ
of document

; twig query
¤
Output: T
REE
S
KETCH
åÈ
Q
that approximates the nesting tree
@


¤

begin
1. Initialize
åÈ
Q
with root

Q
A&quot;BCB
9

åÈ


c
S

2.
for each
c
Ëõ¤
in a pre-order traversal
do
3.
for each
Î
Q
Î

c

Ë

ð

ö
Õ
c
Ö6
c

Ë
children

c

do
4.
Let
í
ò
be the main path of
) $
9ED

c

c


.
5.
F
:=
ÍfÊ

Ð
Ê

Ò
ÎHG
ììì
G
¨CI
is an embedding of
í
ò¹Ô
6.
for all
Ê

Ò
ÎHG
ììì
G
¨CIRË7F
do
7.

I
:= E
VAL
E
MBED

í

Ê


;
k
c


Î
Q

è

¨CI
F
I

8.
done
9.
for

¨
©

in
i
c


Î
Q

do
10.
Add node
¨
Q

¨

c


to
åÈ
Q
if it does not exist
11.
Add edge
Î
Q
Ú
¨
Q
to
åÌÈ
Q
if it does not exist
12.
count
Î
Q

¨
Q


Ò

13.
done
14.
done
15.
if
¦P
c

Ë

ç
ð¦§£ö

Ê

Õ
c
Ö
Ï

ð

ö
Õ
c

Ö
ÒRQ

then
16.
return
Q
// The answer is empty
17.
done
18.
return
åÌÈ
Q
end

Para 164 Page 7
Figure 7: Algorithm E
VAL
Q
UERY
.

Para 165 Page 7
in the synopsis, all counts
m
that correspond to the same
j
are aggregated in count
¢

Q
¦
j
Qe
(line 12). Note that the algorithm inserts exactly one node

Q
¢

¦
I

for each pair
¢

¦
I

, thus forming
a graph-structured summary
¸¹f
Q
. This optimization, which guarantees a worst case size of
Ç
¢{
¸¹f
{v}h{
P
{

for the intermediate result
synopsis, stems from the interpretation of the T
REE
S
KETCH
summarization model: all elements in

contain identically structured
sub-trees and thus need to be represented only once in the synopsis
(regardless of their ancestor nodes.) The query node
I
is included in
the association in order to correctly handle the case where elements
of the same node appear in the bindings of different query nodes.
In order to compute the set of bindings
y
¢
I

¦

Q

for variable
I

,
the algorithm first identifies the synopsis paths that possibly contain descendants of

Q
along
UWVYXY`
¢
I
¦
I


, and the number of descendants along each path is computed with algorithm E
VAL
E
M

Para 166 Page 7
BED
. The separate invocations of E
VAL
E
MBED
essentially apply
an independence assumption between the different variables of the
query, which translates to an independence assumption on the underlying path distribution. We defer this point to the end of the section, where we discuss the relationship of the processing assumptions to the general T
REE
S
KETCH
framework.

Para 167 Page 7
The pseudo-code for algorithm E
VAL
E
MBED
is shown in Figure 8. The final descendant count is computed as the number of
descendants
»TS
along the main path of the embedding, scaled by
the selectivity factors of the branch embeddings. The count
»TS
is
estimated simply as the product of the corresponding edge counts,
using the assumption that every element in source node


has

Para 168 Page 7
count
¢

©¦

U
d

children to target node

U
d
(this is the basic
interpretation of the T
REE
S
KETCH
model.) To estimate the selectivity
À

of branching predicate

l

, the algorithm calls itself recursively to compute the number of descendants for each element of
node


(the source of the branch) along the different embeddings
of

l

. If there exists at least one embedding such that the descendant count is
§
l
, then all elements in


satisfy the branching
predicate and the selectivity is equal to 1. In the opposite case (all
descendant counts are strictly less than 1), each count is treated
as the fraction of elements in

that have descendants along the
corresponding embedding of the branching predicate. Since an element satisfies the branching predicate if it is the root of at least one
Procedure E
VAL
E
MBED
(
í
,
Ê
)
Input: XPath
í
Ò
l
d
Õ
V
l
d
Ö
G
ììì
G
l
º
Õ
V
l
º
Ö
; synopsis path

Para 169 Page 8
Ê
Ò
Î
S
GfÎ
d
G
ìhìì
GfÎ
º
, where
Î
d
G
ììì
GfÎ
º
is an embedding of
l
d
G
l
e
G
ìhìhì
G
l
º
Output: Estimated number of descendants for each element of
Î
along
í
.
begin
1.

S
:=
W
SX

Ã
º
count
Î
`Y
d

Î


// Descendants along main path
2.
for each
V
l

Ëkí
do // Compute the selectivity of branches
3.
F

:=
ÍfÊ

Ð
Ê

Ò
Î

G
¨
d
G
ììì
G
¨CI
is an embedding of
V
l

Ô
4.
for all
¨
I
Ï
ÍfÊ

Ð
Ê

Ò
Î

G
ììì
G
¨
I
ËaF

Ô
ø
ÒRQ
do
5.

I
:=
b
ÁdcÂ eµØ
E
VAL
E
MBED

V
l


Ê


6.
@

è

I
7.
done
8.
if
P


Ëa@

Ï

gf

then
9.
÷

:= 1
10.
else

Para 170 Page 8
11.
÷

:=
h

Para 171 Page 8
b
i
c#Â5pTØ


Ù
b
i
c#
iq
Â5pTØs
¡r
s
I


ut

I


Para 172 Page 8

b
i
c#
iq

i©v

¡r
s
I
r
s
ò


wt

I
t

ò

Ù
t1t1tyx
// inclusion-exclusion

Para 173 Page 8
12.
endif
13.
done
14.
return

S
t
W
d©Ã

Ã
º
÷

end

Para 174 Page 8
Figure 8: Algorithm E
VAL
E
MBED
.

Para 175 Page 8
matching embedding, the overall selectivity is computed using the
inclusion-exclusion principle on the recorded fractions (line 11).
We note that the application of the exclusion/inclusion principle
essentially makes use of an independence assumption on the distribution of document edges, which, as we discuss below, is derived
from the interpretation of the T
REE
S
KETCH
summarization model
and is closely related to the squared error of the synopsis.

Para 176 Page 8
chS
ii©p


Para 177 Page 8
c#d
r



Para 178 Page 8

q
i(¥t
ihi
ÒÒÕÕ
ÕÕ

Para 179 Page 8
c
g
ce
ii


Para 180 Page 8
chy



Para 181 Page 8
c©
A

Para 182 Page 8
d
S



ÒÒÖÖ
ÖÖ

Para 183 Page 8
S
e

e
))
Y
Y
Y
Y

Para 184 Page 8


Para 185 Page 8
e
''
V
V
V
V






ÑÑÔÔ
ÔÔ





00
a
a
a
a

Para 186 Page 8


Para 187 Page 8
d




%

Para 188 Page 8

&amp;

Para 189 Page 8

A$f
c
S


Para 190 Page 8
d
S


Q

cd


Para 191 Page 8

}}zz
zz
S
e


©
33
h
h
h
h

Para 192 Page 8

Q

ce


Para 193 Page 8
e
33
h
h
h
h

Q

cfe


Para 194 Page 8



Q

c
g


Para 195 Page 8

Q

cy


Para 196 Page 8
d




Q

c

(a)
(b)
(c)

Para 197 Page 8
Figure 9: (a) Query
P
, (b) T
REE
S
KETCH
¸if
(c) Result
T
REE
S
KETCH
¸éf
Q
.

Para 198 Page 8
E
XAMPLE
4.1. Consider the invocation of E
VAL
Q
UERY
on the
query
P
and synopsis
¸if
shown in Figure 4.3. Initially, the result
synopsis contains a root
þ
Q
¢6þY¦
I
S

only and
w¿¥»üý
I
S

d
þ
Q
. On
the first iteration of E
VAL
Q
UERY
, variable
IS
is processed and the
bindings of child variable
I
d
are computed. In this case, it is easy
to verify that each element in
þYQ
has 10 descendants along path

Para 199 Page 8
//a
to node

. As a result, node

QÌ¢

¦
I
d

is inserted in
¸¹f
Q
along with edge
2
Q
n

Q
, and count
¢¦2

¦

Q
§d
l#
.

Para 200 Page 8
Let us consider now the processing of
I
d
, and more specifically,
the computation of bindings from
I
d
to
I
g
. Starting from node

Para 201 Page 8

, which appears in the bindings of
I
d
, we can identify exactly
one simple embedding of
UWV Xa`
¢
I
d
¦
I
g
õd

 &quot;d

 ¡ &quot;e
, namely
ëd

 Cfg &quot;h
. The bindings of
I#g
, therefore, will be the descendants of

along the given embedding. To compute the number of descendants
for each element in

(algorithm E
VAL
E
MBED
), we first observe
that
»
S
d
count
¢

¦
f
§}
count
¢
f
¦
h
Ìd

}

¼

d
l
. This count
needs to be scaled by the selectivity of the branching predicate

 $d

,
for which there exist two embeddings:
i
%
, with descendant count
0.6, and
i
&amp;
, with descendant count 0.7. Essentially, 60% of elements in </i>D <i>have a branching embedding along
i
%
and 70% have
a branching embedding along
i
&amp;
. The overall branch selectivity is
computed as
À
d

¼
j
#ª
¼
k¹Ä

¼
j¹}

¼
kõd

¼
a
. Thus, the number
of descendants along </i>d[/g]//f <i>for each binding in
I
d
is
l
}

¼
a
and
¸if
Q
is updated accordingly. The final result synopsis
¸if
Q
is shown in Figure 4.3(c) (synopsis nodes are annotated with the
corresponding query node).

Para 202 Page 8
As noted previously, the evaluation algorithm applies a set of independence assumptions during the processing of an input query
over a concise T
REE
S
KETCH
summary. At a closer inspection, all
the processing assumptions can be reduced to a basic independence
assumption that de-correlates the distribution of document edges
along different paths of the document. This assumption is essentially derived from the interpretation of the T
REE
S
KETCH
synopsis model: given a synopsis edge
Þn
j
, all elements in

have

Para 203 Page 8
count
¢

¦
j

children in
j
, independent of incoming or outgoing
paths (Section 3). Obviously, this interpretation is trivially satisfied
on a stable synopsis where, by virtue of count-stability, all elements
in the extent of a node

have the same edge counts to child nodes.
As a result, E
VAL
Q
UERY
will compute the exact nesting tree of
a query when the accessed edges of the synopsis are count-stable.
In the general case of a compressed T
REE
S
KETCH
, it is straightforward to observe that the validity of the assumption is directly
related to the error of the induced element clustering: if the error is
low, i.e., the clusters are tight, then the elements are closer to the
centroid (which is defined by the recorded average edge counts),
and the assumption becomes more valid. In essence, there is a close
relationship between the squared error of the synopsis, which quantifies the tightness of the clusters, and the quality of the generated
approximate answers. This observation provides the "missing link"
between the construction algorithm and the evaluation framework:
although the build process does not use a workload-based approach
to ensure high-quality approximate answers, it achieves the same
goal by keeping the squared error low and thus making the basic
independence assumption more valid.

Para 204 Page 8
4.4 Selectivity Estimation

Para 205 Page 8
In this section we briefly discuss the use of T
REE
S
KETCH
es for
estimating the selectivity of twig queries. As shown in earlier studies [5, 13], accurate estimation for the number of bindings tuples
for twig queries is a key requirement in producing effective query
plans for complex declarative queries over XML data.

Para 206 Page 8
Our proposed estimation framework uses the result of the E
VAL
Q
UERY
algorithm to efficiently compute an estimate of the query's
selectivity. More specifically, the estimation algorithm performs
a single post-order traversal of the structural summary
¸éf
Q
and
computes, for each node, the average number of binding tuples per
element in its extent. Given the bounded size of
¸if
Q
, it becomes
clear that the estimation process has low memory requirements and
can be performed very efficiently. In the interest of space, we do
not discuss the estimation algorithm further. The full details can be
found in the full version of this paper.
5. AN ERROR METRIC FOR APPROXIMATE

Para 207 Page 9
XML QUERY ANSWERS

Para 208 Page 9
In order to evaluate the effectiveness of the proposed approximate
query answering framework, it is necessary to measure the degree
of similarity between the approximate nesting tree
mlon
¢
P

that
is computed over a concise synopsis
¸if
, and the true nesting tree

Para 209 Page 9
é
¢
P

of the query. More formally, this translates to computing
a distance
ý
¿FÀ
)

¢

lon
¢
P
¦


¢
P
©
between the two XML trees
which essentially quantifies the error of approximation. There are
numerous proposals for distance metrics over trees, the most widely
used being the tree-edit distance metric [20]. As we will see next,
however, the proposed metrics essentially measure the syntactic
differences between the two XML trees and thus fail to capture the
semantics of approximate answers. We note that our discussion will
focus on the tree-edit distance metric, but our observations hold for
other graph-theoretic metrics as well.

Para 210 Page 9
The tree-edit distance
ý
¿FÀ
)
e
¢8¡
d
¦s¡
e

between two XML trees

Para 211 Page 9
¡
d
and
¡
e
measures the minimum cost sequence of edit operations
that transform
¡
d
to
¡
e
(or vise versa). The basic edit operations
include adding, deleting, or relabeling a tree node, while more complex operations (such as copying whole sub-trees) are usually modelled as a composition of simple operations. Consider, for instance,
the example of Figure 10, where
·

and
·
ù
denote sub-trees of
sizes
{
·

{
and
{
·
ù
{
respectively and numbers along edges denote
child cardinalities. We will assume that
¡
is the true nesting tree
of the query, and
¡
d
¦s¡
e
are two possible approximations. If we
limit the edit operations to node insertion and deletion, and assuming that each operation has unit cost, it is straightforward to show
that
ý
¿FÀ
)
e
¢8¡¦s¡
d
§dqp
}a{
·

{
#
p
}a{
·
ù
{
(essentially, we have to add
3
·

sub-trees to the left

element of
¡
d
and delete 3
·

sub-trees
from the right

element in order to transform
¡
d
to
¡
). Similarly,

Para 212 Page 9
ý
¿FÀ
)
e
¢8¡¦s¡
e
¯dqp}#{
·

{
#
pÌ}{
·
ù
{
. According to tree-edit distance,
therefore,
¡
d
and
¡
e
are equally good approximations of the true
result. Intuitively, however, we expect
¡
e
to be a better approximation since it maintains the correlation between the number of
·

and
·
ù
subtrees under the same parent (few
·

are combined with
several
·
ù
and vise versa); answer
¡
d
, on the other hand, conveys
exactly the opposite trait, that there is an equal number of
·

and

Para 213 Page 9
·
ù
sub-trees under every

.

Para 214 Page 9


Para 215 Page 9
ÔÔÙÙ
Ù
&amp;&amp;R
R
R

Para 216 Page 9

y
ÓÓ××
×
d



Para 217 Page 9
d

y
''
U
U
U

Para 218 Page 9
r&amp;s
r&amp;t
r&amp;s
r&amp;t


Para 219 Page 9
ÔÔÙÙ
Ù
&amp;&amp;R
R
R

Para 220 Page 9

d
ÓÓ××
×
d



Para 221 Page 9
y

y
''
U
U
U

Para 222 Page 9
r&amp;s
r&amp;t
r&amp;s
r&amp;t


Para 223 Page 9
ÔÔÙÙ
Ù
&amp;&amp;
R
R
R

Para 224 Page 9


ÓÓ××
×
e



Para 225 Page 9
e


''
U
U
U

Para 226 Page 9
r&amp;s
r&amp;t
r&amp;s
r&amp;t


d

e
Figure 10: Query answer
¡
and two approximations
¡
d
,
¡
e

Para 227 Page 9
The previous example illustrates that the syntactic difference between two documents, as measured by tree-edit distance or other
similar graph-theoretic metrics, is not a suitable similarity metric
for approximate answers. Intuitively, an approximate answer is
useful if it preserves the statistical traits of the true answer, without necessarily being identical to it, and the distance metric should
capture this type of "approximate" similarity. Similar observations
have been made in the context of approximate answers for relational queries [3, 10], where the result of a query is a multi-set of
values. In short, these studies have argued convincingly that settheoretic metrics, which correspond to syntax-oriented metrics in
the XML world, do not yield intuitive results when comparing two
value sets (the approximate and the true answer). This has led to
the introduction of new distance metrics, such as the MAC [10] and
the EMD [3], in order to measure effectively the quality of approximate answers to relational queries.

Para 228 Page 9
A New Distance Metric for XML Trees. We introduce a novel

Para 229 Page 9
distance metric, termed Element Simulation Distance (ESD), that
avoids the shortcomings of syntax-oriented metrics by capturing regions of approximate similarity between the compared XML trees.
To the best of our knowledge, ours is the first metric that considers both the overall path structure and the distribution of document
edges, when computing the distance between two XML trees.

Para 230 Page 9
We now describe the ESD metric in more detail. Let


¡
d
and
j

¡
e
be elements of the compared trees with label
¢

d
label
¢
j

. We wish to define a function
¨
·vu
¢

¦
j

that measures
the degree of "simulation", or sub-tree similarity, between the two
elements. Let
£
S
and
¤
S
denote the children of

and
j
respectively that have tag
)
. If we treat
£wS
¦¤
S
as two sets of "values",
where the distance between any two elements

ó

£
S
¦
j
ó

¤
S
can be measured as
¨
·vu
¢

ó
¦
j
ó

(i.e., a recursive application of
the metric to the children of

¦
j
), then we can measure the distance
ý
¿FÀ
)1xT¢
£vS
¦h¤
S

between
£wS
¦¤
S
by using any existing valueset distance metric, like MAC [10] or EMD [3]. The result is an
indication of how well

's children of tag
)
simulate
j
's children
of the same tag. The ESD distance between

and
j
can now be
measured as the sum of distances for children of matching tags:

Para 231 Page 9
¨
·vu
¢

¦
j
¯d
~
S
ý
¿FÀ
)1xT¢
£vS
¦h¤
S

. In effect, two elements are more
(or less) similar if their children with matching tags are more (or
less) similar themselves, which recursively extends to the whole
sub-structure underneath the two elements. In the case where one
of
£vS
¦h¤
S
is empty, we apply a straightforward transformation so
that the computation of
ý
¿FÀ
)1xT¢
£wS
¦h¤
S

is well defined. More concretely, assume without loss of generality that
¤
S
dzy
. For each
element


£wS
, we insert a unique (artificial) element
&quot;{
in
¤
S
with distance
¨
·vu
¢
¦©
{
kd
{

{
, where
{

{
is the sub-tree size of

Para 232 Page 9

, and
¨
·vu
¢
ó
¦${ad}|G¦d~ü
ó

£vS
¦©
ó
d

. This transformation essentially models the insertion of the missing sub-trees under

Para 233 Page 9
j
and allows the set-distance metric to be computed on the new
non-empty set
¤
S
.

Para 234 Page 9
E
XAMPLE
5.1. Consider the example of Figure 10 and let

and
j
be the left

elements of
¡
and
¡
d
respectively. Elements

Para 235 Page 9

¦
j
have children of tags
v
and
ý
(the roots of sub-trees
·

and
·
ù
)
and thus
¨
·vu
¢

¦
j

d
ý
¿FÀ
)1xT¢
£

¦¤


#ªý
¿FÀ
)1xT¢
£
ù
¦¤
ù

. In order
to compute
ý
¿FÀ
)
x
¢
£

¦¤


, we observe that the pairwise distances

Para 236 Page 9
¨
·vu
¢6v

¦©v

¦©v


£

¦©v


¤

are equal to 0, since the elements
have identical sub-trees. Essentially, the two value sets contain
equal values but at different multiplicities. If we use the MAC metric [10], then the computed distance
ý
¿FÀ
)1xT¢
£

¦¤


is equal to 8
due to the difference in value frequencies. On the other hand, sets

Para 237 Page 9
£
ù
and
¤
ù
have the same elements at the same frequencies and thus

Para 238 Page 9
ý
¿FÀ
)
x
¢
£
ù
¦¤
ù
Ìd

. Overall,
¨
·vu
¢

¦
j
ed
#©
d

. Now, assume that
j
ó
is the left

element of
¡
e
. It is straightforward to show
that, under the same MAC metric,
¨
·vu
¢

¦
j
ó
édj
and thus, as
expected intuitively, the element of
¡
e
simulates better the element
of the true result.

Para 239 Page 9
Having defined the ESD metric between any two elements, we
define the ESD metric between two trees
¡
d
¦s¡
e
as
¨
·vu
¢8¡
d
¦s¡
e
¯d
¨
·vu
¢¦24353
X
¢8¡
d
¦(2 353
X
¢8¡
e
©
. We note that
¨
·vu
¢8¡
d
¦s¡
e

does not
lend itself to a meaningful interpretation, except that a lower value
represents increased similarity between
¡
d
and
¡
e
. This, however,
is a common characteristic of metrics that measure the approximate distance between complex objects (e.g., a similar observation
holds for the MAC and EMD metrics). We note that it is possible
to compute the ESD metric efficiently by first building the stable
Data Set
Elements
File Size (MB)
Stable Synopsis
Size (KB)
IMDB-TX
102,754
3
77
XMark-TX
103,135
5
276
SProt-TX
182,300
4
265
IMDB
236,822
7
149
XMark
2,048,180
100
2,652
SProt
473,031
10
645
DBLP
1,594,443
48
204

Para 240 Page 10
Table 1: Data set characteristics

Para 241 Page 10
summaries of
¡
d
and
¡
e
on the fly and then evaluating the metric
on the stable synopses. The key observation is that a stable summary preserves the path structure and the edge distributions of the
original document, while containing fewer nodes. A detailed description of the computation of ESD on stable summaries can be
found in the full version of the paper [17].

Para 242 Page 10
6. EXPERIMENTAL STUDY

Para 243 Page 10
In this section, we present an extensive experimental study of
T
REE
S
KETCH
es on real-life and synthetic data sets. Our results
verify the effectiveness, in terms of accuracy and construction time,
of the T
REE
S
KETCH
synopses as structural summaries for large
XML data sets. These benefits become even more apparent in a
comparison to previously proposed techniques, where T
REE
S
KETCH
es
perform consistently better in all aspects. Overall, this empirical
study indicates that T
REE
S
KETCH
es are a viable and effective solution for the structural summarization of large XML data sets in
real-world applications.

Para 244 Page 10
6.1 Testbed and Methodology

Para 245 Page 10
Techniques. We have experimented with two techniques.
T
REE
S
KETCH
es. We have implemented a fully functional prototype of the T
REE
S
KETCH
framework that we describe in this paper. Throughout our experiments, the construction algorithm uses
an upper limit of
£
â
d
l'
¦
aY
operations and rebuilds the heap
when its size is reduced below
¤
â
d
l#Y
operations.
Twig-XS
KETCH
es. Twig-XS
KETCH
es [18] have been proposed as
a summarization technique for estimating the selectivity of complex twig queries. Since the original proposal focused solely on
selectivity estimation, we have developed an algorithm for producing approximate answers from a twig-XS
KETCH
The algorithm traverses the query tree and uses the distribution information of the
recorded edge histograms in order to sample the number of descendants for each element in the approximate result tree. For the
construction of twig-XS
KETCH
summaries, we have used the same
parameters that were reported in the original study [18].

Para 246 Page 10
Data Sets. We have used four data sets in our experiments: IMDB,
a real-life data set from the Internet Movie Database Project; XMark,
a synthetic data set that models transactions on a on-line auction
site; Swiss Prot, a real-life data set with annotations on proteins;
and DBLP, a real-life data set with bibliographical data. The main
characteristics of the corresponding XML documents are summarized in Table 1. The TX documents have been used in the twigXS
KETCH
study [18], and we include them here for the comparison
of T
REE
S
KETCH
es against twig-XS
KETCH
es. Looking at the sizes
of the stable summaries, we observe that count-stability is very effective in compressing, without loss, the structural information of
the original documents. Still, processing a query over so large a
summary becomes prohibitively expensive relative to the stringent
time requirements of an approximate answering system.

Para 247 Page 10
Query Workloads. For each data set, we evaluate the performance
IMDB-TX
XMark-TX
SProt-TX

Para 248 Page 10
Avg Number of
Binding Tuples
3,477
2,436
104,592

Para 249 Page 10
IMDB
XMark
SProt
DBLP

Para 250 Page 10
Avg Number of
Binding Tuples
13,039
145,577
365,493
78,784

Para 251 Page 10
Table 2: Workload characteristics

Para 252 Page 10
of the generated summaries against a workload of 1000 positive
queries, i.e., queries that have non-empty results sets. Our experiments with negative workloads have shown that T
REE
S
KETCH
es
consistently produce empty answers as approximations and we therefore omit these workloads from our presentation in the interest of
space. The workload is generated by sampling sub-trees from the
stable synopsis and converting them to twig queries. Table 2 contains the average number of binding tuples per query in the workloads that we have generated.

Para 253 Page 10
Evaluation Metrics. We quantify the accuracy of approximate an
Para 254 Page 10
swers with the ESD metric which was defined in Section 5. More
specifically, we compute the ESD between the approximate and the
true nesting tree of each query in the workload and report the average over all queries. Our implementation uses a slightly revised
version of MAC (kindly provided by Y. Ioannidis and V. Poosala)
as the underlying set-distance metric, and limits comparisons to the
binding elements of the same query variables. As always, the complete details can be found in the full paper [17].

Para 255 Page 10
For experiments on selectivity estimation, we measure the accuracy of the synopses with the average absolute relative error over
all queries in the workload. More formally, if
þ
is the true and

the estimated selectivity for a query in the workload, the absolute
relative error is defined as
{
þRÄ
{
 
ßo4
¢
¦
À

. The sanity bound
À
is
used to avoid the artificially high percentages of low-count queries.
Following common practice [16, 18], we set
À
to the 10-percentile
of true query counts.

Para 256 Page 10
6.2 Results

Para 257 Page 10
Approximate Query Answers. In this experiment, we evaluate

Para 258 Page 10
the effectiveness of our novel T
REE
S
KETCH
synopses as a practical solution for generating approximate answers to complex twig
queries. We present a comparison against the previously proposed
twig-XS
KETCH
synopses, focusing on two measures: the quality
of the generated approximate answers, and the efficiency of the
construction process.

Para 259 Page 10
Figure 11 shows the average ESD metric for approximate answers computed with T
REE
S
KETCH
es and twig-XS
KETCH
es on
a workload of 1000 twig queries, and for the XMark-TX, IMDBTX, and SwissProt-TX data sets. We note that the increased distance numbers are partly due to the underlying MAC metric, which
assigns a heavy penalty if the compared element sets contain the
same sub-tree in different multiplicities. The interpretation of the
results is therefore based on the relative performance of the two
techniques, rather than on the absolute distances. Clearly, our novel
T
REE
S
KETCH
synopses consistently produce approximate answers
of lower error. In all three data sets, the average distance for twigXS
KETCH
es is at least four times higher than the one for T
REE
S
KETCH
es, and the error for a 10KB T
REE
S
KETCH
synopsis (lowest budget) is less than the error for a 50KB twig-XS
KETCH
(highest budget). The effectiveness of T
REE
S
KETCH
es can be attributed
to our novel clustering-based summarization model, which captures very accurately the intrinsic sub-structure similarity found in
XML data. The edge-histogram model used by twig-XS
KETCH
es,
 0
 2000
 4000
 6000
 8000
 10000
 12000
 14000
 16000

Para 260 Page 11
 10  15  20  25  30  35  40  45  50
Avg. ESD

Para 261 Page 11
Synopsis Size (KB)
TreeSketches
TwigXSketches

Para 262 Page 11
 0
 2000
 4000
 6000
 8000
 10000
 12000
 14000
 16000
 18000

Para 263 Page 11
 10  15  20  25  30  35  40  45  50
Avg ESD

Para 264 Page 11
Synopsis Size (KB)
TreeSketches
TwigXSketches

Para 265 Page 11
 0
 20000
 40000
 60000
 80000
 100000
 120000

Para 266 Page 11
 10  15  20  25  30  35  40  45  50
Avg. ESD

Para 267 Page 11
Synopsis Size (KB)
TreeSketches
TwigXSketches

Para 268 Page 11
(a)
(b)
(c)

Para 269 Page 11
Figure 11: Average ESD metric for approximate answers: (a) XMark-TX, (b) IMDB-TX, (c) SwissProt-TX

Para 270 Page 11
on the other hand, can capture correlations within limited neighborhoods of synopsis nodes, while the typically high dimensionality of edge distributions affects negatively the quality of histogram
approximation.

Para 271 Page 11
In terms of construction efficiency, we present a qualitative comparison between the two techniques since the twig-XS
KETCH
code
base is not optimized for speed. The twig-XS
KETCH
construction algorithm starts from a coarse label-split graph, which contains exactly one node for all elements of the same tag, and gradually expands it through incremental refinement operations (basically, node splits, and histogram refinements). To evaluate the benefit of a candidate refinement, the algorithm measures the accuracy of the resulting twig-XS
KETCH
on a sample workload of twig
queries (workload-based evaluation). Our proposed TSB
UILD
algorithm, on the other hand, compresses the stable summary down
to the available space budget, using the squared error as a workloadindependent quality metric.

Para 272 Page 11
IMDB-TX
XMark-TX
SwissProt-TX

Para 273 Page 11
T
REE
S
KETCH
es
0.7
8
10
Twig-XS
KETCH
es
13
47
55

Para 274 Page 11
Table 3: Construction times (in minutes) for T
REE
S
KETCH
es
and twigXSKETCH
es

Para 275 Page 11
Table 3 compares the construction time for T
REE
S
KETCH
es and
twig-XS
KETCH
es for the IMDB-TX, XMark-TX, and SwissProtTX data sets. All times are reported in minutes and were measured on an unloaded Pentium4 3GHz machine, running Linux.
For T
REE
S
KETCH
synopses, we measure the time to compress the
stable summary down to the smallest summary possible, the label split graph; for twig-XS
KETCH
es, we measure the time needed
to expand the original coarse summary to 10KB of storage. This
represents a worst case scenario for T
REE
S
KETCH
es since the distance from the stable summary to the label-split graph is certainly
"longer" than the distance from the label-split-graph to 10KB. Still,
a qualitative comparison of the measured times indicates that T
REE
S
KETCH
construction is much more efficient. As we described in
Section 4.2, the TSB
UILD
algorithm uses effective heuristics to explore limited, yet promising regions of the search space, while the
squared error metric, which is workload-independent, avoids the
most expensive step of the twig-XS
KETCH
algorithm, namely evaluating the accuracy of candidate summaries against sample workloads.

Para 276 Page 11
We have also evaluated the accuracy of T
REE
S
KETCH
-generated
approximate answers for the large datasets of Table 1. The results
remain qualitatively the same as for the smaller data sets and we
omit them in the interest of space. A detailed presentation can be
found in the full version of this paper [17]. Note that we were not
able to evaluate the performance of the twig-XS
KETCH
approach
on the large data sets due to the high construction times.

Para 277 Page 11
Selectivity Estimation. In this experiment, we evaluate the ef
Para 278 Page 11
fectiveness of our proposed synopses in estimating the selectivity
of complex twig queries with branching path expressions. Figure 12 shows the average relative estimation error on a workload
of 1000 queries for T
REE
S
KETCH
es and twig-XS
KETCH
es, and
for the XMark-TX and SwissProt-TX data sets. The results for the
IMDB-TX data set are similar to XMark-TX and are omitted in the
interest of space. As in the previous experiment, the results show
that T
REE
S
KETCH
es are effective in summarizing the key properties of the underlying path distribution. We observe that the estimation error remains well below 10% for all three data sets, even for
small space budgets of 10KB-20KB that represent a small fraction
of the original document sizes. Compared to twig-XS
KETCH
es,
our new T
REE
S
KETCH
synopses produce significantly more accurate estimates and exhibit more stable behavior.

Para 279 Page 11
Figure 13 shows the T
REE
S
KETCH
estimation error over a workload of 1000 queries and for the XMark, IMDB, SwissProt, and
DBLP data sets (the large data sets of Table 1). The results verify the effectiveness of T
REE
S
KETCH
es in computing accurate selectivity estimates for complex twig queries and demonstrate their
nice scaling properties in terms of data size. In all four data sets,
the estimation error drops below 5% for a space budget of 50KB,
which in turn represents an extremely small fraction of the original
document size. At the same time, the construction times remain
affordable given the complexity and size of the involved data sets:
38 minutes for Swiss Prot, 11 minutes for DBLP, 2.5 minutes for
IMDB, while the largest XMark data set required 4 hours.

Para 280 Page 11
7. CONCLUSIONS

Para 281 Page 11
Approximate answers constitute an effective solution for offsetting the high execution cost of complex XML queries in an interactive data exploration environment. In this paper, we have initiated the study of approximate query answering for XML data. We
have proposed the T
REE
S
KETCH
synopses, a novel class of structural summaries that capture very effectively the sub-structure similarity that is commonly found in XML data sets. We have developed a systematic evaluation algorithm for computing approximate
answers over a concise T
REE
S
KETCH
summary, and we have described an efficient heuristic construction algorithm for building an
effective T
REE
S
KETCH
for a limited space budget. To quantify the
 0
 10
 20
 30
 40
 50
 60
 70
 80
 90
 100

Para 282 Page 12
 10  15  20  25  30  35  40  45  50
Avg. Rel Error (%)

Para 283 Page 12
Synopsis Size (KB)
TreeSketches
TwigXSketches

Para 284 Page 12
 0
 10
 20
 30
 40
 50
 60
 70
 80
 90
 100

Para 285 Page 12
 10  15  20  25  30  35  40  45  50
Avg. Rel Error (%)

Para 286 Page 12
Synopsis Size (KB)
TreeSketches
TwigXSketches

Para 287 Page 12
(a)
(b)
 0
 10
 20
 30
 40
 50

Para 288 Page 12
 10  15  20  25  30  35  40  45  50
Avg. Rel Error (%)

Para 289 Page 12
Synopsis Size (KB)
IMDB
XMark
SwissProt
DBLP

Para 290 Page 12
Figure 12: Average selectivity estimation error: (a) XMark-TX,
(b) SwissProt-TX.
Figure 13: T
REE
S
KETCH
estimation error on large data sets.

Para 291 Page 12
quality of the generated approximate answers, we have proposed
a novel distance metric between XML trees that avoids the shortcomings of existing graph-theoretic metrics. Experimental results
on real-life and synthetic data sets have verified the effectiveness
of our approach and have demonstrated its benefits over previously
proposed techniques.

Para 292 Page 12
8. REFERENCES

Para 293 Page 12
[1] Ashraf Aboulnaga, Alaa R. Alameldeen, and Jeffrey F.
Naughton. "Estimating the Selectivity of XML Path
Expressions for Internet Scale Applications". In Proceedings
of the 27th Intl. Conf. on Very Large Data Bases, 2001.

Para 294 Page 12
[2] P. Buneman, M. Grohe, and C. Koch. "Path Queries on
Compressed XML". In Proceedings of the 29th Intl. Conf. on
Very Large Data Bases, 2003.

Para 295 Page 12
[3] Kaushik Chakrabarti, Minos Garofalakis, Rajeev Rastogi,
and Kyuseok Shim. "Approximate Query Processing Using
Wavelets". In Proceedings of the 26th Intl. Conf. on Very
Large Data Bases, 2000.

Para 296 Page 12
[4] Don Chamberlin, James Clark, Daniela Florescu, Jonathan
Robie, J´er^ome Sim´eon, and Mugur Stefanescu. "XQuery 1.0:
An XML Query Language". W3C Working Draft, 2001.

Para 297 Page 12
[5] Zhimin Chen, H.V. Jagadish, Laks V.S. Laksmanan, and
Stelios Paparizos. "From Tree Patterns to Generalized Tree
Patterns: On Efficient Eavluation of XQuery". In
Proceedings of the 29th Intl. Conf. on Very Large Data
Bases, 2003.

Para 298 Page 12
[6] Zhiyuan Chen, H. V. Jagadish, Flip Korn, Nick Koudas,
S. Muthukrishnan, Raymond Ng, and Divesh Srivastava.
"Counting Twig Matches in a Tree". In Proceedings of the
17th Intl. Conf. on Data Engineering, 2001.

Para 299 Page 12
[7] James Clark. "XSL Transformations (XSLT), Version 1.0".
W3C Recommendation, November 1999.

Para 300 Page 12
[8] James Clark and Steve DeRose. "XML Path Language
(XPath), Version 1.0". W3C Recommendation, November
1999.

Para 301 Page 12
[9] Juliana Freire, Jayant R. Haritsa, Maya Ramanath, Prasan
Roy, and J

er

ome Sim

eon. "StatiX: Making XML Count". In
Proceedings of the 2002 ACM SIGMOD Intl. Conf. on
Management of Data, 2002.

Para 302 Page 12
[10] Yannis E. Ioannidis and Viswanath Poosala.
"Histogram-Based Approximation of Set-Valued Query
Answers". In Proceedings of the 25th Intl. Conf. on Very
Large Data Bases, 1999.
[11] Raghav Kaushik, Pradeep Shenoy, Phillip Bohannon, and
Ehud Gudes. "Exploiting Local Similarity for Efficient
Indexing of Paths in Graph Structured Data". In Proceedings
of the 18th Intl. Conf. on Data Engineering, 2002.

Para 303 Page 12
[12] L. Lim, M. Wang, S. Padmanabhan, J.S. Vitter, and R. Parr.
XPathLearner: An On-Line Self-Tuning Markov Histogram
for XML Path Selectivity Estimation. In Proceedings of the
28th Intl. Conf. on Very Large Data Bases, 2002.

Para 304 Page 12
[13] Jason McHugh and Jennifer Widom. "Query Optimization
for XML". In Proceedings of the 25th Intl. Conf. on Very
Large Data Bases, 1999.

Para 305 Page 12
[14] Tova Milo and Dan Suciu. "Index structures for Path
Expressions". In Proceedings of the 7th Intl. Conf. on
Database Theory (ICDT'99), 1999.

Para 306 Page 12
[15] N. Polyzotis and M. Garofalakis. "Statistical Synopses for
Graph Structured XML Databases". In Proceedings of the
2002 ACM SIGMOD Intl. Conf. on Management of Data,
2002.

Para 307 Page 12
[16] N. Polyzotis and M. Garofalakis. "Structure and Value
Synopses for XML Data Graphs". In Proceedings of the 28th
Intl. Conf. on Very Large Data Bases, 2002.

Para 308 Page 12
[17] Neoklis Polyzotis, Minos Garofalakis, and Yannis Ioannidis.
"Approximate XML Query Answers". University of
California Santa Cruz, Technical Report, 2004.

Para 309 Page 12
[18] Neoklis Polyzotis, Minos Garofalakis, and Yannis Ioannidis.
"Selectivity Estimation for XML Twigs". In Proceedings of
the 20th Intl. Conf. on Data Engineering, 2004.

Para 310 Page 12
[19] C. M. Procopiuc. Geometric Techniques for Clustering:
Theory and Practice. PhD thesis, Duke Univ., 2001.

Para 311 Page 12
[20] D. Sasha and K. Zhang. Fast algorithms for the unit cost
editing distance between trees. Jnl. of Algorithms, 11, 1990.

Para 312 Page 12
[21] Wei Wang, Haifeng Jiang, Hongjun Lu, and Jeffrey Xu Yu.
Containment join size estimation: Models and methods. In
Proceedings of the 2003 ACM SIGMOD Intl. Conf. on
Management of Data, 2003.

Para 313 Page 12
[22] Yuqing Wu, Jignesh M. Patel, and H.V. Jagadish. "Estimating
Answer Sizes for XML Queries". In Proceedings of the 8th
Intl. Conf. on Extending Database Technology, 2002.

Para 314 Page 12
[23] T. Zhang, R. Ramakrishnan, and M. Livny. BIRCH: An
Efficient Data Clustering Method for Very Large Databases.
In Proceedings of the 1996 ACM SIGMOD Intl. Conf. on
Management of Data, 1996.

