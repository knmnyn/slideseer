
Para 1 Page 1
Cost-Based Labeling of Groups of Mass Spectra

Para 2 Page 1
ABSTRACT

Para 3 Page 1
We make two main contributions in this paper. First, we
motivate and introduce a novel class of data mining problems that arise in labeling a group of mass spectra, specifically for analysis of atmospheric aerosols, but with natural
applications to market-basket datasets. This builds upon
other recent work in which we introduced the problem of
labeling a single spectrum, and is motivated by the advent
of a new generation of Aerosol Time-of-Flight Mass Spectrometers, which are capable of generating mass spectra for
hundreds of aerosol particles per minute. We also describe
two algorithms for group labeling, which differ considerably
in how they utilize an LP solver, and also differ considerably
from algorithms for labeling a single spectrum.

Para 4 Page 1
Our second main contribution is to show how to automatically select between these algorithms in a cost-based
manner, analogous to how a relational query optimizer selects from a space of query plans. While the details are
specific to the labeling problem, we believe that this is a
promising first step towards a general framework for costbased data mining, and opens up an important direction for
future research.

Para 5 Page 1
1. INTRODUCTION

Para 6 Page 1
The size and composition of aerosol particles, which are
often complex mixtures of organic and inorganic solids and
liquid suspended in the air, is directly related to their origin,
evolution and deposition and is intimately related to their
environmental and health effects [19]. The aerosol timeof-flight mass spectrometer (ATOFMS) [20] samples aerosol
particles directly from the ambient air or from an emission
source and obtains size and chemical composition information on one particle at a time, in real-time. It holds the
potential to fundamentally change policy and practice in environmental monitoring, but our ability to analyze the data
is a critical bottleneck. Specifically, an ATOFMS produces
a mass spectrum for each aerosol particle, and can sample
about 250 particles per minute.

Para 7 Page 1
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
Copyright 200X ACM X-XXXXX-XX-X/XX/XX ...
$
5.00.

Para 8 Page 1
A mass spectrum is a plot of signal intensity (often normalized to the largest peak in the spectrum) versus the mass-tocharge (m/z) ratio of the detected ions. Thus, the presence
of a peak indicates the presence of one or more ions containing the corresponding m/z value. A basic task is to label
a spectrum with the ions that are present in the particle,
and we studied this problem in [10], in collaboration with
a team of atmospheric chemists. In practice, however, we
are often interested in the composition of particles sampled
over some time window, rather than the composition of each
individual particle.

Para 9 Page 1
In this paper, our first contribution addresses the central problem of labeling a group of mass spectra. To a first
approximation, we treat the group as an unordered collection. The fact that these spectra are obtained from a continuously sampled stream of particles essentially allows us
to exploit some domain knowledge about the percentage of
similar spectra within a group. The labeling of mass spectra
is a first step in a more comprehensive analysis of ATOFMS
streams, and allows us to model each aerosol particle as a
collection of ions, along with a quantity for each ion. Viewed
thus, an aerosol particle is a generalization of the well-known
market basket abstraction of a collection of items purchased
at one time by a customer. While our primary focus is on
mass spectra, we briefly discuss this connection to market
basket data, which makes our results relevant for a wider
class of applications.

Para 10 Page 1
Additional steps in a typical analysis involve looking for
trends and correlations with other spatiotemporal streams,
taking into account data about ambient conditions and emission sources. Thus, labeling is just one step in a typical
multi-step analysis. Our ultimate objective is to develop
an algebraic framework for expressing such multi-step data
mining analyses, and a cost-based optimization framework
for finding good evaluation plans.

Para 11 Page 1
Our second contribution in this paper is to show how
database concepts like set-orientation and cost-based query
optimization can be applied to data mining tasks (such as labeling mass spectra using linear programming techniques).
While the details are specific to the labeling problem, we
show the benefits of a set-oriented approach to a complex
mining task, in particular, the benefits of essentially "pushing" constraints over the desired set of labels down into the
linear programming computations for identifying those labels. The cost analysis of the algorithms we propose for
group labeling clearly shows the benefits of group labeling versus labeling each spectrum in the group individually. Most importantly, it provides the basis for a cost-based
approach to selecting the most efficient algorithm. To our
knowledge, this is the first paper to describe a cost-based
framework for selecting between alternative data mining algorithms (including algorithms for machine learning problems, statistical analyses, various kinds of frequent itemset
and sequential pattern identification, etc.).

Para 12 Page 2
Research in data mining has largely concentrated on algorithms for a single task, and comparisons of performance
have been empirical in nature. Insights from database systems design can guide the development of a framework for
multi-step analyses that incorporates data mining tasks such
as clustering, decision-tree construction, or labeling. In turn,
this opens the door to a cost-based optimization framework,
and to a compositional approach to mining. We believe that
our results are a modest first step towards this goal.

Para 13 Page 2
1.1 Outline

Para 14 Page 2
The rest of the paper is structured as follows. We review
single spectrum labeling in Section 2 and then introduce
group labeling in Section 3. We propose two new algorithms
for group labeling in Section 4. In Section 5, we present a
cost analysis of these algorithms. Using this analysis as a
foundation, we propose a cost-based method for selecting the
most efficient group labeling algorithm, taking into account
the characteristics of the data and the group labeling parameters, in Section 6. In Section 7, we study the algorithm
selection method experimentally, and show its effectiveness.
In Section 8, we discuss the connections between spectrum
labeling and market basket analysis. We survey related work
in Section 9.

Para 15 Page 2
2. SPECTRUM LABELING

Para 16 Page 2
In this section, we review the problem of labeling a single
mass spectrum, introduced in [10], to keep this paper selfcontained. The formalization of the group labeling problem,
presented in the next section, builds upon the single spectrum case.

Para 17 Page 2
2.1 Preliminaries

Para 18 Page 2
A mass spectrum can be represented as a normalized

Para 19 Page 2
vector b,
P
i
b
i
= 1. b
i
 R is the relative signal intensity at
m/z value i.

Para 20 Page 2
The signature of an ion is a vector s, s
i
 R and
P

Para 21 Page 2
i

Para 22 Page 2
s
i
= 1, representing the distribution of its isotopes, i.e.,
s

Para 23 Page 2
i

Para 24 Page 2
is the relative abundance of isotopes with m/z value i.

Para 25 Page 2
A signature database is
a
set
of
signatures
S = {s
1
, s
2
, ..., s
n
} where s
j
is the signature of chemical
element j. All the spectra and signatures have the same
`range' and `granularity' over m/z axis; i.e., they have the
same dimension and the i
th
element of a spectrum or signature always corresponds to the same m/z value i.

Para 26 Page 2
The task of spectrum labeling is to find the chemical
ions identified by the peaks in the spectrum and, ideally,
their quantities in the particle. If we arrange the n signatures in the signature database in some order, the signature
database can be represented as a matrix A = [s
1
, s
2
, ..., s
n
],
where the k
th
column in matrix A represents signature k.
The labeling task consists of finding an n-dimensional vector x such that x[j] is the relative abundance of chemical
element j. This is equivalent to solving the linear equation

Para 27 Page 2
Ax = b, x  0.
(1)
2.2 An Optimization-Based Reformulation

Para 28 Page 2
2.2.1 Error Bound

Para 29 Page 2
In real applications, the observed spectrum usually contains noise and calibration discrepancies, and cannot be described as an exact linear combination of ion signatures. Labeling therefore involves finding a linear combination of ion
signatures that approximately matches the input spectrum.
Therefore, we introduce an error bound E with respect to a
certain distance function D. The linear equation model (1)
then becomes an optimization task:

Para 30 Page 2
Seek
a,
s.t.
D(Aa, b) &lt; E,
a  0
(2)

Para 31 Page 2
Given a signature database A that contains n signatures,

Para 32 Page 2
and an input spectrum b, the search space for the optimization task defined in (2) is an n-dimensional continuous space.

Para 33 Page 2
The solution space for input b is a subspace within this
search space.

Para 34 Page 2
Definition 1. Given a signature database A, an input spec
Para 35 Page 2
trum b, and an error bound E with respect to distance func
Para 36 Page 2
tion D, the solution space of spectrum b,

Para 37 Page 2
L
b
= {a | D(Aa, b) &lt; E and a  0}

Para 38 Page 2
It is worth noticing that the choice of the distance function D in (2) could dramatically change the complexity
of the problem [10].
Using Manhattan distance, namely
D(v
1
, v
2
) =
P
i
|v
1
[i] - v
2
[i]|, the optimization task of (2)
can be interpreted as a linear programming task [10] whose
time complexity is polynomial in the total number of signatures in the signature database. Other distance functions
can be useful in certain situations, for example, to spread
errors over fewer dimensions. However, considering other
distance functions is outside the scope of this paper, and we
will henceforth assume that Manhattan distance is used.

Para 39 Page 2
2.2.2 Optimization Model

Para 40 Page 2
In [10], we have shown that the optimization task defined
in (2) will have an infinite number of solutions for most
input spectra. Fortunately, in practice, we only care about
those solutions that are significantly different. A natural
approach to deal with the infinity in a continuous space is
to discretize it into grids, so that the number of possible
solutions is finite.

Para 41 Page 2
Formally, a discretization is specified by a threshold vector t = [t
1
, t
2
, ...t
d
+1
] divides each dimension
of
the
search
space into d ranges: [t
1
, t
2
), [t
2
, t
3
)...[t
d
, t
d
+ 1),
where t
i
and t
i
+1
are the lower bound and upper bound of
range i. A cell is the finest granularity of the discretization,
which characterizes the degree of detail users care about.
Given a discretization that divides each dimension into d
ranges, the whole search space is discretized into d
n
cells
,
where n is the number of dimensions. (Recall that n is the
number of signatures in the signature database.)

Para 42 Page 2
A label of spectrum b is simply a cell that intersects b's
solution space. It can be represented as a vector of integers
x, s.t. x[i] indicates the range it falls into on dimension

Para 43 Page 2
i.

Para 44 Page 2
1
The set of all cells intersecting b's solution space forms

Para 45 Page 2
the label set of spectrum b. We use the term feasible

Para 46 Page 2
1

Para 47 Page 2
This is defined rigorously using the notion of an index
vector in [10].
subspace to describe any subspace of the search space that
intersects the solution space.

Para 48 Page 3
Figure 1 illustrates the concepts discussed in this section.
Suppose there are two signatures in the signature database.
The threshold vector t = [0, 0.3, 0.6, 1] divides each dimension into three ranges indexed by 0, 1, and 2. The search
space is a two-dimensional space ABCD. S
1
S
2
S
3
S
4
is the
solution space of an example input spectrum, which intersects the cells LF GM and M GHA. So, cells LF GM and
M GHA, which can be represented as vectors [0, 1] and [0, 2],
are labels of the input spectrum. Subspace ALF H intersects
the solution space, so it is a feasible subspace. M BEG is
also a feasible subspace.

Para 49 Page 3
 ¡ ¡ ¡ ¡ ¡ ¡ 
 ¡ ¡ ¡ ¡ ¡ ¡ 
 ¡ ¡ ¡ ¡ ¡ ¡ 
 ¡ ¡ ¡ ¡ ¡ ¡ 
 ¡ ¡ ¡ ¡ ¡ ¡ 
 ¡ ¡ ¡ ¡ ¡ ¡ 

Para 50 Page 3
¢¡¢¡¢¡¢¡¢¡¢¡¢
¢¡¢¡¢¡¢¡¢¡¢¡¢
¢¡¢¡¢¡¢¡¢¡¢¡¢
¢¡¢¡¢¡¢¡¢¡¢¡¢
¢¡¢¡¢¡¢¡¢¡¢¡¢
¢¡¢¡¢¡¢¡¢¡¢¡¢
£¡£¡£¡£¡£¡£¡£
£¡£¡£¡£¡£¡£¡£
£¡£¡£¡£¡£¡£¡£
£¡£¡£¡£¡£¡£¡£
£¡£¡£¡£¡£¡£¡£

Para 51 Page 3
¤¡¤¡¤¡¤¡¤¡¤¡¤
¤¡¤¡¤¡¤¡¤¡¤¡¤
¤¡¤¡¤¡¤¡¤¡¤¡¤
¤¡¤¡¤¡¤¡¤¡¤¡¤
¤¡¤¡¤¡¤¡¤¡¤¡¤

Para 52 Page 3
B
¥¡¥¡¥¡¥¡¥¡¥
¥¡¥¡¥¡¥¡¥¡¥
¦¡¦¡¦¡¦¡¦¡¦
¦¡¦¡¦¡¦¡¦¡¦
§¡§¡§¡§¡§
§¡§¡§¡§¡§
§¡§¡§¡§¡§
§¡§¡§¡§¡§
§¡§¡§¡§¡§
§¡§¡§¡§¡§
§¡§¡§¡§¡§
§¡§¡§¡§¡§
§¡§¡§¡§¡§
§¡§¡§¡§¡§
§¡§¡§¡§¡§

Para 53 Page 3
¨¡¨¡¨¡¨¡¨
¨¡¨¡¨¡¨¡¨
¨¡¨¡¨¡¨¡¨
¨¡¨¡¨¡¨¡¨
¨¡¨¡¨¡¨¡¨
¨¡¨¡¨¡¨¡¨
¨¡¨¡¨¡¨¡¨
¨¡¨¡¨¡¨¡¨
¨¡¨¡¨¡¨¡¨
¨¡¨¡¨¡¨¡¨
¨¡¨¡¨¡¨¡¨

Para 54 Page 3
cell
space
solution 
Label

Para 55 Page 3
L
M

Para 56 Page 3
0.3
0.6
1

Para 57 Page 3
0.3
0.6
1
0
F
H

Para 58 Page 3
E
C
D
A

Para 59 Page 3
G
S1

Para 60 Page 3
©¡©¡©¡©¡©¡©
©¡©¡©¡©¡©¡©
©¡©¡©¡©¡©¡©
¡¡¡¡¡
¡¡¡¡¡
¡¡¡¡¡
S3
S2
S4

Para 61 Page 3
Figure 1: Illustration of Concepts

Para 62 Page 3
Given an error bound E with respect to a distance function D and a discretization, we now redefine the task of
spectrum labeling as follows:
Find all cells that intersect the solution space of the input spectrum.

Para 63 Page 3
Table 1 summarizes the notations used in this paper and
provides an operational optimization model for the labeling
task that we just described.

Para 64 Page 3
Notation:
x
A n dimensional vector of integers
, 1  x[i]  d.

Para 65 Page 3
b
Input mass spectrum

Para 66 Page 3
t
Threshold vector for discretization
d
Number of ranges per dimension
under discretization
L
Label set of input spectrum
A
Signature database
D
Distance function
E
Error bound

Para 67 Page 3
L=

Para 68 Page 3
For every possible x, 1  x[i]  d
Seek a s.t.

Para 69 Page 3
D(Aa, b)  E
(3)
t[j]  a[i] &lt; t[j + 1], j = x[i]
If (3) succeeds, L = L  x

Para 70 Page 3
Return L

Para 71 Page 3
Table 1: Operational Definition of Spectrum Labeling

Para 72 Page 3
3. GROUP LABELING

Para 73 Page 3
In this section, we introduce the problem of labeling a
group of spectra. In environmental monitoring, the spectra are collected through continuous sampling, and a group
that is collected at a single location over a short time-span is
likely to contain many similar spectra (because the environment does not change instantaneously). Thus, the goal is to
find these common, or typical, spectra.
2
Indeed, this is the
goal even when the group does not reflect particles from the
same location and time; e.g., when analyzing a collection of
spectra obtained at multiple locations and times but with
some commonalities in ambient conditions.

Para 74 Page 3
Given a group of spectra {b
i
}, we can conceptually
3
compute a set of label sets {L
i
}, where L
i
= {
x
ij
} is the label

Para 75 Page 3
set of b
i
. We define the support of a label x with respect

Para 76 Page 3
to the group of spectra {b
i
} as the percentage of b
i
s whose
corresponding label set contains x.

Para 77 Page 3
Definition 2. Given a group of spectra {b}, the support

Para 78 Page 3
of a label x =
|{L
i
|xL
i
}|
|{L
i
}|
, where L
i
= {
x
ij
} is the label set

Para 79 Page 3
of spectrum b
i
.

Para 80 Page 3
Intuitively, the support characterizes the likelihood of a
label given a group of similar spectra. Extending the concept
of `label' and `label set' discussed in Section 2.2, we define
group label and group label set as follows:

Para 81 Page 3
Definition 3. Given a group of spectra B = {b
i
} and a
threshold M in Sup, x is a group label if the support of x
w.r.t. B is greater than M in Sup. The group label set
for the group B is GL = {x|x is a group label of B}.

Para 82 Page 3
As an example, consider a group of spectra {b
1
, b
2
, b
3
}.

Para 83 Page 3
Let the label set for b
1
be {x
1
, x
2
}, the label set for b
2
be

Para 84 Page 3
{x

Para 85 Page 3
2

Para 86 Page 3
}, and the label set for b
3
be {x
3
}. Then, support(x
1
) =
support(x
3
) = 33%, support(x
2
) = 66%. Suppose the M in Sup
threshold is set to be 50%, then x
2
is the only group label.
The group label set is therefore {x
2
}.

Para 87 Page 3
Spectral labeling is important in many domains other than
environmental monitoring because mass spectra are a widely
used tool for chemical and biological analysis. Surprisingly,
the concepts also show promise for analyzing market-basket
data; we discuss this briefly in Section 8.

Para 88 Page 3
4. SEARCH FOR GROUP LABELS

Para 89 Page 3
In this section, we first review a depth-first search algorithm introduced in [10] for single spectrum labeling, based
on which we propose two new algorithms for group labeling.
When we go from labeling a single spectrum to a large group
of spectra, the problem is fundamentally altered by the notion of support. The new Depth First Search with Voting
(DFSVoting) and Candidate Generation and Test(GenTest)
algorithms for group labeling differ significantly in how they
handle support.

Para 90 Page 3
4.1 Basic Depth First Search Algorithm

Para 91 Page 3
If a subspace is not feasible, then we do not need to consider any cell in that subspace. The basic depth-first single
spectrum labeling algorithm utilizes this property to prune
the search space. Table 2 shows the operational procedure
which invokes an LP call to test whether a given subspace
is feasible.

Para 92 Page 3
2

Para 93 Page 3
A related task is to find common ions across the group of
spectra. Further, we often have domain knowledge that can
be expressed in terms of constraints over the composition of
the particles in the group. These extensions are important
directions for future research, but outside the scope of this
paper.

Para 94 Page 3
3

Para 95 Page 3
Computing all label sets is inefficient, and the group labeling algorithms that we propose avoid this.

Para 96 Page 4
Given :
Input spectrum b

Para 97 Page 4
Threshold vector t
Error bound E

Para 98 Page 4
is feasible(subspace S)

Para 99 Page 4
Seek a, s.t.

Para 100 Page 4
D(Aa, b)  E
(*)

Para 101 Page 4
t[l
i
]  a[i] &lt; t[h
i
]
t[l
i
] and t[h
i
] are the boundary of S in dimension i

Para 102 Page 4
if (*) succeeds, return TRUE, otherwise return FALSE

Para 103 Page 4
Table 2: Testing the Feasibility of a Subspace

Para 104 Page 4
The basic depth-first single spectrum labeling algorithm is
shown in Table 3, and uses a divide-and-conquer approach.
Its exploration of the search space can be mapped to a search
tree. Each node in the search tree is associated with a unique
subspace.

Para 105 Page 4
At each node, the algorithm first invokes a linear programming (LP) call to check if the subspace is feasible. If
the subspace is not feasible, the subtree is pruned and not
explored. Otherwise, we know there are one or more labels in the subspace, and we must search inside that subspace. To do this, we select a dimension j that has not been
subdivided to the finest possible granurality, and use it to
split the subspace into smaller spaces, each of which has
the finest possible granurality in dimension j. Each smaller
space created thus corresponds to a new search node is, and
is explored recursively.

Para 106 Page 4
The above procedure is repeated until either (1) the current subspace is not feasible, or (2) the current subspace is a
cell. In the former case, we discard the current search node
and backtrack. In the latter case, the label corresponding
to this cell is output by the algorithm.

Para 107 Page 4
Given :
Input spectrum b

Para 108 Page 4
Threshold vector t = [t
1
, t
2
, . . . , t
d
+1
]
Error bound E

Para 109 Page 4
Output:
Label set for b

Para 110 Page 4
Depth First Search(subspace S)
if (is feasible(S))
RETURN
else
if (S is a cell)
output the corresponding label of S
else
pick dimension(j)
split S into a set of subspacesS
i
s.t. Each S
i
is not divisible on dimension j
for each result subspace S
i
Depth First Search(S
i
)

Para 111 Page 4
Main: Depth First Search(the whole search space W )

Para 112 Page 4
Table 3: Algorithm for Single Spectrum Labeling

Para 113 Page 4
In Table 2, the method pick dimension(j) chooses the
dimension to split. We use a simple scheme in which (k+1)
th

Para 114 Page 4
dimension is chosen as the split dimension at level k of the
recursion, assuming the search starts from level 0.
4

Para 115 Page 4
4

Para 116 Page 4
Different strategies for choosing the dimension to split are
studied in [10].
4.2 Depth-First Search Voting Algorithm

Para 117 Page 4
In group labeling, a subspace is `feasible' (i.e., worth further exploration) only when it intersects the solution spaces
of at least a certain minimum number of spectra. Following this intuition, we derive the DFSVoting group labeling
algorithm (shown in Table 4) from the depth-first single
spectrum labeling algorithm by changing the definition of
`feasible'.

Para 118 Page 4
At each search node, we take a vote among the spectra in
the group. A spectrum votes yes at a node if the subspace
corresponding to the node is feasible for the spectrum; otherwise it votes no. When the number of yes votes exceeds
the minimum number required by the support theshold, the
algorithm goes on to search the children of the current node
in depth-first order. Otherwise, the subspace at the current
node is pruned, and the algorithm backtracks to the parent
node.

Para 119 Page 4
Consider an example of group labeling, with two signatures in the database and with two spectra in the group,
and the threshold vector for discretization set to be t =
[0, 0.3, 0.6, 1]. Suppose that the label sets for the two spectra are {x
1
, x
2
, x
3
} and {x
1
, x
2
, x
4
} respectively, in which
x

Para 120 Page 4
1

Para 121 Page 4
= [0, 1], x
2
= [0, 2], x
3
= [0, 0] and x
4
= [1, 2].

Para 122 Page 4
Figure 2 illustrates the execution of the DFSVoting algorithm. The shadow area in each search node represents the
subspace investigated. Beside each search node, we show
the set of spectra that vote yes for the subspace, and the
order in which nodes are visited. The edge connecting two
search nodes is tagged by the additional constraint introduced when going from the parent to its child.

Para 123 Page 4
Input :
Set of Spectra B, |B| = w

Para 124 Page 4
Threshold vector t = [t
1
, t
2
, . . . , t
d
+1
]
Error bound E
Support threshold M in Sup

Para 125 Page 4
Output:
Group label set for B

Para 126 Page 4
DFSVoting(Subspace S, Set of Spectra C)

Para 127 Page 4
C = {b|b  C, S is feasible w.r.t. b}

Para 128 Page 4
if |C |  M in sup  w
RETURN

Para 129 Page 4
else
if (S is a cell)
output the corresponding label of S
else
pick dimension(j)
split S into a set of subspaces S
i
s.t each S
i
is not divisable on dimension j
for each result subspace S
i
DFSVoting(S
i
, C )

Para 130 Page 4
Main : DFSVoting(The whole search space W , B)

Para 131 Page 4
Table 4: Algorithm DFSVoting for Group Labeling

Para 132 Page 4
The following theorem establishes the correctness of DFSVoting. The proof is omitted for lack of space.

Para 133 Page 4
Theorem
1. Given a group of spectra and a specified
minimum support, the DFSVoting algorithm finds the complete group label set without duplication.

Para 134 Page 4
4.3 Candidate Generation and Test Algorithm

Para 135 Page 4
The Candidate Generation and Test (GenTest) algorithm
0&lt;=a1 &lt; 0.3
0.3 &lt;=a1 &lt; 0.6
0.6 &lt;= a1 &lt; 1

Para 136 Page 5
0 &lt;= a2 &lt; 0.3
0.3 &lt;=a2 &lt; 0.6
0.6 &lt;= a2 &lt; 1
1

Para 137 Page 5
feasible cells (labels)
Infeasible subspaces
{1,2}

Para 138 Page 5
{1}
3
{1,2}
4
{1,2}
5
2
{1,2}
6
{2}
{}
7

Para 139 Page 5
Figure 2: An Example of the DFSVoting Algorithm

Para 140 Page 5
uses the depth-first algorithm for single spectrum labeling
as a building block. It is based on the following observation:

Para 141 Page 5
Lemma
1. Suppose that we are given a support threshold
M in Sup, a set of spectra B, |B| = w, and a subset S, S 
B, |S| = (1 - M in Sup)  w + 1 . Then, l is a group label

Para 142 Page 5
 b  S, s.t. l is a label of b.

Para 143 Page 5
The above lemma essentially uses a pigeon-hole argument
to establish that labels with a given level of support can only
be missing in a certain (hopefully small, for high support)
number of spectra. In particular, such a label must appear
in the labels for some spectrum in set S if we pick |S| =

Para 144 Page 5
(1 - M in Sup)  w + 1 . Thus, the union of the label sets
of spectra in such a set S contains all group labels for B.

Para 145 Page 5
The GenTest algorithm shown in Table 5 consists of two
phases: (1) Select a group S with (1 - M in Sup) × w + 1
spectra from B and calculate the label set for each of them.
This generates a set of candidates group labels. (2) For
each candidate group label, test whether it is a label for
each spectrum in B - S. If a candidate label appears in the
label set of at least w × M in Sup spectra, it is output as
a group label for B.

Para 146 Page 5
The following theorem establishes the correctness of GenTest.

Para 147 Page 5
Theorem
2. Given a group of spectra and a specified
minimum support, the GenTest algorithm finds the complete
group label set without duplication.

Para 148 Page 5
We observe that both algorithms are highly parallelizable.
DFSVoting is also non-blocking, in contrast to GenTest, in
which the testing phase is blocked until the candidate generation phase is complete. A more detailed analysis that
compares the cost of the two algorithms is presented in the
next section.

Para 149 Page 5
5. COST ANALYSIS

Para 150 Page 5
The goal of our analysis is to estimate the effect of various
inputs on the overall cost of each algorithm, and more importantly, to determine the relationship between algorithm
cost and the characteristics of the data. Ultimately, we want
to be able to select the less expensive algorithm for any instance of the problem by using these cost estimates.

Para 151 Page 5
In what follows, we will use the notation in Table 6.
Input :
Set of Spectra B, |B| = w

Para 152 Page 5
Threshold vector t = [t
1
, t
2
, . . . , t
d
+1
]
Error bound E
Support threshold M in Sup
Output:
Group label set for B
GenTest
L = 
B
0
= { (1 - M in Sup)  w + 1 spectra
randomly choosen from B}

Para 153 Page 5
for each b in B
0
find F
i
, the label set of b
for each label l  F
i
l.count + +
L = L  F
i
for each spectrum b  B - B
0
for each l  L

Para 154 Page 5
if l is a label for the b
l.count + +;
for each label l  L
if (l.count &gt; M in Sup  w)
output l as a solution

Para 155 Page 5
Table 5: Algorithm GenTest for Group Labeling

Para 156 Page 5
Notation
Meaning

Para 157 Page 5
n
Number of element signatures in the
database
d
Number of ranges per dimension
under discretization
m
Number of labels for a particular
spectrum
w
Size of the group of spectra
s
Conceptual number of identical spectra
within the group
M in Sup
Minimum support threshold for
group labeling
C
Single
Cost of labeling a single spectrum
C
V oting
Cost of DFSVoting algorithm
C
GenT est
Cost of GenTest algorithm

Para 158 Page 5
Table 6: Notation for Cost Analysis

Para 159 Page 5
5.1 Cost Metric

Para 160 Page 5
The proposed algorithms call an LP solver to determine
whether a subspace is feasible or not. The exact cost of
an LP call depends on the initial point and the constraints.
When more sophisticated optimization is used, the cost of
a particular LP call may also depend on the previous linear
programming tasks performed [18]. Fortunately, the cost of
one LP call is polynomial in the number of signatures in
the database [18] and both DFSVoting and GenTest tend
to have similar gains when given additional constraints and
similar input spectra. Therefore, the number of LP calls
incurred is a good cost metric, at least for comparing the two
algorithms. In addition, this abstraction makes our analysis
applicable to other depth-first search algorithms that invoke
expensive subcomputations at each node.

Para 161 Page 5
5.2 Cost of Labeling One Spectrum

Para 162 Page 5
The depth-first single spectrum labeling algorithm takes
a spectrum as input and outputs its label set. The search
space corresponds to a complete tree, as shown in Figure 3.
. . . . . .
level 0

Para 163 Page 6
level 1

Para 164 Page 6
level k

Para 165 Page 6
level n
(leaf level)
 . . . . . .
 . . . . . .
 . . . . . .

Para 166 Page 6
 . . . . . .
 . . . . . .

Para 167 Page 6
Figure 3: A Complete Search Tree

Para 168 Page 6
Each leaf node corresponds to a cell in the space. The tree
is traversed in a top-down fashion. At each non-leaf node
visited, we invoke an LP call to see if it has in its subtree
a leaf node corresponding to a label. If there is such a leaf
node, all the children of the subtree are visited, otherwise,
the algorithm will prune that subtree. We can think of the
algorithm as a node coloring game.

Para 169 Page 6
Given a complete tree of n + 1 levels, a painter

Para 170 Page 6
randomly drops
m black balls on the leaf nodes
and colors the non-leaf nodes as follows: If a
non-leaf node has a black ball in its subtree, paint
it black; otherwise, leave it white.

Para 171 Page 6
The painter corresponds to the input spectrum. The number of black balls is the number of labels for that spectrum.
The complete tree with n+1 levels corresponds to the entire
search space of the depth-first algorithm, and each leaf node
with a black ball is a label. A non-leaf node is black if its
corresponding subspace is feasible.

Para 172 Page 6
Lemma
2. Given a spectrum b and a discretization criterion that divides each dimension of the search space into d
ranges, if the corresponding node coloring game ends with
n

Para 173 Page 6
b

Para 174 Page 6
black non-leaf nodes, the number of LP calls invoked by

Para 175 Page 6
the depth-first algorithm in Table 3 to label spectrum b is:

Para 176 Page 6
C
single
= n
b
 d + 1
(4)

Para 177 Page 6
Proof.
In the node coloring game, a non-leaf node is
black if it corresponds to a feasible subspace. Black nodes
are those that invoke one LP call for each of their children.
Since each black node invokes an LP call for each of its
children and one LP call is performed at the root node, the
total number of LP calls invoked is n
b
 d + 1.

Para 178 Page 6
In transforming the single spectrum labeling problem to a
node coloring game, we deliberately made a random drop
assumption: A label of a spectrum is randomly and uniformly assigned to a cell in the search space.

Para 179 Page 6
This assumption actually allows duplicates among the m
labels for a spectrum, which is not the case for our labeling
algorithm. However, the number of labels m is much smaller
than the total number of cells d
n
. Therefore, the difference
due to duplicates is negligible.

Para 180 Page 6
In reality, the uniform distribution assumption is also violated. The labels are not spread out in the space without
any constraints. They all intersect the solution space of the
input spectrum, which is a convex hull [10]. In other words,
they are close to each other in the space. Nonethless, these
simplifications allow us to derive cost formulae that track
actual performance very well, as we show empirically in Section 7.

Para 181 Page 6
Given the `node coloring game' model, to estimate cost,
we have to estimate the number of black non-leaf nodes.
In order to estimate the total number of black nodes after
playing the game, we first estimate the probability that a
particular non-leaf node is painted black.

Para 182 Page 6
Lemma
3. In the node coloring game, if the painter has
m balls, the probability that a non-leaf node at level k is
colored black is:

Para 183 Page 6
P (k) = 1 ,,1- 1d

Para 184 Page 6
k
«
m
(5)

Para 185 Page 6
Proof.
At a particular level k, there are d
k
nodes. So,
for a particular non-leaf node N at level k the probability
that a particular black ball is in the subtree of N is
1
d
k
.

Para 186 Page 6
1 1
d
k
then gives the probability that a particular black
ball is not in the subtree of N . Since each ball is dropped
independently, the probability that all m black balls are not
in N 's subtree is
`11
d
k
´
m
. Hence, 1 `11
d
k
´
m
gives us
the probability that node N at level k has a black ball in
its subtree. In other words, the probability that a painter
colors a node black at level k is:

Para 187 Page 6
P (k) = 1 ,,1- 1d

Para 188 Page 6
k
«
m

Para 189 Page 6
Given the function P in Lemma 3, we can estimate the
number of black nodes at level k, and in turn, the overall
number of LP calls invoked by the depth-first algorithm for
labeling a single spectrum.

Para 190 Page 6
Theorem
3. Given a signature database with n signatures and a threshold vector t that divides each dimension
of the search space into d ranges, under the random drop
assumption, the expected number of LP calls invoked by the
depth-first algorithm shown in Table 3 to label a single spectrum with m labels is:

Para 191 Page 6
C
Single
= d 
 
n
-1
X

Para 192 Page 6
k
=0
d
k

,,1-,,1- 1d

Para 193 Page 6
k
«
m
«!+1 (6)

Para 194 Page 6
Proof.
The spectrum labeling process is equivalent to
the node coloring game. The complete search tree as shown
in Figure 3 has n levels (counting from 0). Each non-leaf
node has d children. For each level k, there are d
k
equivalent
nodes. According to Lemma 3, the probability of a non-leaf
at level k being black is P(k), so the average number of
black nodes at level k is d
k
 P (k). Adding up the number
of black nodes at each non-leaf level gives us the number
of black nodes in the tree:
P
n
-1
k
=0
d
k
 P (k). Combining
the result of Lemma 2, we have the total number of LP
calls invoked by the basic depth first search algorithm as:
C

Para 195 Page 6
Single
= d 
`P
n
-1
k
=1
d
k
 P (k)
´+1. Replacing P(k) with

Para 196 Page 6
the formula given in Lemma 3 leads to the formula (6) stated
in this theorem.

Para 197 Page 6
When k is large, P (k) is reduced to
m
d
k
and formula (6) is
approximately equivalent to:

Para 198 Page 6
C
Single
 d  (n - 1)  m
(7)

Para 199 Page 6
This suggests that the number of LP calls invoked by the
algorithm is linear in the number of labels for the input spectrum.
5.3 Cost of Group Labeling

Para 200 Page 7
When we go from single spectrum labeling to labeling a
group of spectra, the analysis is complicated further by the
fact that data distribution has a significant impact on performance. In this subsection, we first propose a simple model
to characterize data distribution, and then analyze the cost
of the two group labeling algorithms. Our analysis of the
relationship between data distribution and algorithm cost,
leads to the discussion of cost-based algorithm selection in
Section 6.

Para 201 Page 7
5.3.1 A Model of Data Distribution

Para 202 Page 7
As discussed in Section 3, the majority of spectra in groups
that we want to label tend to be very similar to each other.
A simplified way to model this is that most spectra in a group
are identical, while the rest are random noise or `impurities'
with great variance. Following this intuition, we model a
group of w spectra as s identical spectra mixed with w - s
random `noise' spectra which are greatly different from each
other.

Para 203 Page 7
While this is an overly simplified model of the data, note
that the number of identical spectra s is just a conceptual
parameter which describes the `diversity'(or `variance') of
the data.
Of course, more complicated statistical tools,
such as Chi-Square testing [4] and other deviation detection
and characterization methods [2] can be adopted for characterizing the data. The simple model we propose, however,
suffices for a cost analysis aimed at estimating the relative
performance of DFSVoting and GenTest.

Para 204 Page 7
5.3.2 DFSVoting

Para 205 Page 7
The DFSVoting algorithm proposed in Section 4 is a direct extension of the depth-first algorithm for single spectrum labeling. All the analysis for the single spectrum case
still holds, with the difference that we now have a group of
painters voting for the color of a non-leaf node.

Para 206 Page 7
According to the notation in Table 6, we have a group
of w spectra, within which s spectra are the same. The
group labeling algorithm will look for all the labels that are
common to at least t = w  M in Sup spectra. We again
assume each spectrum has m labels.
5
The node coloring
game for single spectrum labeling then becomes the group
node coloring game described below.

Para 207 Page 7
There are w painters in the game, and each has
m black balls. They randomly drop the balls onto
the leaf nodes. For a particular node N , a painter
votes yes if at least one of his black balls is in
N 's subtree. A node is painted black if at least
t = w  M in Sup painters vote yes.

Para 208 Page 7
As described in Section 4, if a node has v votes (v  t),
it is painted black and v LP calls are issued for each of its
children; otherwise, the node is `white', and is pruned. In
addition, the root node requires w LP calls. The cost of
DFSVoting is therefore:

Para 209 Page 7
C
V oting
= w + d  #V otes got by all black nodes
(8)

Para 210 Page 7
Lemma
4. In the group node coloring game, if there w
painters independently vote for the color of the nodes, the

Para 211 Page 7
5

Para 212 Page 7
This is a strong assumption. If spectra differ a lot, the size
of label sets may vary greatly. However, when the majority
of spectra are similar, this is a reasonable simplification.
probability that a particular node at level k receives v votes
is:

Para 213 Page 7
P V ote(v, w) = C
v
w
 P (k)
v
 (1 - P (k))
w
-v
(9)

Para 214 Page 7
Proof.
As shown in Theorem 3, for a non-leaf node at
level k, the probability that a painter drops at least one
black ball in N 's subtree is P (k). Thus, with a probability
P (k), node N will get a vote from a particular painter. Since
all the painters make independent decisions, given a group
of w painters, the probability that node N receives v votes
is:

Para 215 Page 7
P V ote(v, w) = C
v
w
 P (k)
v
 (1 - P (k))
w
-v

Para 216 Page 7
Lemma 4 studies the situation when painters make decisions independently. We now extend it to the case when
some of them always make the same decision, and in turn
estimate the number of LP calls invoked by a particular
node.

Para 217 Page 7
Lemma
5. Following the notation in Table 6, let t = w 
M in Sup . Given a group of w spectra of which s are identical, under the random drop assumption the expected number
of LP calls invoked at a particular non-leaf node at level k
in the search tree is:

Para 218 Page 7
N odeCost(k) = P (k)

Para 219 Page 7
"P
w
v
=max(t,s)
C
v
-s
w
-s
P (k)
v
-s
(1 - P (k))
w
-v
 d  v
"+

Para 220 Page 7
(1 - P (k)) 
`P
w
-s
v
=t
C
v
w
-s
P (k)
v
(1 - P (k))
w
-s-v
 d  v
´(10)

Para 221 Page 7
Proof.
When there are s identical spectra in the group
of w spectra, the DFSVoting algorithm described in Section
4 will act as if s painters out of w are `identical' (making
exactly the same decision all the time), which means a node
will either get all the votes of those s painters or lose all their
votes. Apart from the s identical painters, the remaining
painters still vote independently, as before. According to
Lemma 4, the probability that node N receives v
1
votes
from the remaining w - s painters is P V ote(v
1
, w - s). If s
identical painters all vote for node N , then the probability of
node N receiving v (w  v  s) votes is P V ote(v - s, w - s).
If (and only if) a node receives v votes, v  t, we invoke v LP
calls for each of its d children. Thus, the expected number
of LP calls invoked at node N under the precondition that
s identical painters all vote for N is:

Para 222 Page 7
E
yes
=
w
X

Para 223 Page 7
v
=max(t,s)
P V ote(v - s, w - s)  d  v
(11)

Para 224 Page 7
Similarly, the expected number of LP calls invoked by
node N under the precondition that s identical painters all
vote no at node N is:

Para 225 Page 7
E
no
=
w
-s
X

Para 226 Page 7
v
=t
P V ote(v, w - s)  d  v
(12)

Para 227 Page 7
Since s identical painters act alike, they vote yes at node
N with probability P (k), and vote no with probability 1 P (k). Combining this with formula (11) and formula (12),
we arrive at the overall estimated number of LP calls invoked
at node N : P (k)  E
yes
+ (1 - P (k))  E
no
, which is the same
as formula 10 given in this theorem.

Para 228 Page 8
This leads us to the formula estimating the overall cost of
the DFSVoting algorithm.

Para 229 Page 8
Theorem
4. Assume there are w spectra in the group,
each of which has m solutions, and that s of them are identical. Under the random drop assumption, given a signature
data base of n signatures, and a discretization that divides
each dimension of the search space into d ranges, the expected number of LP calls in the DFSVoting algorithm is:

Para 230 Page 8
C
V oting
= w +
n
-1
X

Para 231 Page 8
k
=0
d
k
 N odeCost(k)
(13)

Para 232 Page 8
.

Para 233 Page 8
Proof.
Given a signature database of n signatures, the
search tree of DFSVoting has n levels. There are d
k
equivalent nodes at level k. According to Lemma 5, a particular node at level k will invoke N odeCost(k) LP calls. So
the expected number of LP calls invoked at level k is d
k

N odeCost(k). Adding the LP calls invoked at each non-leaf
level plus the w LP calls at the root gives us an estimate
of the total number of LP calls invoked by the algorithm:
C

Para 234 Page 8
V oting
= w +
P
n
-1
k
=0
d
k
 N odeCost(k).

Para 235 Page 8
5.3.3 GenTest

Para 236 Page 8
Theorem
5. Suppose that randomly selected spectra from
a group follow the same data distribution as the group. Following the notation in Table 6, if we are given a signature
database of n signatures, and a discretization that divides
each dimension of the search space into d ranges, under the
random drop assumption the expected number of LP calls
invoked by the GenTest algorithm is:

Para 237 Page 8
C
GenT est
 d  (n - 1)  m  (w - t + 1)+
`(w-t+1)(1s
w
) + 1
´m(t-1),
(14)

Para 238 Page 8
where t = w  M in Sup .

Para 239 Page 8
Proof.
The GenTest algorithm described in Section 4
has two phases, and we analyze the cost of each phase below.

Para 240 Page 8
Candidate Generation Phase: GenTest selects
w t + 1 spectra from the group. For each of these spectra, it
generates a label set. The cost of searching for the label set
for a single spectrum is C
Single
, from Theorem 3. Therefore,
the number of LP calls invoked for generating the candidate
labels is:

Para 241 Page 8
C
Single
 (w - t + 1)
(15)

Para 242 Page 8
Test Phase: The GenTest algorithm takes every generated candidate label and tests it on the remaining t - 1
spectra. In the generation phase, (w - t + 1) spectra are
randomly selected. According to the assumption that the
randomly selected spectra follow the same data distribution
as the original group, there will be
s
w
 (w - t + 1) identical
spectra with the same m labels and (1 s
w
)  (w - t + 1)
spectra that have distinct labels. So the total number of
candidates generated will be
`(1s
w
)  (w - t + 1) + 1
´m.

Para 243 Page 8
Since each `test' invokes an LP call, the total number of LP
calls invoked in this phase is the number of candidates times
the number of remaining spectra:

Para 244 Page 8
(t - 1)  m 
"(1s

Para 245 Page 8
w
)  (w - t + 1) + 1
" (16)
Adding the cost of the generation and test phases gives us
the total number of LP calls invoked by GenTest:

Para 246 Page 8
C
GenT est
= C
Single
 (w - t + 1)+
(t - 1)  m 
`(1s
w
)  (w - t + 1) + 1
´
(17)

Para 247 Page 8
Substituting C
Single
with equation (7), we have C
GenT est

d(n-1)m(w-t+1)+(t-1)m
`(1s
w
)  (w - t + 1) + 1
´.

Para 248 Page 8
6. ALGORITHM SELECTION

Para 249 Page 8
We can use the cost formulae for DFSVoting and GenTest
to estimate the cost of both DFSVoting and GenTest. Evaluating these formulae at optimization time has two drawbacks: (1) The calculation of C
V oting
involves very high
precision floating point arithmetic, which is rather costly.
(2) It is hard to tune the cost estimates in cases when there
is significant discrepancy between the estimates and the observed real cost.

Para 250 Page 8
In this section, we propose an approach to algorithm selection that relies on precomputing decision plots, which essentially capture the performance tradeoffs between algorithms.
The precomputation approach also highlights an important
point: Even if closed-form formulae cannot be derived to accurately predict algorithm costs, unlike the case for DFSVoting and GenTest, a promising approach is to start with a
rough initial estimate for a decision plot and to apply machine learning or statistical modeling techniques to refine the
estimate.

Para 251 Page 8
6.1 Algorithm Profile

Para 252 Page 8
Using the cost analysis discussed in Section 5, we can plot
the relation between M in Sup and cost for a given group
of spectra, assuming that the number of identical spectra
in the group, s, is also known or can be estimated. Figure
4 shows a series of graphs derived from the calculation of
formulae (13) and (17). The y-axis in those graphs is the
estimated number of LP calls invoked by the algorithm. The
x-axis represents the M in Sup value specified by the user.
These graphs characterize the performance characteristics
of the two algorithms with respect to input data. We call
such a graph an algorithm profile. We focus on the case
when the group size is fixed, for simplicity; otherwise, this
adds an extra dimension to the algorithm profile.

Para 253 Page 8
The group size in the algorithm profile shown in Figure
4 is set to be 1000. Each graph in the series corresponds
to a particular s value shown in the upper right corner. As
we can see in the algorithm profile, the lines for DFSVoting and GenTest intersect, which indicates that the choice
of M in Sup will change the algorithm of choice for a given
group of spectra. From the series of graphs shown in Figure 4, we also notice that the intersection point varies with
s. Thus, the choice of algorithm should be based on both
the value s (data distribution) and M in Sup (an analysis
threshold).

Para 254 Page 8
6.2 Decision Plots

Para 255 Page 8
If we plot algorithm costs as a function of M in Sup on
the y-axis and s on the x-axis, each point in the space corresponds to a choice of algorithm. What we are really looking
for is an approximate separation of the space so that in one
region, the DFSVoting algorithm is faster and in the other
region, the GenTest algorithm is faster. Since the decision
of algorithm selection can be made simply by looking up this
0
0.2 0.4 0.6 0.8
1
0
0.5
1
1.5
2
x 10
5
w=1000, s=100

Para 256 Page 9
support
#LP calls

Para 257 Page 9
0
0.2 0.4 0.6 0.8
1
0
0.5
1
1.5
2
x 10
5
w=1000, s=200

Para 258 Page 9
support
#LP calls

Para 259 Page 9
0
0.2 0.4 0.6 0.8
1
0
0.5
1
1.5
2
x 10
5
w=1000, s=300

Para 260 Page 9
support
#LP calls

Para 261 Page 9
0
0.2 0.4 0.6 0.8
1
0
0.5
1
1.5
2
x 10
5
w=1000, s=400

Para 262 Page 9
support
#LP calls

Para 263 Page 9
0
0.2 0.4 0.6 0.8
1
0
0.5
1
1.5
2
x 10
5
w=1000, s=500

Para 264 Page 9
support
#LP calls

Para 265 Page 9
0
0.2 0.4 0.6 0.8
1
0
0.5
1
1.5
2
x 10
5
w=1000, s=600

Para 266 Page 9
support
#LP calls

Para 267 Page 9
0
0.2 0.4 0.6 0.8
1
0
0.5
1
1.5
2
x 10
5
w=1000, s=700

Para 268 Page 9
support
#LP calls

Para 269 Page 9
0
0.2 0.4 0.6 0.8
1
0
0.5
1
1.5
2
x 10
5
w=1000, s=800

Para 270 Page 9
support
#LP calls

Para 271 Page 9
0
0.2 0.4 0.6 0.8
1
0
0.5
1
1.5
2
x 10
5
w=1000, s=900

Para 272 Page 9
support
#LP calls

Para 273 Page 9
DFSVoting
GenTest

Para 274 Page 9
Figure 4: Algorithm Profile

Para 275 Page 9
precomputed information, we call such a graph a decision
plot.

Para 276 Page 9
More abstractly, a decision plot for group labeling algorithms is a function f (M in Sup, s), which takes M in Sup
and s as the input and outputs the group algorithm to use.
The concept of a decision plot can be easily extended to deal
with multiple algorithms, in which case, the whole space is
divided into several regions. Each region corresponds to a
particular algorithm, which is expect to perform best in that
region (defined by data and analysis parameters). We can
think of this extended decision plot as a Voronoi diagram
[17]. Of course many other extensions can also be explored.

Para 277 Page 9
To choose a group labeling algorithm based on data distribution and a minimum support threshold, a decision plot
can be derived from the algorithm profile shown in Figure
4. Given a fixed group size w, we use M in Sup as the yaxis and s/w as the x-axis, and mark each point (identified
by a &lt; M in Sup, s/w &gt; pair) with the corresponding best
algorithm, as indicated by the algorithm profiles. It gives us
the graph shown in Figure 5. As we can see, the graph can
be divided into two regions. The smaller triangle region corresponds to the case when GenTest is better and the other
region represents the case when DFSVoting is better. It
is worth noting that the boundary between regions corresponds to the intersection points in the algorithm profiles.
In our particular case, the boundary of these two regions
is approximately two straight lines, which suggests that we
can simply fit two linear functions of M in Sup and s to approximate the real decision plot. We study this approach
experimentally in Section 7.

Para 278 Page 9
6.3 Algorithm Selection Framework

Para 279 Page 9
6.3.1 Estimating Data Distribution

Para 280 Page 9
Given a decision plot and a group of spectra to label, we
still need a data distribution parameter s to `lookup' the
decision plot and make a choice of group labeling algorithm.
Throughout the cost analysis in Section 5, we assumed that
the value s is the number of identical spectra in the group.
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1

Para 281 Page 9
s/w
support
Choose DFSVoting
Choose GenTest

Para 282 Page 9
Figure 5: Decision Plot

Para 283 Page 9
A direct approach to estimating this value is to divide the
group of spectra into clusters whose diameters are smaller
than a certain threshold and use the size of the largest cluster as the value of s. Many clustering algorithms [3, 5, 8, 26]
and random sampling [24] algorithms can be applied here.

Para 284 Page 9
6.3.2 System Graph

Para 285 Page 9
Now that we have discussed all the components in our
algorithm selection framework, we put the pieces together
in Figure 6. A given group of spectra to label first goes
through the data distribution estimator, which estimates its
data distribution parameter. The algorithm selector takes
the estimated data distribution parameter (s), user-specified
analysis parameters (e.g., M in Sup) and looks up the decision plot to select the best algorithm. The mining engine
then applies the algorithm to the input group of spectra and
outputs the group label set.

Para 286 Page 9
In Figure 6 there are also two lines going from the output
to the algorithm profile builder and data distribution estimator. This indicates that the output can serve as `ground
truth' to tune the data distribution estimator and algorithm
profile. When the algorithm profile component accumulates
enough data, it can in turn update the decision plot with
more accurate information. In the experimental system we
have built, these two feedback loops from the final output
are not implemented yet. Section 7 provides more details
and experimental results on the rest of the components and
focuses on validating the decision plot for group labeling
constructed using the theoretical cost analysis.

Para 287 Page 9
Group of Spectra

Para 288 Page 9
Data
Distribution
Estimator

Para 289 Page 9
Algorithm
Selector

Para 290 Page 9
Decision
Table
Mining
Engine

Para 291 Page 9
Group Label
Set
Algorithm
Profile
User Defined
Parameters

Para 292 Page 9
Table lookup

Para 293 Page 9
Algorithm

Para 294 Page 9
Figure 6: System Graph

Para 295 Page 9
7. EXPERIMENTAL RESULTS
7.1 Experimental Setting

Para 296 Page 10
The spectra we used in our experiments are collected from
an Aerosol Time-of-Flight Mass Spectrometer. The signature database, obtained from domain experts in atmospheric
aerosols, is essentially a collection of isotope distributions of
chemical ions they want to detect. There are 197 signatures
in the signature database, and each signature or spectrum
has 255 dimensions. Notice that the performance bottleneck
is not in the size of the `signature database'. Rather, it is
in the number of spectra to be labeled in a given amount
of time (recall that our application involves monitoring a
stream of spectra), and the cost is dominated by CPUintensive LP calls, rather than I/O intensive disk accesses.
Analogous to how a traditional DBMS seeks to minimize the
cost of disk accesses, our goal is to minimize the cost of LP
computation. The experimental system is implemented in
C++ and runs on a 512M memory PC with Linux.

Para 297 Page 10
Throughout our experiments, the error bound E is set
to 0.05 (a value selected heuristically after some experimentation). The threshold vector t = [t
1
, . . . , t
d
+1
] used
is t = [0, 0.1, 0.4, 1]. This threshold vector divides the relative quantity of a chemical element into three ranges, [0,0.1),
[0.1,0.4) and [0.4,1), with each range corresponding to the
state of `missing', `present', and `abundant' respectively.

Para 298 Page 10
7.2 The Choice of Cost Metric

Para 299 Page 10
Throughout the cost analysis in Section 5, we used the
number of LP calls as the cost metric, assuming that the
number of LP calls invoked is proportional to the execution
time of the algorithm. However, the time cost of a particular
LP call may vary due to differences in constraints and the
context of a particular LP task. To study whether the choice
of LP call as a cost unit is justified, we randomly selected
spectra, and recorded the number of LP calls and execution
time required to label each of them. Figure 7 plots the
results of our experiment, where the x-axis is the number
of LP calls invoked by a particular task and the y-axis is
the execution time for that task. As shown in the graph,
the relation between execution time and number of LP calls
invoked is clear: The execution time is proportional to the
number of LP calls invoked.

Para 300 Page 10
0
200
400
600
800
1000
0
0.5
1
1.5
2
2.5
3x 10
6

Para 301 Page 10
#LP calls
execution time (in microseconds)

Para 302 Page 10
Figure 7: Number of LP calls vs.Execution Time

Para 303 Page 10
7.3 Algorithm Profiles and Decision Plots

Para 304 Page 10
For the algorithm selection framework we propose, we
want to study two issues via experiments: (1) How does the
algorithm profile derived from the cost estimation formula
match the actual algorithm profile and how good is the cost
estimation in terms of deriving the right decision plot? (2)
How good is the decision plot derived from the theoretical
cost model, in terms of providing the correct information
for algorithm selection? In all the experimental data shown
in this subsection, the group size is set to be 1000 spectra,
while the error bound and threshold vector remain the same
as those described in Section 7.1.

Para 305 Page 10
0
0.2 0.4 0.6 0.8
1

Para 306 Page 10
0

Para 307 Page 10
0.5

Para 308 Page 10
1

Para 309 Page 10
1.5

Para 310 Page 10
2

Para 311 Page 10
2.5
x 10
5
    w=1000, s=100

Para 312 Page 10
support

Para 313 Page 10
#LP calls

Para 314 Page 10
0
0.2 0.4 0.6 0.8
1
0
0.5
1
1.5
2
2.5
x 10
5
    w=1000, s=200

Para 315 Page 10
support
#LP calls

Para 316 Page 10
0
0.2 0.4 0.6 0.8
1
0
0.5
1
1.5
2
2.5
x 10
5
    w=1000, s=300

Para 317 Page 10
support
#LP calls

Para 318 Page 10
0
0.2 0.4 0.6 0.8
1

Para 319 Page 10
0

Para 320 Page 10
0.5

Para 321 Page 10
1

Para 322 Page 10
1.5

Para 323 Page 10
2

Para 324 Page 10
2.5
x 10
5
    w=1000, s=400

Para 325 Page 10
support

Para 326 Page 10
#LP calls

Para 327 Page 10
0
0.2 0.4 0.6 0.8
1
0
0.5
1
1.5
2
2.5
x 10
5
    w=1000, s=500

Para 328 Page 10
support
#LP calls

Para 329 Page 10
0
0.2 0.4 0.6 0.8
1
0
0.5
1
1.5
2
2.5
x 10
5
    w=1000, s=600

Para 330 Page 10
support
#LP calls

Para 331 Page 10
0
0.2 0.4 0.6 0.8
1

Para 332 Page 10
0

Para 333 Page 10
0.5

Para 334 Page 10
1

Para 335 Page 10
1.5

Para 336 Page 10
2

Para 337 Page 10
2.5
x 10
5
    w=1000, s=700

Para 338 Page 10
support

Para 339 Page 10
#LP calls

Para 340 Page 10
0
0.2 0.4 0.6 0.8
1
0
0.5
1
1.5
2
2.5
x 10
5
    w=1000, s=800

Para 341 Page 10
support
#LP calls

Para 342 Page 10
0
0.2 0.4 0.6 0.8
1
0
0.5
1
1.5
2
2.5
x 10
5
    w=1000, s=900

Para 343 Page 10
support
#LP calls

Para 344 Page 10
DFSVoting (Actual)
GenTest (Actual)
Naive (Actual)
DFSVoting (Predict)
GenTest (Predict)

Para 345 Page 10
Figure 8: Experimental Result of Algorithm Profile
(w=1000, n =197)

Para 346 Page 10
0
0.2
0.4
0.6
0.8
1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1

Para 347 Page 10
s/w
support
(a) Decision Plot(Synthesized Data)

Para 348 Page 10
0
0.2
0.4
0.6
0.8
1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1

Para 349 Page 10
s/w
support
(a) Decision Plot (Theory)

Para 350 Page 10
Choose GenTest
Choose DFSVoting

Para 351 Page 10
Figure 9:
Experimental Result of Decision plot
(w=1000, n =197)

Para 352 Page 10
7.3.1 Algorithm Profile

Para 353 Page 10
Figure 8 shows both the predicted algorithm profile and
real algorithm profile for DFSVoting and GenTest.
The
group size w in this series of experiments is fixed at 1000
while the number of identical spectra s in the group varies
from 100 to 900. Each graph shown in Figure 8 corresponds
to a particular s (100, 200, ..., 900) in order from left to
right and top to bottom. The series with small circles on
the top of each graph shows the cost of the brute-force approach which labels all the spectra one by one.
6
The series
with stars in each graph are for DFSVoting and the series
with plus signs stand for GenTest. Solid lines show the real

Para 354 Page 10
6

Para 355 Page 10
Due to the variance of average number of labels of each
spectrum, the cost of brute-force approach varies from
dataset to dataset
experimental results while the dotted lines are theoretical
predictions plotted for comparison.

Para 356 Page 11
As we can see in these graphs, the theoretical prediction
matches the experimental results in terms of general shape
and rough absolute values. It is worth noting that both the
theoretical line and experimental line of DFSVoting drop
sharply around the support value of s/w, which is the point
at which we have almost no group labels due to the high
minimum support. While it is clear that the analytical cost
estimation does not precisely predict the cost of each algorithm, it does a good job of predicting the cross-over points
of the two algorithms and their relative performance, which
is what we really care about for cost-based optimization: in
the graphs in Figure 8 the theoretical lines cross each other
at almost the same support value that the real experimental
lines cross.

Para 357 Page 11
Going further as suggested in Section 6.2, we plot two
decision plots for experimental results and theoretical prediction, respectively, in Figure 9. The left graph shows the
decision plot plotted from experimental results. The right
graph shows the decision table plotted from theoretical prediction. The plus signs stand for the case when the DFSVoting algorithm is better while zero signs represent the case
when the GenTest algorithm is better. The two decision
plots are almost exactly the same, except for four points on
the lower boundary of the two regions.

Para 358 Page 11
For those cases where the theoretical decision plot conflicts with the real decision plot, we can see from the algorithm profile graph that the extra LP calls incurred by
the wrong choice is less than 10% of the cost of the optimal
algorithm. This is tolerable.

Para 359 Page 11
0
0.2
0.4
0.6
0.8
1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1

Para 360 Page 11
s/w
support
Choose DFSVoting
Choose GenTest

Para 361 Page 11
Figure 10:
Decision plot for Randomly Selected
Data, w=1000

Para 362 Page 11
7.3.2 Decision Plots

Para 363 Page 11
Figure 10 summarizes a series of experiments designed to
explore the idea of performing algorithm selection by looking
up the decision plot.
A plus represents the case when
DFSVoting is better and a zero sign stand for the case when
GenTest is preferred. The solid lines separating the graph
into two regions are derived from theoretical cost model.
Points to the right of those lines are cases where GenTest
algorithm is predicted to be faster. Points to the left of those
solid lines are the cases where DFSVoting is predicted to be
faster. As we can see in the graph, the solid line almost
perfectly separate the plus signs and zero signs, with only a
few exceptions near the borders, indicating that the decision
plot derived from the theoretical cost model almost perfectly
predicts the best algorithm.

Para 364 Page 11
7.4 Scalability

Para 365 Page 11
We now consider the scalability of the two proposed algorithms. We fixed the value of M in Sup at 70%. The
percentage of `identical spectra' s/w is set to be 80%. Figure 11 shows the cost growth of each algorithm with respect
to the growth of group size. Each point on the graph is the
average of experimental results over 20 selected groups of
spectra such that the group size w is the same for all these
20 groups. As we can see in the graph, both algorithms'
costs grow linearly with respect to the group size.

Para 366 Page 11
Experiments with other M in Sup and s/w values have
consistently shown similar results to the one shown in Figure
11, and are omitted.

Para 367 Page 11
0
1000
2000
3000
4000
5000
0
1
2
3
4
5
6
7
8
9
x 10
5
s/w = 80%, support=70%

Para 368 Page 11
Group Size
#LP calls
GenTest
DFSVoting

Para 369 Page 11
Figure 11: Scalability over group size, s/w=80%,
support=70%

Para 370 Page 11
8. FROM MASS SPECTRA TO MASS MAR
Para 371 Page 11
KET

Para 372 Page 11
In previous sections, we were focused on the spectrum
labeling problem. In this section, we discuss promising connections between the spectral labeling framework and market basket analysis. An obvious connection is that after
a spectrum is labeled, we can treat it as an itemset containing the detected ions, and apply the wealth of results
about itemset mining for further analysis. This is a significant benefit, since it allows us to apply powerful and widely
available tools to the new problem of analyzing streams of
mass spectra.

Para 373 Page 11
There is also a deeper and surprising connection in the
other direction; we might well have a promising tool for market basket analysis in spectral labeling. In the spectrum labeling framework, we have a signature database, which represents the domain knowledge, containing profiles for chemical elements of interest. Using this, for a given spectrum we
compute a label, which is essentially the most likely combination in which the known chemical ions appear in the
spectrum.

Para 374 Page 11
If we replace chemical ion signatures by customer buying
patterns that indicate underlying phenomena of interest, as
suggested by McCarthy [16], and substitute input spectra
with a customers `market basket (purchases in a single visit
to a store), then labeling offers a description of the customer
by decomposing the market basket into the most plausible
combination of known purchasing patterns corresponding to
phenomena of interest.

Para 375 Page 11
For example, if we know the typical buying pattern of
a doting father is a lot of toys and a few pencils, and a
low income customer usually purchases a lot of chicken but
very little seafood, our signature database would contain
the buying patterns of these two types of customers. When
a market basket containing a lot of toys, some pencils, a
lot of chicken but, no seafood is encountered, labeling will
categorize that particular customer as a poor man but a
doting father. In another purchase where the market basket
contains a lot of toys but no food, labeling will describe the
customer as a doting father, but will not be able to detect
whether he is poor or rich. Such analysis was suggested
as a significant direction for data mining research, called
phenomenal data mining, in McCarthys visionary paper [16],
and labeling offers promise as a tool with which to attack
this intriguing application domain.

Para 376 Page 12
9. RELATED WORK

Para 377 Page 12
To our knowledge, this is the first paper to discuss labeling of groups of mass spectra, or to address cost-based
data mining algorithm selection. The idea of a data mining language or framework has been explored by many researchers. In [11], Imielinski and Mannila described their
vision of a data mining system, including a language specification and a general discussion of components for query
compilation and execution. [12] proposed a unified algebra
for multi-step data mining. [7] proposed a universal data
mining model consisting of a data view, a model view and
a process view. [28, 29] proposed general data mining architectures and discussed extending a DBMS with mining
capabilities.

Para 378 Page 12
The cost analysis methodology used in this paper is similar to the analysis of the cost of index seek in [25]. An
average case analysis of branch-and-bound algorithms is presented by Zhang et. al in [27]. Various aspects of numerical
optimization are studied in [18]. More details on estimating
the number of labels and the volume of a spectrum's solution space can be found in [14, 13, 15]. [4, 21] discuss how
to describe data distributions. Clustering based techniques
are surveyed in [3].

Para 379 Page 12
More information about spectrum labeling and environmental monitoring is provided in [10, 6, 23]. Labeled spectra
are related to market baskets, to which a number of methods
based on association rule mining and can be directly applied,
e.g., [1, 9, 22]. Further extensions to a broader concept of
phenomenal data mining is introduced in [16].

Para 380 Page 12
10. REFERENCES

Para 381 Page 12
[1] R. Agrawal et al. Mining association rules between sets
of items in large databases. In ACM SIGMOD, 1993.

Para 382 Page 12
[2] A. Arning et al. A linear method for deviation
detection in large databases. In ACM KDD, 1996.

Para 383 Page 12
[3] P. Berkhin. Survey of clustering data mining
techniques. Technical report, Accrue Software, San
Jose, CA, 2002.

Para 384 Page 12
[4] K. A. D. Peter J. Bickel. Inference in the
multiparameter case, Chapter 6. Prentice Hall, 2
edition, 2001.

Para 385 Page 12
[5] C. H. Cheng et al. Entropy-based subspace clustering
for mining numerical data. In ACM KDD , 1999.

Para 386 Page 12
[6] E. Gard, Jet. al. Real-time analysis of individual
atmospheric aerosol particles: Design and performance
of a portable atofms. In Anal. Chem., pages
4083­4091, 1997.

Para 387 Page 12
[7] I. Geist. A framework for data mining and kdd. In
SAC, 2002.

Para 388 Page 12
[8] S. Guha, N. Mishra, R. Motwani, and L. O'Callaghan.
Clustering data streams. In IEEE Symposium on
Foundations of Computer Science, 2000.

Para 389 Page 12
[9] J. Han, J. Pei, and Y. Yin. Mining frequent patterns
without candidate generation. In 2000 ACM
SIGMOD, 2000.

Para 390 Page 12
[10] Citation details omitted for anonymity

Para 391 Page 12
[11] T. Imielinski and H. Mannila. A database perspective
on knowledge discovery. In Comm. Of The Acm,
39:58­64, 1996.

Para 392 Page 12
[12] T. Johnson et al. The 3w model and algebra for
unified data mining. In The VLDB Journal, 2000.

Para 393 Page 12
[13] J. B. Lasserre. The integer hull of a convex rational
polytope. In Math. Oper. Res., 2003.

Para 394 Page 12
[14] J. B. Lasserre. A laplace transform algorithm for the
volume of a convex polytope. volume 48, 2003.

Para 395 Page 12
[15] J. B. Lasserre and E. S. Zeron. On counting integral
points in a convex rational polytope. In Math. Oper.
Res., 2003.

Para 396 Page 12
[16] J. McCarthy. Phenomenal data mining. In
Communications of the ACM 43(8), 2000.

Para 397 Page 12
[17] T. M. Mitchell. Machine Learning.
WCB/McGraw-Hill, 1997.

Para 398 Page 12
[18] J. Nocedal and S. J. Wright. Numerical Optimization.
Springer, 1 edition, 1999.

Para 399 Page 12
[19] National Research Council. Research Priorities for
Airborne Particulate Matter. Immediate Priorities and
a Long-Range Research Portfolio. 1998, National
Academy Press, Washington, DC.

Para 400 Page 12
[20] K. A. Prather et al. Real-time characterization of
individual aerosol particles using time-of-flight mass
spectrometry. Anal. Chem., 1994; 66, 1403-1407.

Para 401 Page 12
[21] O. P. Rud. Data Mining Cookbook: Modeling data for
marketing, risk, and CRM. Wiley, 1 edition, 2001.

Para 402 Page 12
[22] R. Srikant and R. Agrawal. Mining quantitative
association rules in large relational tables. In ACM
SIGMOD, 1996.

Para 403 Page 12
[23] D. Suess and K. Prather. Mass spectrometry of
aerosols. In Chemical Reviews, pages 3007­3035, 1999.

Para 404 Page 12
[24] H. Toivonen. Sampling large databases for association
rules. In VLDB, 1996.

Para 405 Page 12
[25] S. Yao. Approximating block accesses in database
organizations. In Communications of the ACM 20(4),
pages 260­261, 1977.

Para 406 Page 12
[26] T. Zhang et al. BIRCH: an efficient data clustering
method for very large databases. In ACM SIGMOD,
1996.

Para 407 Page 12
[27] W. Zhang and R. Korf. An average-case analysis of
branch-and-bound with applications: Summary of
results. In AAAI, 1992.

Para 408 Page 12
[28] R. Meo et al. A tightly-coupled architecture for data
mining. In ICDE, pages 316­322, 1998.

Para 409 Page 12
[29] S. Sarawagi, et al. Integrating mining with relational
database systems. In ACM SIGMOD, 1998.

