0	Data Swapping: Variations on a Theme by Dalenius and Reiss By Stephen Fienberg, Julie Mclntyre  					Hilal Akay 
1	Abstract The paper revisited the original published version (“A Technique for Disclosure” by Dalenius and Reiss, 1978) Examine the original proposal The variations and refinements of data swapping Model based methods for statistical disclosure limitation 
2	Statistical disclosure problem  providing quality data to users while protecting the identities of subjects.  concerned with the possibility of a person inferring sensitive information from a database.  A value of some variable is compromisable if it can be uniquely determined from the information that is released. Data swapping: introduced by Dalenius and Reiss  disclosure protection and release of statistically usable databases 
3	Data swapping  a method of preserving confidentiality in data sets that contain categorical variables,i.e, for contingency tables Categorical variables: it makes no sense to say that one category of data is more or less than another (ex: Mr or Mrs, hair colors, religions) X quantitive variables transform a database by exchanging values of sensitive variables among individual records in such a way to maintain lower order frequency counts and marginals 
4	Data swapping confidentiality introducing uncertainty about sensitive data values preserving certain statistics of the data  preserves lower order marginal totals, no impact on inferences that derive from these statistics a unique approach  they cast disclosure limitation problem firmly as a statistical problem. The release of data is justified if one can show that the probability of any individual's data being compromised is small.  The usefulness of data by focusing on the type and amount of distortion introduced by the data. 
5	Theorical justification Consider a set of N individuals. With each individual, associate data observed with respect to V variables, X, Y ..... U, some of which may be sensitive.  it is all categorical: values in the domain {0, 1 ..... (r-l)} for some r, denote the categories into which the N individuals are classified.  a categorical database by an N × V matrix, the original data matrix mo. using this matrix, mo, produce another data matrix, me, to be used as the basis for producing statistics by way of tabulations  
6	t-order statistic if the tabulation involves data for one variable only, the statistic will be referred to as an 1-order statistic; the simplest case in kind is #(x = 0) if the tabulation involves data for two or more variables, the statistic will be referred to as a 2-order statistic, a 3-order statistic, etc., as the case may be; a simple example is #(x = 0, y = 0), which is a 2- order statistic. This matrix me,while not identical with mo, is t-order equivalent with mo,so that t-order statistics are preseved (yield the same t-order statistics). 
7	Data swapping swap the values of sensitive variables among records in such a way that the t-order frequency counts, i.e., the entries in the t-way marginal table, are preserved: t-order equivalent to the original database. justification: existence of sufficient number of t-order equivalent databases to introduce uncertainty about the true values of sensitive variables. the sensitive variable is protected from compromise if there is at least one other database or table, t-order equivalent of the original one, that assigns it a different value. 
8	Example1 Swap values of X  1 with 5 4 with 7 data in tabular form  the two-way marginal tables have not changed from the original data 
9	Example1 the two-way marginal tables have not changed from the original data Summing over any dimension results in the same 2-way totals for the swapped data as for the original data there are at least two data bases that could have generated the same set of two-way tables The data for any single individual cannot be determined with certainty from the release of this information alone. 
10	Example1 construct a new database that is equivalent to the original one in terms of t-order statistics where the new data is sufficiently different from the original so that compromise is not possible a database presented only in terms of t-order statistics is unlikely to be compromised every sensitive variable of every individual is almost certainly involved in at least one swap and hence cannot be determined. 
11	Example2 Swap data for the X-variable for k=4 individuals, number 1 and three others Find the 2-order equivalence İn this case, five possible matrices 
12	Example2 This matrix yields 1- and 2-order statistics identical with the corresponding statistics computed from mo 
13	Probability The probability that the swap will result in a 2-equivalent database is Two variables: To protect data in both the X and Y variables , swap data for both.  Starting with mo, swap data for the X variable and get  mex. Next, starting with mex, swap data for the Y variable and get mexy 
14	Observations  focus primarily on the release of data in the form of 2-way marginal totals details and proofs in the original text are unclear  They do not actually swap data but only ask about possible data swaps.  Their sole purpose appears to have been to provide a framework for evaluating the likelihood of disclosure. 
15	Observations the concept of disclosure is probabilistic and not absolute Data release should be based on an assessment of the probability of the occurrence of disclosure.  tradeoff between protection and utility  no release of information without some possibility o disclosure responsibility of data managers to weigh the risks data utility is defined statistically The requirement to maintain  a set of marginal totals places the emphasis on statistical utility by preserving certain types of inferences (t-way and lower marginal totals) 
16	The form of released data microdata releases:requires that enough data are swapped to introduce sufficient uncertainty about the true values of the individual's data.  tabulation: All marginal tables up to order t are unchanged by the transformation  Identifiying enough swaps to protect every value in the database turns out to be computationaly impractical an approximate data swapping approach for the release of microdata from categorical databases that aproximately preservers t-order marginal totals 
17	Approximation a more feasible approach data swapping is performed so that t-order frequency counts are approximately preserved compute relevant frequency tables from the original database, and then construct a new database to be consistent with these tables, according to probability distribution derived from the original frequency tables extended for containing continues variables, an alogrithm for approximately preserving generalized kth order moments (Reiss, Post, and Dalenius ) for k=2 
18	Applying data swapping to census data releases The US Census Bereau began using a variant of data swapping for data releases from the 1990 decennial census.  Before implementation the method was tested with extensive simulations and the release of both tabulations and microdata was considered Records are swapped between census blocks between individuals or households that have been matched on a predetermined set of k variables.  The (k + 1)-way marginals involving the matching variables and census block totals are guaranteed to remain the same; however, marginals for tables involving other variables are subject to change at any level of tabulation. U.S 2000 decennial census : unique records that were more at risk of disclosure were targeted to be involved in swaps.  
19	Variations on a Theme-Extensions and alternatives Rank swaping NISS Web-based Data Swapping Data Swapping and Local Recoding Data Shuffling 
20	Rank swapingby Moore Rank-based proximity swapping algorithm Find swaps for a continuous variable in a way that swapped records are guaranteed to be within a specified rank-distance of one another.  Multivariate statistics computed from data swapped with this algorithm will be less distorted than those computed after an unconstrained swap. Certain summary statistics are preserved within a specified interval Values of a swapped variable are uniformly distributed on the interval between its bottom-coded and top-coded values. 
21	Rank swapingby Carlson and Salabasis For continuous or ordinally scaled variables Variables:  X and Y  Databases: S1 = [X1, Y1] and S2 = [X2, Y2] Databases are ranked with respect to X, so for large sample sizes, the corresponding ordered values of X1 and X2 should be approximately equal  Swap X1 and X2,  S1 = [X1, Y2] and S 2 = [X2Y1].  randomly dividing the database into two equal parts, ranking and performing the swap, and then recombining wasteful of the data  theory apply only to bivariate correlation coefficients 
22	NISS Web-based Data Swapping By user-specified parameters, produces a data set for release as microdata swap variables and the swap rate, i.e., the proportion of records to be involved in swaps pairs of records are randomly selected and values for that variable exchanged Both risk and utility decrease as the number of swap variables and the swap rate increase high swapping rate implies that data are well-protected from compromise, but inferential properties are more likely to be distorted The risk-utility frontier identifies the greatest amount of protection achievable for any set of swap variables and swap rate for a variety variables generate and test 
23	Data Swapping and Local Recoding   by Takemura  a disclosure limitation procedure for microdata that combines data swapping and local recoding  identifies groups of individuals in the database with similar records different matching algorithms to identify and pair similar individuals for swapping, ex:clustering,Edmond’s algorithm ”obscuring” the values of sensitive variables either by swapping records among individuals within groups, or recoding the sensitive variables for the entire group The method works for both continuous and categorical variables.  The swapping version of the method resemblaces to rank swapping, but the criterion for swapping varies across individuals. 
24	Data Shufflingby Mulalidhar and Sarathy  replace sensitive data by simulated data with similar distributional properties suppose that X represents sensitive variables and S non-sensitive variables Generate new data Y to replace X by using the conditional distribution of X given S, f(X|S), so that f(X|S,Y) = f(X|S). The released versions of the sensitive data, i.e., Y, provide an intruder with no additional information about f(X|S).  One of the problems is that f is unknown and thus there is information in Y  Replace the rank order values of Y with those of X, as in rank swapping. 
25	Data swapping and Model-based statistical Methods methods that use a specific model to perturb or transform data to protect confidentiality Post Randomization Method–PRAM  methods that involve some perturbation or transformation to protect confidentiality, but preserve minimal sufficient statistics for a specific model, thereby maintaining the data users’ inferences under that model Model-based Approaches for the Release of Marginals and Other statistics  
26	Post Randomization Method–PRAM Suppose that a sensitive variable has categories 1, . . . ,m.  each value of the variable in the database is altered according to a predefined transition probability (Markov) matrix.  conditional on its observed value, each value of the variable is assigned one of 1, . . . ,m.  observations either remain the same or are changed to another possible value, all with known probability  The degree of protection depends on the probabilities in the transition matrix and the frequencies of observations in the original database. 
27	Model-based Approaches “bootstrap-like” sampling from the empirical distribution of the data and then releasing the sampled data for analysis (Fienberg, Steele, and Makov) In the case of categorical data, this procedure is closely related to the problem of generating entries in a contingency table given a fixed set of marginals.  Preserving marginal totals is equivalent to preserving sufficient statistics of certain log-linear models. The Dalenius and Reiss data swap preserves marginal totals of tables up to order t, and so can be viewed as a model-based method with respect to a log-linear model. 
28	Discussion Data swapping is used for the release of marginals in a contingency table that are useful for statistical analysis.  This leads to a consideration of log-linear models for which marginal totals are minimal sufficient statistics Although Dalenius and Reiss made no references to log-linear models, they appear to provide the justification for much of the original paper. Data swapping as originally proposed by Dalenius and Reiss does not generalize in ways that they thought because of the relationship between the calculation of bounds for cell entries in contingency tables given a set of released marginals the generation of tables from the exact distribution of a log-linear model given its minimal sufficient statistics marginals.  Original paper focus primarily on the release of data in the form of 2-way marginal totals details and proofs in the original text are unclear Future work : probabilistic justifications and more systematic methods 
29	Thank you. Questions? 
