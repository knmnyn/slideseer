0	Deriving Private Information from Randomized Data Zhengli Huang Wenliang (Kevin) Du Biao Chen Syracuse University 
1	Privacy-Preserving Data Mining Data Mining Data Collection Data Disguising Central Database Classification Association Rules Clustering 
2	Random Perturbation + Original Data X Random Noise R Disguised Data Y 
3	How Secure is  Randomization Perturbation? 
4	A Simple Observation We can’t perturb the same number for several times. If we do that, we can estimate the original data:  Let t be the original data, Disguised data: t + R1, t + R2, …, t + Rm Let  Z = [(t+R1)+ … + (t+Rm)] / m Mean: E(Z) = t 
5	This looks familiar …  This is the data set (x, x, x, x, x, x, x, x) Random Perturbation: (x+r1, x+r2,……, x+rm) We know this is NOT safe.   Observation: the data set is highly correlated. 
6	Let’s Generalize! Data set: (x1, x2, x3, ……, xm) If the correlation among data attributes are high, can we use that to improve our estimation (from the disguised data)? 
7	Data Reconstruction (DR) Original Data X Disguised Data Y Distribution of random noise Reconstructed Data X’ What’s their difference? Data Reconstruction 
8	Reconstruction Algorithms Principal Component Analysis (PCA) Bayes Estimate Method 
9	PCA-Based  Data Reconstruction 
10	PCA-Based Reconstruction Disguised Information Reconstructed Information Squeeze Information Loss 
11	How? Observation: Original data are correlated. Noise are not correlated. Principal Component Analysis Useful for lossy compression 
12	PCA Introduction The main use of PCA: reduce the dimensionality while retaining as much information as possible. 1st PC: containing the greatest amount of variation.  2nd PC: containing the next largest amount of variation. 
13	For the Original Data They are correlated. If we remove 50% of the dimensions, the actual information loss might be less than 10%. 
14	For the Random Noises They are not correlated. Their variance is evenly distributed to any direction. If we remove 50% of the dimensions, the actual noise loss should be 50%. 
15	PCA-Based Reconstruction Original Data X Disguised Data Reconstructed  Data PCA Compression De-Compression 
16	Bayes-Estimation-Based  Data Reconstruction 
17	A Different Perspective What is the Most likely X? Disguised Data Y Possible X Possible X Possible X Random Noise 
18	The Problem Formulation For each possible X, there is a probability:  P(X | Y). Find an X, s.t., P(X | Y) is maximized. How to compute  P(X | Y)? 
19	The Power of the Bayes Rule P(X|Y) is difficult! P(X|Y)? P(Y|X) P(Y) P(X) * 
20	Computing P(X | Y)? P(X|Y) = P(Y|X)* P(X) / P(Y) P(Y|X):  remember Y = X + R P(Y): A constant (we don’t care) How to get P(X)? This is where the correlation can be used. Assume Multivariate Gaussian Distribution The parameters are unknown. 
21	Multivariate Gaussian Distribution A Multivariate Gaussian distribution Each variable is a Gaussian distribution with mean i  Mean vector  = (1 ,…, m) Covariance matrix   Both  and  can be estimated from Y So we can get P(X) 
22	Bayes-Estimate-based Data Reconstruction Original X Disguised  Data Y Randomization Estimated X Which X maximizes  P(X|Y) P(X) P(Y|X) 
23	Evaluation 
24	Increasing the Number of Attributes 
25	Increasing Eigenvalues of the Non-Principal Components 
26	How to improve  Random Perturbation? 
27	Observation from PCA How to make it difficult to squeeze out noise? Make the correlation of the noise similar to the original data. Noise now concentrates on the principal components, like the original data X. How to get the correlation of X? 
28	Improved Randomization 
29	Conclusion And Future Work When does randomization fail: Answer: when the data correlation is high. Can it be cured? Using correlated noise similar to the original data Still Unknown: Is the correlated-noise approach really better? Can other information affect privacy? 
