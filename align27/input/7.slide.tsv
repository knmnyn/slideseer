0	Multiple Aggregations Over Data Streams Rui Zhang		National Univ. of Singapore Nick Koudas		Univ. of Toronto Beng Chin Ooi		National Univ. of Singapore Divesh Srivastava	AT&T Labs-Research 
1	Outline Introduction Query example and Gigascope Single aggregation Multiple aggregations Problem definition Algorithmic strategies Analysis Experiments Conclusion and future work 
2	Aggregate Query Over Streams Select tb, SrcIP, count (*) 	from IPPackets 	group by time/60 as tb, SrcIP More examples:  Gigascope: A Stream Database for Network Applications (SIGMOD’03). Holistic UDAFs at Streaming Speed (SIGMOD’04). Sampling Algorithms in a Stream Operator (SIGMOD’05) (SrcIP, SrcPort, DstIP, DstPort, time, …) 
3	Gigascope  All inputs and outputs are streams. Two level structure: LFTA and HFTA. LFTA/HFTA: Low/High-level Filter Transform and Aggregation. Simple operations in LFTA:  reduce the amount of data sent to HFTA. fit into L3 cache. 
4	Outline Introduction Query example and Gigascope Single aggregation Multiple aggregations Problem definition Algorithmic strategies Analysis Experiments Conclusion and future work 
5	Select tb, SrcIP, count (*) 	from IPPackets 	group by time/60 as tb, SrcIP Example:  2, 24, 2, 17, 12… hash by modulo 10 Costs  C1 for probing the hash table in LFTA C2 for updating HFTA from LFTA Bottleneck is the total of C1 and C2 cost. Single Aggregation 
6	Select tb, SrcIP, count (*) 	from IPPackets 	group by time/60 as tb, SrcIP Example:  2, 24, 2, 17, 12… hash by modulo 10 Costs  C1 for probing the hash table in LFTA C2 for updating HFTA from LFTA Bottleneck is the total of C1 and C2 cost. Single Aggregation 
7	Select tb, SrcIP, count (*) 	from IPPackets 	group by time/60 as tb, SrcIP Example:  2, 24, 2, 17, 12… hash by modulo 10 Costs  C1 for probing the hash table in LFTA C2 for updating HFTA from LFTA Bottleneck is the total of C1 and C2 cost. Single Aggregation 
8	Select tb, SrcIP, count (*) 	from IPPackets 	group by time/60 as tb, SrcIP Example:  2, 24, 2, 17, 12… hash by modulo 10 Costs  C1 for probing the hash table in LFTA C2 for updating HFTA from LFTA Bottleneck is the total of C1 and C2 cost. Single Aggregation 
9	Select tb, SrcIP, count (*) 	from IPPackets 	group by time/60 as tb, SrcIP Example:  2, 24, 2, 17, 12… hash by modulo 10 Costs  C1 for probing the hash table in LFTA C2 for updating HFTA from LFTA Bottleneck is the total of C1 and C2 cost. Single Aggregation 
10	Select tb, SrcIP, count (*) 	from IPPackets 	group by time/60 as tb, SrcIP Example:  2, 24, 2, 17, 12… hash by modulo 10 Costs  C1 for probing the hash table in LFTA C2 for updating HFTA from LFTA Bottleneck is the total of C1 and C2 cost. ( 2, 2 ) Single Aggregation 
11	Single Aggregation Select tb, SrcIP, count (*) 	from IPPackets 	group by time/60 as tb, SrcIP Example:  2, 24, 2, 17, 12… hash by modulo 10 Costs Probe cost: C1 for probing the hash table in LFTA. Eviction cost: C2 for updating HFTA from LFTA. Bottleneck is the total of C1 and C2 costs. Evicting everything at the end of each time bucket. C1 C2 
12	Outline Introduction Query example and Gigascope Single aggregation Multiple aggregations Problem definition Algorithmic strategies Analysis Experiments Conclusion and future work 
13	Multiple Aggregations Relation R containing attributes A, B, C 3 Queries Select tb, A, count(*) 		from R 		group by time/60 as tb, A Select tb, B, count(*) 		from R 		group by time/60 as tb, B Select tb, C, count(*) 		from R 		group by time/60 as tb, C Cost: E1= n 3 c1 + 3n x1 c2 	 n: number of records coming in 	x1: collision rate of A, B, C LFTAs HFTAs C2 
14	Alternatively… Maintain a phantom Total size being the same. Cost: E2= nc1 + 3x2nc1 + 3 x1’ x2nc2 	x1’: collision rate of A, B, C 	x2:  collision rate of ABC LFTAs HFTAs C2 C1 A B C ABC C1 C1 C1 phantom 
15	Cost Comparison Without phantom: E1= 3nc1 + 3x1nc2 With phantom E2= nc1 + 3x2nc1 + 3x1’x2nc2 Difference E1-E2=[(2-3x2)c1 + 3(x1-x1’x2)c2]n If x2 is small, then E1 - E2 > 0. 
16	More Phantoms Relation R contains attributes A, B, C, D. Queries: group by AB, BC, BD, CD 
17	Outline Introduction Query example and Gigascope Single aggregation Multiple aggregations Problem definition Algorithmic strategies Analysis Experiments Conclusion and future work 
18	Problem definition Constraint: Given fixed size of memory M. Guarantee low loss rate when evicting everything at the end of time window Size should be small to fit in L3 cache Hardware (the network card) memory size limit.  Problems: 1) Phantom choosing.  Configuation: a set of queries and phantoms. 2) Space allocation.  x  ∝ g/b Objective: Minimize the cost. 
19	The View Materialization Problem psc 6M ps 0.8M pc 6M sc 6M p 0.2M s 0.01M c 0.1M none 1 
20	Differences 
21	Outline Introduction Query example and Gigascope Single aggregation Multiple aggregations Problem definition Algorithmic strategies Analysis Experiments Conclusion and future work 
22	Algorithmic Strategies Brute-force: try all possibilities of phantom combinations and all possibilities of space allocation Too expensive. Greedy by increasing space used (hint: x ≈    g/b , see analysis later) b =φg , φ is large enough to guarantee a low collision rate. Greedy by increasing collision rate (our proposal) modeling the collision rate accurately. 
23	Algorithmic Strategies Brute-force: try all possibilities of phantom combinations and all possibilities of space allocation Too expensive. Greedy by increasing space used (hint: x ≈    g/b , see analysis later) b =φg , φ is large enough to guarantee a low collision rate. Greedy by increasing collision rate (our proposal) modeling the collision rate accurately. 
24	Algorithmic Strategies Brute-force: try all possibilities of phantom combinations and all possibilities of space allocation Too expensive. Greedy by increasing space used (hint: x ≈    g/b , see analysis later) b =φg , φ is large enough to guarantee a low collision rate. Greedy by increasing collision rate (our proposal) modeling the collision rate accurately. 
25	Algorithmic Strategies Brute-force: try all possibilities of phantom combinations and all possibilities of space allocation Too expensive. Greedy by increasing space used (hint: x ≈    g/b , see analysis later) b =φg , φ is large enough to guarantee a low collision rate. Greedy by increasing collision rate (our proposal) modeling the collision rate accurately. 
26	Algorithmic Strategies Brute-force: try all possibilities of phantom combinations and all possibilities of space allocation Too expensive. Greedy by increasing space used (hint: x ≈    g/b , see analysis later) b =φg , φ is large enough to guarantee a low collision rate. Greedy by increasing collision rate (our proposal) modeling the collision rate accurately. 
27	Algorithmic Strategies Brute-force: try all possibilities of phantom combinations and all possibilities of space allocation Too expensive. Greedy by increasing space used (hint: x ≈    g/b , see analysis later) b =φg , φ is large enough to guarantee a low collision rate. Greedy by increasing collision rate (our proposal) modeling the collision rate accurately. 
28	Algorithmic Strategies Brute-force: try all possibilities of phantom combinations and all possibilities of space allocation Too expensive. Greedy by increasing space used (hint: x ≈    g/b , see analysis later) b =φg , φ is large enough to guarantee a low collision rate. Greedy by increasing collision rate (our proposal) modeling the collision rate accurately. 
29	Algorithmic Strategies Brute-force: try all possibilities of phantom combinations and all possibilities of space allocation Too expensive. Greedy by increasing space used (hint: x ≈    g/b , see analysis later) b =φg , φ is large enough to guarantee a low collision rate. Greedy by increasing collision rate (our proposal) modeling the collision rate accurately. 
30	Algorithmic Strategies Brute-force: try all possibilities of phantom combinations and all possibilities of space allocation Too expensive. Greedy by increasing space used (hint: x ≈    g/b , see analysis later) b =φg , φ is large enough to guarantee a low collision rate. Greedy by increasing collision rate (our proposal) modeling the collision rate accurately. Jump 
31	Outline Introduction Query example and Gigascope Single aggregation Multiple aggregations Problem definition Algorithmic strategies Analysis Experiments Conclusion and future work 
32	Collision Rate Model Random data distribution nrg : expected number of records in a group k : number of groups hashing to a bucket nrg k: number of records hashing to a bucket Random hash: probability of collision 1 – 1/k nrg k(1-1/k): number of collisions in the bucket g : total number of groups b : total number of buckets ,  where Clustered data distribution la : average flow length 
33	The Low Collision Rate Part 	Phantom is beneficial only when the collision rate is low, therefore the low collision rate part of the collision rate curve is of interest. 	Linear regression:  
34	Space Allocation: The Two-level case One phantom R0 feeding all queries R1, R2, …, Rf. Their hash tables’ collision rates are x0, x1, …, xf.  Result: quadratic equation.  Let partial derivative of e over bi equal 0. 
35	Space Allocation: General cases Resulted in equations of order higher than 4, which are un solvable algebraically (Abel’s Theorem). Partial results:  b12 is proportional to  Heuristics: Treat the configuration as  	two-level cases recursively. Supernode. Implementation: SL: Supernode with linear combination of the number of groups. SR: Supernode with square root combination of the number of groups. PL: Proportional linearly to the number of groups. PR: Proportional to the square root of the number of groups. ES: Exhaustive space allocation. Supernode 
36	Outline Introduction Query example and Gigascope Single aggregation Multiple aggregations Problem definition Algorithmic strategies Analysis Experiments Conclusion and future work 
37	Experiments: space allocation (ABCD(ABC(A BC(B C)) D))  Comparison of space allocation schemes Queries in red; phantoms in blue. x-axis: memory constraint ; y-axis: relative error compared to the optimal space allocation. Heuristics SL: Supernode with linear combination of the number of groups. SR: Supernode with square root combination of the number of groups. PL: Proportional linearly to the number of groups. PR: Proportional to the square root of the number of groups. Result: SL is the best; SL and SR are generally better than PL and PR. 
38	Experiments: phantom choosing Heuristics GCSL: Greedy by increasing Collision rate; allocating space using Supernode with Linear combination of the number of groups. GCPL: Greedy by increasing Collision rate; allocating space using Proportional Linearly to the number of groups. GS: Greedy by increasing Space.  Recall Results: GCSL is better than GS; GCPL is the lower bound of GS. 
39	Experiments: real data Experiments on real data Actually let the data records stream by the hash tables and calculate the cost. x-axis: memory constraint ; y-axis: relative cost compared to the optimal cost. Results GCSL is very close to optimal and always better than GS. By maintaining phantoms, we reduce the cost up to a factor of 35. 
40	Outline Introduction Query example and Gigascope Single aggregation Multiple aggregations Problem definition Algorithmic strategies Analysis Experiments Conclusion and future work 
41	Conclusion and future work We introduced the notion of phantoms (fine granularity aggregation queries) that has the benefit of supporting shared computation. We formulated the MA problem, analyzed its components and proposed greedy heuristics to solve it. Through experiments on both real and synthetic data sets, we demonstrate the effectiveness of our techniques. The cost achieved by our solution is up to 35 times less than that of the existing solution. We are trying to deploy this framework in the real DSMS system. 
42	Questions ? 
