0	 Cost-Based Labeling of Groups of Mass Spectra  
1	 ABSTRACT  
2	 We make two main contributions in this paper. First, we motivate and introduce a novel class of data mining problems that arise in labeling a group of mass spectra, specifically for analysis of atmospheric aerosols, but with natural applications to market-basket datasets. This builds upon other recent work in which we introduced the problem of labeling a single spectrum, and is motivated by the advent of a new generation of Aerosol Time-of-Flight Mass Spectrometers, which are capable of generating mass spectra for hundreds of aerosol particles per minute. We also describe two algorithms for group labeling, which differ considerably in how they utilize an LP solver, and also differ considerably from algorithms for labeling a single spectrum.  
3	 Our second main contribution is to show how to automatically select between these algorithms in a cost-based manner, analogous to how a relational query optimizer selects from a space of query plans. While the details are specific to the labeling problem, we believe that this is a promising first step towards a general framework for costbased data mining, and opens up an important direction for future research.  
4	 1. INTRODUCTION  
5	 The size and composition of aerosol particles, which are often complex mixtures of organic and inorganic solids and liquid suspended in the air, is directly related to their origin, evolution and deposition and is intimately related to their environmental and health effects [19]. The aerosol timeof-flight mass spectrometer (ATOFMS) [20] samples aerosol particles directly from the ambient air or from an emission source and obtains size and chemical composition information on one particle at a time, in real-time. It holds the potential to fundamentally change policy and practice in environmental monitoring, but our ability to analyze the data is a critical bottleneck. Specifically, an ATOFMS produces a mass spectrum for each aerosol particle, and can sample about 250 particles per minute.  
6	 Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Copyright 200X ACM X-XXXXX-XX-X/XX/XX ... $ 5.00.  
7	 A mass spectrum is a plot of signal intensity (often normalized to the largest peak in the spectrum) versus the mass-tocharge (m/z) ratio of the detected ions. Thus, the presence of a peak indicates the presence of one or more ions containing the corresponding m/z value. A basic task is to label a spectrum with the ions that are present in the particle, and we studied this problem in [10], in collaboration with a team of atmospheric chemists. In practice, however, we are often interested in the composition of particles sampled over some time window, rather than the composition of each individual particle.  
8	 In this paper, our first contribution addresses the central problem of labeling a group of mass spectra. To a first approximation, we treat the group as an unordered collection. The fact that these spectra are obtained from a continuously sampled stream of particles essentially allows us to exploit some domain knowledge about the percentage of similar spectra within a group. The labeling of mass spectra is a first step in a more comprehensive analysis of ATOFMS streams, and allows us to model each aerosol particle as a collection of ions, along with a quantity for each ion. Viewed thus, an aerosol particle is a generalization of the well-known market basket abstraction of a collection of items purchased at one time by a customer. While our primary focus is on mass spectra, we briefly discuss this connection to market basket data, which makes our results relevant for a wider class of applications.  
9	 Additional steps in a typical analysis involve looking for trends and correlations with other spatiotemporal streams, taking into account data about ambient conditions and emission sources. Thus, labeling is just one step in a typical multi-step analysis. Our ultimate objective is to develop an algebraic framework for expressing such multi-step data mining analyses, and a cost-based optimization framework for finding good evaluation plans.  
10	 Our second contribution in this paper is to show how database concepts like set-orientation and cost-based query optimization can be applied to data mining tasks (such as labeling mass spectra using linear programming techniques). While the details are specific to the labeling problem, we show the benefits of a set-oriented approach to a complex mining task, in particular, the benefits of essentially "pushing" constraints over the desired set of labels down into the linear programming computations for identifying those labels. The cost analysis of the algorithms we propose for group labeling clearly shows the benefits of group labeling versus labeling each spectrum in the group individually. Most importantly, it provides the basis for a cost-based approach to selecting the most efficient algorithm. To our knowledge, this is the first paper to describe a cost-based framework for selecting between alternative data mining algorithms (including algorithms for machine learning problems, statistical analyses, various kinds of frequent itemset and sequential pattern identification, etc.).  
11	 Research in data mining has largely concentrated on algorithms for a single task, and comparisons of performance have been empirical in nature. Insights from database systems design can guide the development of a framework for multi-step analyses that incorporates data mining tasks such as clustering, decision-tree construction, or labeling. In turn, this opens the door to a cost-based optimization framework, and to a compositional approach to mining. We believe that our results are a modest first step towards this goal.  
12	 1.1 Outline  
13	 The rest of the paper is structured as follows. We review single spectrum labeling in Section 2 and then introduce group labeling in Section 3. We propose two new algorithms for group labeling in Section 4. In Section 5, we present a cost analysis of these algorithms. Using this analysis as a foundation, we propose a cost-based method for selecting the most efficient group labeling algorithm, taking into account the characteristics of the data and the group labeling parameters, in Section 6. In Section 7, we study the algorithm selection method experimentally, and show its effectiveness. In Section 8, we discuss the connections between spectrum labeling and market basket analysis. We survey related work in Section 9.  
14	 2. SPECTRUM LABELING  
15	 In this section, we review the problem of labeling a single mass spectrum, introduced in [10], to keep this paper selfcontained. The formalization of the group labeling problem, presented in the next section, builds upon the single spectrum case.  
16	 2.1 Preliminaries  
17	 A mass spectrum can be represented as a normalized  
18	 vector b, P i b i = 1. b i  R is the relative signal intensity at m/z value i.  
19	 The signature of an ion is a vector s, s i  R and P  
20	 i  
21	 s i = 1, representing the distribution of its isotopes, i.e., s  
22	 i  
23	 is the relative abundance of isotopes with m/z value i.  
24	 A signature database is a set of signatures S = {s 1 , s 2 , ..., s n } where s j is the signature of chemical element j. All the spectra and signatures have the same `range' and `granularity' over m/z axis; i.e., they have the same dimension and the i th element of a spectrum or signature always corresponds to the same m/z value i.  
25	 The task of spectrum labeling is to find the chemical ions identified by the peaks in the spectrum and, ideally, their quantities in the particle. If we arrange the n signatures in the signature database in some order, the signature database can be represented as a matrix A = [s 1 , s 2 , ..., s n ], where the k th column in matrix A represents signature k. The labeling task consists of finding an n-dimensional vector x such that x[j] is the relative abundance of chemical element j. This is equivalent to solving the linear equation  
26	 Ax = b, x  0. (1) 2.2 An Optimization-Based Reformulation  
27	 2.2.1 Error Bound  
28	 In real applications, the observed spectrum usually contains noise and calibration discrepancies, and cannot be described as an exact linear combination of ion signatures. Labeling therefore involves finding a linear combination of ion signatures that approximately matches the input spectrum. Therefore, we introduce an error bound E with respect to a certain distance function D. The linear equation model (1) then becomes an optimization task:  
29	 Seek a, s.t. D(Aa, b) &lt; E, a  0 (2)  
30	 Given a signature database A that contains n signatures,  
31	 and an input spectrum b, the search space for the optimization task defined in (2) is an n-dimensional continuous space.  
32	 The solution space for input b is a subspace within this search space.  
33	 Definition 1. Given a signature database A, an input spec 
34	 trum b, and an error bound E with respect to distance func 
35	 tion D, the solution space of spectrum b,  
36	 L b = {a | D(Aa, b) &lt; E and a  0}  
37	 It is worth noticing that the choice of the distance function D in (2) could dramatically change the complexity of the problem [10]. Using Manhattan distance, namely D(v 1 , v 2 ) = P i |v 1 [i] - v 2 [i]|, the optimization task of (2) can be interpreted as a linear programming task [10] whose time complexity is polynomial in the total number of signatures in the signature database. Other distance functions can be useful in certain situations, for example, to spread errors over fewer dimensions. However, considering other distance functions is outside the scope of this paper, and we will henceforth assume that Manhattan distance is used.  
38	 2.2.2 Optimization Model  
39	 In [10], we have shown that the optimization task defined in (2) will have an infinite number of solutions for most input spectra. Fortunately, in practice, we only care about those solutions that are significantly different. A natural approach to deal with the infinity in a continuous space is to discretize it into grids, so that the number of possible solutions is finite.  
40	 Formally, a discretization is specified by a threshold vector t = [t 1 , t 2 , ...t d +1 ] divides each dimension of the search space into d ranges: [t 1 , t 2 ), [t 2 , t 3 )...[t d , t d + 1), where t i and t i +1 are the lower bound and upper bound of range i. A cell is the finest granularity of the discretization, which characterizes the degree of detail users care about. Given a discretization that divides each dimension into d ranges, the whole search space is discretized into d n cells , where n is the number of dimensions. (Recall that n is the number of signatures in the signature database.)  
41	 A label of spectrum b is simply a cell that intersects b's solution space. It can be represented as a vector of integers x, s.t. x[i] indicates the range it falls into on dimension  
42	 i.  
43	 1 The set of all cells intersecting b's solution space forms  
44	 the label set of spectrum b. We use the term feasible  
45	 1  
46	 This is defined rigorously using the notion of an index vector in [10]. subspace to describe any subspace of the search space that intersects the solution space.  
47	 Figure 1 illustrates the concepts discussed in this section. Suppose there are two signatures in the signature database. The threshold vector t = [0, 0.3, 0.6, 1] divides each dimension into three ranges indexed by 0, 1, and 2. The search space is a two-dimensional space ABCD. S 1 S 2 S 3 S 4 is the solution space of an example input spectrum, which intersects the cells LF GM and M GHA. So, cells LF GM and M GHA, which can be represented as vectors [0, 1] and [0, 2], are labels of the input spectrum. Subspace ALF H intersects the solution space, so it is a feasible subspace. M BEG is also a feasible subspace.  
48	  ¡ ¡ ¡ ¡ ¡ ¡   ¡ ¡ ¡ ¡ ¡ ¡   ¡ ¡ ¡ ¡ ¡ ¡   ¡ ¡ ¡ ¡ ¡ ¡   ¡ ¡ ¡ ¡ ¡ ¡   ¡ ¡ ¡ ¡ ¡ ¡   
49	 ¢¡¢¡¢¡¢¡¢¡¢¡¢ ¢¡¢¡¢¡¢¡¢¡¢¡¢ ¢¡¢¡¢¡¢¡¢¡¢¡¢ ¢¡¢¡¢¡¢¡¢¡¢¡¢ ¢¡¢¡¢¡¢¡¢¡¢¡¢ ¢¡¢¡¢¡¢¡¢¡¢¡¢ £¡£¡£¡£¡£¡£¡£ £¡£¡£¡£¡£¡£¡£ £¡£¡£¡£¡£¡£¡£ £¡£¡£¡£¡£¡£¡£ £¡£¡£¡£¡£¡£¡£  
50	 ¤¡¤¡¤¡¤¡¤¡¤¡¤ ¤¡¤¡¤¡¤¡¤¡¤¡¤ ¤¡¤¡¤¡¤¡¤¡¤¡¤ ¤¡¤¡¤¡¤¡¤¡¤¡¤ ¤¡¤¡¤¡¤¡¤¡¤¡¤  
51	 B ¥¡¥¡¥¡¥¡¥¡¥ ¥¡¥¡¥¡¥¡¥¡¥ ¦¡¦¡¦¡¦¡¦¡¦ ¦¡¦¡¦¡¦¡¦¡¦ §¡§¡§¡§¡§ §¡§¡§¡§¡§ §¡§¡§¡§¡§ §¡§¡§¡§¡§ §¡§¡§¡§¡§ §¡§¡§¡§¡§ §¡§¡§¡§¡§ §¡§¡§¡§¡§ §¡§¡§¡§¡§ §¡§¡§¡§¡§ §¡§¡§¡§¡§  
52	 ¨¡¨¡¨¡¨¡¨ ¨¡¨¡¨¡¨¡¨ ¨¡¨¡¨¡¨¡¨ ¨¡¨¡¨¡¨¡¨ ¨¡¨¡¨¡¨¡¨ ¨¡¨¡¨¡¨¡¨ ¨¡¨¡¨¡¨¡¨ ¨¡¨¡¨¡¨¡¨ ¨¡¨¡¨¡¨¡¨ ¨¡¨¡¨¡¨¡¨ ¨¡¨¡¨¡¨¡¨  
53	 cell space solution  Label  
54	 L M  
55	 0.3 0.6 1  
56	 0.3 0.6 1 0 F H  
57	 E C D A  
58	 G S1  
59	 ©¡©¡©¡©¡©¡© ©¡©¡©¡©¡©¡© ©¡©¡©¡©¡©¡© ¡¡¡¡¡ ¡¡¡¡¡ ¡¡¡¡¡ S3 S2 S4  
60	 Figure 1: Illustration of Concepts  
61	 Given an error bound E with respect to a distance function D and a discretization, we now redefine the task of spectrum labeling as follows: Find all cells that intersect the solution space of the input spectrum.  
62	 Table 1 summarizes the notations used in this paper and provides an operational optimization model for the labeling task that we just described.  
63	 Notation: x A n dimensional vector of integers , 1  x[i]  d.  
64	 b Input mass spectrum  
65	 t Threshold vector for discretization d Number of ranges per dimension under discretization L Label set of input spectrum A Signature database D Distance function E Error bound  
66	 L=  
67	 For every possible x, 1  x[i]  d Seek a s.t.  
68	 D(Aa, b)  E (3) t[j]  a[i] &lt; t[j + 1], j = x[i] If (3) succeeds, L = L  x  
69	 Return L  
70	 Table 1: Operational Definition of Spectrum Labeling  
71	 3. GROUP LABELING  
72	 In this section, we introduce the problem of labeling a group of spectra. In environmental monitoring, the spectra are collected through continuous sampling, and a group that is collected at a single location over a short time-span is likely to contain many similar spectra (because the environment does not change instantaneously). Thus, the goal is to find these common, or typical, spectra. 2 Indeed, this is the goal even when the group does not reflect particles from the same location and time; e.g., when analyzing a collection of spectra obtained at multiple locations and times but with some commonalities in ambient conditions.  
73	 Given a group of spectra {b i }, we can conceptually 3 compute a set of label sets {L i }, where L i = { x ij } is the label  
74	 set of b i . We define the support of a label x with respect  
75	 to the group of spectra {b i } as the percentage of b i s whose corresponding label set contains x.  
76	 Definition 2. Given a group of spectra {b}, the support  
77	 of a label x = |{L i |xL i }| |{L i }| , where L i = { x ij } is the label set  
78	 of spectrum b i .  
79	 Intuitively, the support characterizes the likelihood of a label given a group of similar spectra. Extending the concept of `label' and `label set' discussed in Section 2.2, we define group label and group label set as follows:  
80	 Definition 3. Given a group of spectra B = {b i } and a threshold M in Sup, x is a group label if the support of x w.r.t. B is greater than M in Sup. The group label set for the group B is GL = {x|x is a group label of B}.  
81	 As an example, consider a group of spectra {b 1 , b 2 , b 3 }.  
82	 Let the label set for b 1 be {x 1 , x 2 }, the label set for b 2 be  
83	 {x  
84	 2  
85	 }, and the label set for b 3 be {x 3 }. Then, support(x 1 ) = support(x 3 ) = 33%, support(x 2 ) = 66%. Suppose the M in Sup threshold is set to be 50%, then x 2 is the only group label. The group label set is therefore {x 2 }.  
86	 Spectral labeling is important in many domains other than environmental monitoring because mass spectra are a widely used tool for chemical and biological analysis. Surprisingly, the concepts also show promise for analyzing market-basket data; we discuss this briefly in Section 8.  
87	 4. SEARCH FOR GROUP LABELS  
88	 In this section, we first review a depth-first search algorithm introduced in [10] for single spectrum labeling, based on which we propose two new algorithms for group labeling. When we go from labeling a single spectrum to a large group of spectra, the problem is fundamentally altered by the notion of support. The new Depth First Search with Voting (DFSVoting) and Candidate Generation and Test(GenTest) algorithms for group labeling differ significantly in how they handle support.  
89	 4.1 Basic Depth First Search Algorithm  
90	 If a subspace is not feasible, then we do not need to consider any cell in that subspace. The basic depth-first single spectrum labeling algorithm utilizes this property to prune the search space. Table 2 shows the operational procedure which invokes an LP call to test whether a given subspace is feasible.  
91	 2  
92	 A related task is to find common ions across the group of spectra. Further, we often have domain knowledge that can be expressed in terms of constraints over the composition of the particles in the group. These extensions are important directions for future research, but outside the scope of this paper.  
93	 3  
94	 Computing all label sets is inefficient, and the group labeling algorithms that we propose avoid this.  
95	 Given : Input spectrum b  
96	 Threshold vector t Error bound E  
97	 is feasible(subspace S)  
98	 Seek a, s.t.  
99	 D(Aa, b)  E (*)  
100	 t[l i ]  a[i] &lt; t[h i ] t[l i ] and t[h i ] are the boundary of S in dimension i  
101	 if (*) succeeds, return TRUE, otherwise return FALSE  
102	 Table 2: Testing the Feasibility of a Subspace  
103	 The basic depth-first single spectrum labeling algorithm is shown in Table 3, and uses a divide-and-conquer approach. Its exploration of the search space can be mapped to a search tree. Each node in the search tree is associated with a unique subspace.  
104	 At each node, the algorithm first invokes a linear programming (LP) call to check if the subspace is feasible. If the subspace is not feasible, the subtree is pruned and not explored. Otherwise, we know there are one or more labels in the subspace, and we must search inside that subspace. To do this, we select a dimension j that has not been subdivided to the finest possible granurality, and use it to split the subspace into smaller spaces, each of which has the finest possible granurality in dimension j. Each smaller space created thus corresponds to a new search node is, and is explored recursively.  
105	 The above procedure is repeated until either (1) the current subspace is not feasible, or (2) the current subspace is a cell. In the former case, we discard the current search node and backtrack. In the latter case, the label corresponding to this cell is output by the algorithm.  
106	 Given : Input spectrum b  
107	 Threshold vector t = [t 1 , t 2 , . . . , t d +1 ] Error bound E  
108	 Output: Label set for b  
109	 Depth First Search(subspace S) if (is feasible(S)) RETURN else if (S is a cell) output the corresponding label of S else pick dimension(j) split S into a set of subspacesS i s.t. Each S i is not divisible on dimension j for each result subspace S i Depth First Search(S i )  
110	 Main: Depth First Search(the whole search space W )  
111	 Table 3: Algorithm for Single Spectrum Labeling  
112	 In Table 2, the method pick dimension(j) chooses the dimension to split. We use a simple scheme in which (k+1) th  
113	 dimension is chosen as the split dimension at level k of the recursion, assuming the search starts from level 0. 4  
114	 4  
115	 Different strategies for choosing the dimension to split are studied in [10]. 4.2 Depth-First Search Voting Algorithm  
116	 In group labeling, a subspace is `feasible' (i.e., worth further exploration) only when it intersects the solution spaces of at least a certain minimum number of spectra. Following this intuition, we derive the DFSVoting group labeling algorithm (shown in Table 4) from the depth-first single spectrum labeling algorithm by changing the definition of `feasible'.  
117	 At each search node, we take a vote among the spectra in the group. A spectrum votes yes at a node if the subspace corresponding to the node is feasible for the spectrum; otherwise it votes no. When the number of yes votes exceeds the minimum number required by the support theshold, the algorithm goes on to search the children of the current node in depth-first order. Otherwise, the subspace at the current node is pruned, and the algorithm backtracks to the parent node.  
118	 Consider an example of group labeling, with two signatures in the database and with two spectra in the group, and the threshold vector for discretization set to be t = [0, 0.3, 0.6, 1]. Suppose that the label sets for the two spectra are {x 1 , x 2 , x 3 } and {x 1 , x 2 , x 4 } respectively, in which x  
119	 1  
120	 = [0, 1], x 2 = [0, 2], x 3 = [0, 0] and x 4 = [1, 2].  
121	 Figure 2 illustrates the execution of the DFSVoting algorithm. The shadow area in each search node represents the subspace investigated. Beside each search node, we show the set of spectra that vote yes for the subspace, and the order in which nodes are visited. The edge connecting two search nodes is tagged by the additional constraint introduced when going from the parent to its child.  
122	 Input : Set of Spectra B, |B| = w  
123	 Threshold vector t = [t 1 , t 2 , . . . , t d +1 ] Error bound E Support threshold M in Sup  
124	 Output: Group label set for B  
125	 DFSVoting(Subspace S, Set of Spectra C)  
126	 C = {b|b  C, S is feasible w.r.t. b}  
127	 if |C |  M in sup  w RETURN  
128	 else if (S is a cell) output the corresponding label of S else pick dimension(j) split S into a set of subspaces S i s.t each S i is not divisable on dimension j for each result subspace S i DFSVoting(S i , C )  
129	 Main : DFSVoting(The whole search space W , B)  
130	 Table 4: Algorithm DFSVoting for Group Labeling  
131	 The following theorem establishes the correctness of DFSVoting. The proof is omitted for lack of space.  
132	 Theorem 1. Given a group of spectra and a specified minimum support, the DFSVoting algorithm finds the complete group label set without duplication.  
133	 4.3 Candidate Generation and Test Algorithm  
134	 The Candidate Generation and Test (GenTest) algorithm 0&lt;=a1 &lt; 0.3 0.3 &lt;=a1 &lt; 0.6 0.6 &lt;= a1 &lt; 1  
135	 0 &lt;= a2 &lt; 0.3 0.3 &lt;=a2 &lt; 0.6 0.6 &lt;= a2 &lt; 1 1  
136	 feasible cells (labels) Infeasible subspaces {1,2}  
137	 {1} 3 {1,2} 4 {1,2} 5 2 {1,2} 6 {2} {} 7  
138	 Figure 2: An Example of the DFSVoting Algorithm  
139	 uses the depth-first algorithm for single spectrum labeling as a building block. It is based on the following observation:  
140	 Lemma 1. Suppose that we are given a support threshold M in Sup, a set of spectra B, |B| = w, and a subset S, S  B, |S| = (1 - M in Sup)  w + 1 . Then, l is a group label  
141	  b  S, s.t. l is a label of b.  
142	 The above lemma essentially uses a pigeon-hole argument to establish that labels with a given level of support can only be missing in a certain (hopefully small, for high support) number of spectra. In particular, such a label must appear in the labels for some spectrum in set S if we pick |S| =  
143	 (1 - M in Sup)  w + 1 . Thus, the union of the label sets of spectra in such a set S contains all group labels for B.  
144	 The GenTest algorithm shown in Table 5 consists of two phases: (1) Select a group S with (1 - M in Sup) × w + 1 spectra from B and calculate the label set for each of them. This generates a set of candidates group labels. (2) For each candidate group label, test whether it is a label for each spectrum in B - S. If a candidate label appears in the label set of at least w × M in Sup spectra, it is output as a group label for B.  
145	 The following theorem establishes the correctness of GenTest.  
146	 Theorem 2. Given a group of spectra and a specified minimum support, the GenTest algorithm finds the complete group label set without duplication.  
147	 We observe that both algorithms are highly parallelizable. DFSVoting is also non-blocking, in contrast to GenTest, in which the testing phase is blocked until the candidate generation phase is complete. A more detailed analysis that compares the cost of the two algorithms is presented in the next section.  
148	 5. COST ANALYSIS  
149	 The goal of our analysis is to estimate the effect of various inputs on the overall cost of each algorithm, and more importantly, to determine the relationship between algorithm cost and the characteristics of the data. Ultimately, we want to be able to select the less expensive algorithm for any instance of the problem by using these cost estimates.  
150	 In what follows, we will use the notation in Table 6. Input : Set of Spectra B, |B| = w  
151	 Threshold vector t = [t 1 , t 2 , . . . , t d +1 ] Error bound E Support threshold M in Sup Output: Group label set for B GenTest L =  B 0 = { (1 - M in Sup)  w + 1 spectra randomly choosen from B}  
152	 for each b in B 0 find F i , the label set of b for each label l  F i l.count + + L = L  F i for each spectrum b  B - B 0 for each l  L  
153	 if l is a label for the b l.count + +; for each label l  L if (l.count &gt; M in Sup  w) output l as a solution  
154	 Table 5: Algorithm GenTest for Group Labeling  
155	 Notation Meaning  
156	 n Number of element signatures in the database d Number of ranges per dimension under discretization m Number of labels for a particular spectrum w Size of the group of spectra s Conceptual number of identical spectra within the group M in Sup Minimum support threshold for group labeling C Single Cost of labeling a single spectrum C V oting Cost of DFSVoting algorithm C GenT est Cost of GenTest algorithm  
157	 Table 6: Notation for Cost Analysis  
158	 5.1 Cost Metric  
159	 The proposed algorithms call an LP solver to determine whether a subspace is feasible or not. The exact cost of an LP call depends on the initial point and the constraints. When more sophisticated optimization is used, the cost of a particular LP call may also depend on the previous linear programming tasks performed [18]. Fortunately, the cost of one LP call is polynomial in the number of signatures in the database [18] and both DFSVoting and GenTest tend to have similar gains when given additional constraints and similar input spectra. Therefore, the number of LP calls incurred is a good cost metric, at least for comparing the two algorithms. In addition, this abstraction makes our analysis applicable to other depth-first search algorithms that invoke expensive subcomputations at each node.  
160	 5.2 Cost of Labeling One Spectrum  
161	 The depth-first single spectrum labeling algorithm takes a spectrum as input and outputs its label set. The search space corresponds to a complete tree, as shown in Figure 3. . . . . . . level 0  
162	 level 1  
163	 level k  
164	 level n (leaf level)  . . . . . .  . . . . . .  . . . . . .  
165	  . . . . . .  . . . . . .  
166	 Figure 3: A Complete Search Tree  
167	 Each leaf node corresponds to a cell in the space. The tree is traversed in a top-down fashion. At each non-leaf node visited, we invoke an LP call to see if it has in its subtree a leaf node corresponding to a label. If there is such a leaf node, all the children of the subtree are visited, otherwise, the algorithm will prune that subtree. We can think of the algorithm as a node coloring game.  
168	 Given a complete tree of n + 1 levels, a painter  
169	 randomly drops m black balls on the leaf nodes and colors the non-leaf nodes as follows: If a non-leaf node has a black ball in its subtree, paint it black; otherwise, leave it white.  
170	 The painter corresponds to the input spectrum. The number of black balls is the number of labels for that spectrum. The complete tree with n+1 levels corresponds to the entire search space of the depth-first algorithm, and each leaf node with a black ball is a label. A non-leaf node is black if its corresponding subspace is feasible.  
171	 Lemma 2. Given a spectrum b and a discretization criterion that divides each dimension of the search space into d ranges, if the corresponding node coloring game ends with n  
172	 b  
173	 black non-leaf nodes, the number of LP calls invoked by  
174	 the depth-first algorithm in Table 3 to label spectrum b is:  
175	 C single = n b  d + 1 (4)  
176	 Proof. In the node coloring game, a non-leaf node is black if it corresponds to a feasible subspace. Black nodes are those that invoke one LP call for each of their children. Since each black node invokes an LP call for each of its children and one LP call is performed at the root node, the total number of LP calls invoked is n b  d + 1.  
177	 In transforming the single spectrum labeling problem to a node coloring game, we deliberately made a random drop assumption: A label of a spectrum is randomly and uniformly assigned to a cell in the search space.  
178	 This assumption actually allows duplicates among the m labels for a spectrum, which is not the case for our labeling algorithm. However, the number of labels m is much smaller than the total number of cells d n . Therefore, the difference due to duplicates is negligible.  
179	 In reality, the uniform distribution assumption is also violated. The labels are not spread out in the space without any constraints. They all intersect the solution space of the input spectrum, which is a convex hull [10]. In other words, they are close to each other in the space. Nonethless, these simplifications allow us to derive cost formulae that track actual performance very well, as we show empirically in Section 7.  
180	 Given the `node coloring game' model, to estimate cost, we have to estimate the number of black non-leaf nodes. In order to estimate the total number of black nodes after playing the game, we first estimate the probability that a particular non-leaf node is painted black.  
181	 Lemma 3. In the node coloring game, if the painter has m balls, the probability that a non-leaf node at level k is colored black is:  
182	 P (k) = 1 ,,1- 1d  
183	 k « m (5)  
184	 Proof. At a particular level k, there are d k nodes. So, for a particular non-leaf node N at level k the probability that a particular black ball is in the subtree of N is 1 d k .  
185	 1 1 d k then gives the probability that a particular black ball is not in the subtree of N . Since each ball is dropped independently, the probability that all m black balls are not in N 's subtree is `11 d k ´ m . Hence, 1 `11 d k ´ m gives us the probability that node N at level k has a black ball in its subtree. In other words, the probability that a painter colors a node black at level k is:  
186	 P (k) = 1 ,,1- 1d  
187	 k « m  
188	 Given the function P in Lemma 3, we can estimate the number of black nodes at level k, and in turn, the overall number of LP calls invoked by the depth-first algorithm for labeling a single spectrum.  
189	 Theorem 3. Given a signature database with n signatures and a threshold vector t that divides each dimension of the search space into d ranges, under the random drop assumption, the expected number of LP calls invoked by the depth-first algorithm shown in Table 3 to label a single spectrum with m labels is:  
190	 C Single = d    n -1 X  
191	 k =0 d k  ,,1-,,1- 1d  
192	 k « m «!+1 (6)  
193	 Proof. The spectrum labeling process is equivalent to the node coloring game. The complete search tree as shown in Figure 3 has n levels (counting from 0). Each non-leaf node has d children. For each level k, there are d k equivalent nodes. According to Lemma 3, the probability of a non-leaf at level k being black is P(k), so the average number of black nodes at level k is d k  P (k). Adding up the number of black nodes at each non-leaf level gives us the number of black nodes in the tree: P n -1 k =0 d k  P (k). Combining the result of Lemma 2, we have the total number of LP calls invoked by the basic depth first search algorithm as: C  
194	 Single = d  `P n -1 k =1 d k  P (k) ´+1. Replacing P(k) with  
195	 the formula given in Lemma 3 leads to the formula (6) stated in this theorem.  
196	 When k is large, P (k) is reduced to m d k and formula (6) is approximately equivalent to:  
197	 C Single  d  (n - 1)  m (7)  
198	 This suggests that the number of LP calls invoked by the algorithm is linear in the number of labels for the input spectrum. 5.3 Cost of Group Labeling  
199	 When we go from single spectrum labeling to labeling a group of spectra, the analysis is complicated further by the fact that data distribution has a significant impact on performance. In this subsection, we first propose a simple model to characterize data distribution, and then analyze the cost of the two group labeling algorithms. Our analysis of the relationship between data distribution and algorithm cost, leads to the discussion of cost-based algorithm selection in Section 6.  
200	 5.3.1 A Model of Data Distribution  
201	 As discussed in Section 3, the majority of spectra in groups that we want to label tend to be very similar to each other. A simplified way to model this is that most spectra in a group are identical, while the rest are random noise or `impurities' with great variance. Following this intuition, we model a group of w spectra as s identical spectra mixed with w - s random `noise' spectra which are greatly different from each other.  
202	 While this is an overly simplified model of the data, note that the number of identical spectra s is just a conceptual parameter which describes the `diversity'(or `variance') of the data. Of course, more complicated statistical tools, such as Chi-Square testing [4] and other deviation detection and characterization methods [2] can be adopted for characterizing the data. The simple model we propose, however, suffices for a cost analysis aimed at estimating the relative performance of DFSVoting and GenTest.  
203	 5.3.2 DFSVoting  
204	 The DFSVoting algorithm proposed in Section 4 is a direct extension of the depth-first algorithm for single spectrum labeling. All the analysis for the single spectrum case still holds, with the difference that we now have a group of painters voting for the color of a non-leaf node.  
205	 According to the notation in Table 6, we have a group of w spectra, within which s spectra are the same. The group labeling algorithm will look for all the labels that are common to at least t = w  M in Sup spectra. We again assume each spectrum has m labels. 5 The node coloring game for single spectrum labeling then becomes the group node coloring game described below.  
206	 There are w painters in the game, and each has m black balls. They randomly drop the balls onto the leaf nodes. For a particular node N , a painter votes yes if at least one of his black balls is in N 's subtree. A node is painted black if at least t = w  M in Sup painters vote yes.  
207	 As described in Section 4, if a node has v votes (v  t), it is painted black and v LP calls are issued for each of its children; otherwise, the node is `white', and is pruned. In addition, the root node requires w LP calls. The cost of DFSVoting is therefore:  
208	 C V oting = w + d  #V otes got by all black nodes (8)  
209	 Lemma 4. In the group node coloring game, if there w painters independently vote for the color of the nodes, the  
210	 5  
211	 This is a strong assumption. If spectra differ a lot, the size of label sets may vary greatly. However, when the majority of spectra are similar, this is a reasonable simplification. probability that a particular node at level k receives v votes is:  
212	 P V ote(v, w) = C v w  P (k) v  (1 - P (k)) w -v (9)  
213	 Proof. As shown in Theorem 3, for a non-leaf node at level k, the probability that a painter drops at least one black ball in N 's subtree is P (k). Thus, with a probability P (k), node N will get a vote from a particular painter. Since all the painters make independent decisions, given a group of w painters, the probability that node N receives v votes is:  
214	 P V ote(v, w) = C v w  P (k) v  (1 - P (k)) w -v  
215	 Lemma 4 studies the situation when painters make decisions independently. We now extend it to the case when some of them always make the same decision, and in turn estimate the number of LP calls invoked by a particular node.  
216	 Lemma 5. Following the notation in Table 6, let t = w  M in Sup . Given a group of w spectra of which s are identical, under the random drop assumption the expected number of LP calls invoked at a particular non-leaf node at level k in the search tree is:  
217	 N odeCost(k) = P (k)  
218	 "P w v =max(t,s) C v -s w -s P (k) v -s (1 - P (k)) w -v  d  v "+  
219	 (1 - P (k))  `P w -s v =t C v w -s P (k) v (1 - P (k)) w -s-v  d  v ´(10)  
220	 Proof. When there are s identical spectra in the group of w spectra, the DFSVoting algorithm described in Section 4 will act as if s painters out of w are `identical' (making exactly the same decision all the time), which means a node will either get all the votes of those s painters or lose all their votes. Apart from the s identical painters, the remaining painters still vote independently, as before. According to Lemma 4, the probability that node N receives v 1 votes from the remaining w - s painters is P V ote(v 1 , w - s). If s identical painters all vote for node N , then the probability of node N receiving v (w  v  s) votes is P V ote(v - s, w - s). If (and only if) a node receives v votes, v  t, we invoke v LP calls for each of its d children. Thus, the expected number of LP calls invoked at node N under the precondition that s identical painters all vote for N is:  
221	 E yes = w X  
222	 v =max(t,s) P V ote(v - s, w - s)  d  v (11)  
223	 Similarly, the expected number of LP calls invoked by node N under the precondition that s identical painters all vote no at node N is:  
224	 E no = w -s X  
225	 v =t P V ote(v, w - s)  d  v (12)  
226	 Since s identical painters act alike, they vote yes at node N with probability P (k), and vote no with probability 1 P (k). Combining this with formula (11) and formula (12), we arrive at the overall estimated number of LP calls invoked at node N : P (k)  E yes + (1 - P (k))  E no , which is the same as formula 10 given in this theorem.  
227	 This leads us to the formula estimating the overall cost of the DFSVoting algorithm.  
228	 Theorem 4. Assume there are w spectra in the group, each of which has m solutions, and that s of them are identical. Under the random drop assumption, given a signature data base of n signatures, and a discretization that divides each dimension of the search space into d ranges, the expected number of LP calls in the DFSVoting algorithm is:  
229	 C V oting = w + n -1 X  
230	 k =0 d k  N odeCost(k) (13)  
231	 .  
232	 Proof. Given a signature database of n signatures, the search tree of DFSVoting has n levels. There are d k equivalent nodes at level k. According to Lemma 5, a particular node at level k will invoke N odeCost(k) LP calls. So the expected number of LP calls invoked at level k is d k  N odeCost(k). Adding the LP calls invoked at each non-leaf level plus the w LP calls at the root gives us an estimate of the total number of LP calls invoked by the algorithm: C  
233	 V oting = w + P n -1 k =0 d k  N odeCost(k).  
234	 5.3.3 GenTest  
235	 Theorem 5. Suppose that randomly selected spectra from a group follow the same data distribution as the group. Following the notation in Table 6, if we are given a signature database of n signatures, and a discretization that divides each dimension of the search space into d ranges, under the random drop assumption the expected number of LP calls invoked by the GenTest algorithm is:  
236	 C GenT est  d  (n - 1)  m  (w - t + 1)+ `(w-t+1)(1s w ) + 1 ´m(t-1), (14)  
237	 where t = w  M in Sup .  
238	 Proof. The GenTest algorithm described in Section 4 has two phases, and we analyze the cost of each phase below.  
239	 Candidate Generation Phase: GenTest selects w t + 1 spectra from the group. For each of these spectra, it generates a label set. The cost of searching for the label set for a single spectrum is C Single , from Theorem 3. Therefore, the number of LP calls invoked for generating the candidate labels is:  
240	 C Single  (w - t + 1) (15)  
241	 Test Phase: The GenTest algorithm takes every generated candidate label and tests it on the remaining t - 1 spectra. In the generation phase, (w - t + 1) spectra are randomly selected. According to the assumption that the randomly selected spectra follow the same data distribution as the original group, there will be s w  (w - t + 1) identical spectra with the same m labels and (1 s w )  (w - t + 1) spectra that have distinct labels. So the total number of candidates generated will be `(1s w )  (w - t + 1) + 1 ´m.  
242	 Since each `test' invokes an LP call, the total number of LP calls invoked in this phase is the number of candidates times the number of remaining spectra:  
243	 (t - 1)  m  "(1s  
244	 w )  (w - t + 1) + 1 " (16) Adding the cost of the generation and test phases gives us the total number of LP calls invoked by GenTest:  
245	 C GenT est = C Single  (w - t + 1)+ (t - 1)  m  `(1s w )  (w - t + 1) + 1 ´ (17)  
246	 Substituting C Single with equation (7), we have C GenT est  d(n-1)m(w-t+1)+(t-1)m `(1s w )  (w - t + 1) + 1 ´.  
247	 6. ALGORITHM SELECTION  
248	 We can use the cost formulae for DFSVoting and GenTest to estimate the cost of both DFSVoting and GenTest. Evaluating these formulae at optimization time has two drawbacks: (1) The calculation of C V oting involves very high precision floating point arithmetic, which is rather costly. (2) It is hard to tune the cost estimates in cases when there is significant discrepancy between the estimates and the observed real cost.  
249	 In this section, we propose an approach to algorithm selection that relies on precomputing decision plots, which essentially capture the performance tradeoffs between algorithms. The precomputation approach also highlights an important point: Even if closed-form formulae cannot be derived to accurately predict algorithm costs, unlike the case for DFSVoting and GenTest, a promising approach is to start with a rough initial estimate for a decision plot and to apply machine learning or statistical modeling techniques to refine the estimate.  
250	 6.1 Algorithm Profile  
251	 Using the cost analysis discussed in Section 5, we can plot the relation between M in Sup and cost for a given group of spectra, assuming that the number of identical spectra in the group, s, is also known or can be estimated. Figure 4 shows a series of graphs derived from the calculation of formulae (13) and (17). The y-axis in those graphs is the estimated number of LP calls invoked by the algorithm. The x-axis represents the M in Sup value specified by the user. These graphs characterize the performance characteristics of the two algorithms with respect to input data. We call such a graph an algorithm profile. We focus on the case when the group size is fixed, for simplicity; otherwise, this adds an extra dimension to the algorithm profile.  
252	 The group size in the algorithm profile shown in Figure 4 is set to be 1000. Each graph in the series corresponds to a particular s value shown in the upper right corner. As we can see in the algorithm profile, the lines for DFSVoting and GenTest intersect, which indicates that the choice of M in Sup will change the algorithm of choice for a given group of spectra. From the series of graphs shown in Figure 4, we also notice that the intersection point varies with s. Thus, the choice of algorithm should be based on both the value s (data distribution) and M in Sup (an analysis threshold).  
253	 6.2 Decision Plots  
254	 If we plot algorithm costs as a function of M in Sup on the y-axis and s on the x-axis, each point in the space corresponds to a choice of algorithm. What we are really looking for is an approximate separation of the space so that in one region, the DFSVoting algorithm is faster and in the other region, the GenTest algorithm is faster. Since the decision of algorithm selection can be made simply by looking up this 0 0.2 0.4 0.6 0.8 1 0 0.5 1 1.5 2 x 10 5 w=1000, s=100  
255	 support #LP calls  
256	 0 0.2 0.4 0.6 0.8 1 0 0.5 1 1.5 2 x 10 5 w=1000, s=200  
257	 support #LP calls  
258	 0 0.2 0.4 0.6 0.8 1 0 0.5 1 1.5 2 x 10 5 w=1000, s=300  
259	 support #LP calls  
260	 0 0.2 0.4 0.6 0.8 1 0 0.5 1 1.5 2 x 10 5 w=1000, s=400  
261	 support #LP calls  
262	 0 0.2 0.4 0.6 0.8 1 0 0.5 1 1.5 2 x 10 5 w=1000, s=500  
263	 support #LP calls  
264	 0 0.2 0.4 0.6 0.8 1 0 0.5 1 1.5 2 x 10 5 w=1000, s=600  
265	 support #LP calls  
266	 0 0.2 0.4 0.6 0.8 1 0 0.5 1 1.5 2 x 10 5 w=1000, s=700  
267	 support #LP calls  
268	 0 0.2 0.4 0.6 0.8 1 0 0.5 1 1.5 2 x 10 5 w=1000, s=800  
269	 support #LP calls  
270	 0 0.2 0.4 0.6 0.8 1 0 0.5 1 1.5 2 x 10 5 w=1000, s=900  
271	 support #LP calls  
272	 DFSVoting GenTest  
273	 Figure 4: Algorithm Profile  
274	 precomputed information, we call such a graph a decision plot.  
275	 More abstractly, a decision plot for group labeling algorithms is a function f (M in Sup, s), which takes M in Sup and s as the input and outputs the group algorithm to use. The concept of a decision plot can be easily extended to deal with multiple algorithms, in which case, the whole space is divided into several regions. Each region corresponds to a particular algorithm, which is expect to perform best in that region (defined by data and analysis parameters). We can think of this extended decision plot as a Voronoi diagram [17]. Of course many other extensions can also be explored.  
276	 To choose a group labeling algorithm based on data distribution and a minimum support threshold, a decision plot can be derived from the algorithm profile shown in Figure 4. Given a fixed group size w, we use M in Sup as the yaxis and s/w as the x-axis, and mark each point (identified by a &lt; M in Sup, s/w &gt; pair) with the corresponding best algorithm, as indicated by the algorithm profiles. It gives us the graph shown in Figure 5. As we can see, the graph can be divided into two regions. The smaller triangle region corresponds to the case when GenTest is better and the other region represents the case when DFSVoting is better. It is worth noting that the boundary between regions corresponds to the intersection points in the algorithm profiles. In our particular case, the boundary of these two regions is approximately two straight lines, which suggests that we can simply fit two linear functions of M in Sup and s to approximate the real decision plot. We study this approach experimentally in Section 7.  
277	 6.3 Algorithm Selection Framework  
278	 6.3.1 Estimating Data Distribution  
279	 Given a decision plot and a group of spectra to label, we still need a data distribution parameter s to `lookup' the decision plot and make a choice of group labeling algorithm. Throughout the cost analysis in Section 5, we assumed that the value s is the number of identical spectra in the group. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1  
280	 s/w support Choose DFSVoting Choose GenTest  
281	 Figure 5: Decision Plot  
282	 A direct approach to estimating this value is to divide the group of spectra into clusters whose diameters are smaller than a certain threshold and use the size of the largest cluster as the value of s. Many clustering algorithms [3, 5, 8, 26] and random sampling [24] algorithms can be applied here.  
283	 6.3.2 System Graph  
284	 Now that we have discussed all the components in our algorithm selection framework, we put the pieces together in Figure 6. A given group of spectra to label first goes through the data distribution estimator, which estimates its data distribution parameter. The algorithm selector takes the estimated data distribution parameter (s), user-specified analysis parameters (e.g., M in Sup) and looks up the decision plot to select the best algorithm. The mining engine then applies the algorithm to the input group of spectra and outputs the group label set.  
285	 In Figure 6 there are also two lines going from the output to the algorithm profile builder and data distribution estimator. This indicates that the output can serve as `ground truth' to tune the data distribution estimator and algorithm profile. When the algorithm profile component accumulates enough data, it can in turn update the decision plot with more accurate information. In the experimental system we have built, these two feedback loops from the final output are not implemented yet. Section 7 provides more details and experimental results on the rest of the components and focuses on validating the decision plot for group labeling constructed using the theoretical cost analysis.  
286	 Group of Spectra  
287	 Data Distribution Estimator  
288	 Algorithm Selector  
289	 Decision Table Mining Engine  
290	 Group Label Set Algorithm Profile User Defined Parameters  
291	 Table lookup  
292	 Algorithm  
293	 Figure 6: System Graph  
294	 7. EXPERIMENTAL RESULTS 7.1 Experimental Setting  
295	 The spectra we used in our experiments are collected from an Aerosol Time-of-Flight Mass Spectrometer. The signature database, obtained from domain experts in atmospheric aerosols, is essentially a collection of isotope distributions of chemical ions they want to detect. There are 197 signatures in the signature database, and each signature or spectrum has 255 dimensions. Notice that the performance bottleneck is not in the size of the `signature database'. Rather, it is in the number of spectra to be labeled in a given amount of time (recall that our application involves monitoring a stream of spectra), and the cost is dominated by CPUintensive LP calls, rather than I/O intensive disk accesses. Analogous to how a traditional DBMS seeks to minimize the cost of disk accesses, our goal is to minimize the cost of LP computation. The experimental system is implemented in C++ and runs on a 512M memory PC with Linux.  
296	 Throughout our experiments, the error bound E is set to 0.05 (a value selected heuristically after some experimentation). The threshold vector t = [t 1 , . . . , t d +1 ] used is t = [0, 0.1, 0.4, 1]. This threshold vector divides the relative quantity of a chemical element into three ranges, [0,0.1), [0.1,0.4) and [0.4,1), with each range corresponding to the state of `missing', `present', and `abundant' respectively.  
297	 7.2 The Choice of Cost Metric  
298	 Throughout the cost analysis in Section 5, we used the number of LP calls as the cost metric, assuming that the number of LP calls invoked is proportional to the execution time of the algorithm. However, the time cost of a particular LP call may vary due to differences in constraints and the context of a particular LP task. To study whether the choice of LP call as a cost unit is justified, we randomly selected spectra, and recorded the number of LP calls and execution time required to label each of them. Figure 7 plots the results of our experiment, where the x-axis is the number of LP calls invoked by a particular task and the y-axis is the execution time for that task. As shown in the graph, the relation between execution time and number of LP calls invoked is clear: The execution time is proportional to the number of LP calls invoked.  
299	 0 200 400 600 800 1000 0 0.5 1 1.5 2 2.5 3x 10 6  
300	 #LP calls execution time (in microseconds)  
301	 Figure 7: Number of LP calls vs.Execution Time  
302	 7.3 Algorithm Profiles and Decision Plots  
303	 For the algorithm selection framework we propose, we want to study two issues via experiments: (1) How does the algorithm profile derived from the cost estimation formula match the actual algorithm profile and how good is the cost estimation in terms of deriving the right decision plot? (2) How good is the decision plot derived from the theoretical cost model, in terms of providing the correct information for algorithm selection? In all the experimental data shown in this subsection, the group size is set to be 1000 spectra, while the error bound and threshold vector remain the same as those described in Section 7.1.  
304	 0 0.2 0.4 0.6 0.8 1  
305	 0  
306	 0.5  
307	 1  
308	 1.5  
309	 2  
310	 2.5 x 10 5     w=1000, s=100  
311	 support  
312	 #LP calls  
313	 0 0.2 0.4 0.6 0.8 1 0 0.5 1 1.5 2 2.5 x 10 5     w=1000, s=200  
314	 support #LP calls  
315	 0 0.2 0.4 0.6 0.8 1 0 0.5 1 1.5 2 2.5 x 10 5     w=1000, s=300  
316	 support #LP calls  
317	 0 0.2 0.4 0.6 0.8 1  
318	 0  
319	 0.5  
320	 1  
321	 1.5  
322	 2  
323	 2.5 x 10 5     w=1000, s=400  
324	 support  
325	 #LP calls  
326	 0 0.2 0.4 0.6 0.8 1 0 0.5 1 1.5 2 2.5 x 10 5     w=1000, s=500  
327	 support #LP calls  
328	 0 0.2 0.4 0.6 0.8 1 0 0.5 1 1.5 2 2.5 x 10 5     w=1000, s=600  
329	 support #LP calls  
330	 0 0.2 0.4 0.6 0.8 1  
331	 0  
332	 0.5  
333	 1  
334	 1.5  
335	 2  
336	 2.5 x 10 5     w=1000, s=700  
337	 support  
338	 #LP calls  
339	 0 0.2 0.4 0.6 0.8 1 0 0.5 1 1.5 2 2.5 x 10 5     w=1000, s=800  
340	 support #LP calls  
341	 0 0.2 0.4 0.6 0.8 1 0 0.5 1 1.5 2 2.5 x 10 5     w=1000, s=900  
342	 support #LP calls  
343	 DFSVoting (Actual) GenTest (Actual) Naive (Actual) DFSVoting (Predict) GenTest (Predict)  
344	 Figure 8: Experimental Result of Algorithm Profile (w=1000, n =197)  
345	 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1  
346	 s/w support (a) Decision Plot(Synthesized Data)  
347	 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1  
348	 s/w support (a) Decision Plot (Theory)  
349	 Choose GenTest Choose DFSVoting  
350	 Figure 9: Experimental Result of Decision plot (w=1000, n =197)  
351	 7.3.1 Algorithm Profile  
352	 Figure 8 shows both the predicted algorithm profile and real algorithm profile for DFSVoting and GenTest. The group size w in this series of experiments is fixed at 1000 while the number of identical spectra s in the group varies from 100 to 900. Each graph shown in Figure 8 corresponds to a particular s (100, 200, ..., 900) in order from left to right and top to bottom. The series with small circles on the top of each graph shows the cost of the brute-force approach which labels all the spectra one by one. 6 The series with stars in each graph are for DFSVoting and the series with plus signs stand for GenTest. Solid lines show the real  
353	 6  
354	 Due to the variance of average number of labels of each spectrum, the cost of brute-force approach varies from dataset to dataset experimental results while the dotted lines are theoretical predictions plotted for comparison.  
355	 As we can see in these graphs, the theoretical prediction matches the experimental results in terms of general shape and rough absolute values. It is worth noting that both the theoretical line and experimental line of DFSVoting drop sharply around the support value of s/w, which is the point at which we have almost no group labels due to the high minimum support. While it is clear that the analytical cost estimation does not precisely predict the cost of each algorithm, it does a good job of predicting the cross-over points of the two algorithms and their relative performance, which is what we really care about for cost-based optimization: in the graphs in Figure 8 the theoretical lines cross each other at almost the same support value that the real experimental lines cross.  
356	 Going further as suggested in Section 6.2, we plot two decision plots for experimental results and theoretical prediction, respectively, in Figure 9. The left graph shows the decision plot plotted from experimental results. The right graph shows the decision table plotted from theoretical prediction. The plus signs stand for the case when the DFSVoting algorithm is better while zero signs represent the case when the GenTest algorithm is better. The two decision plots are almost exactly the same, except for four points on the lower boundary of the two regions.  
357	 For those cases where the theoretical decision plot conflicts with the real decision plot, we can see from the algorithm profile graph that the extra LP calls incurred by the wrong choice is less than 10% of the cost of the optimal algorithm. This is tolerable.  
358	 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1  
359	 s/w support Choose DFSVoting Choose GenTest  
360	 Figure 10: Decision plot for Randomly Selected Data, w=1000  
361	 7.3.2 Decision Plots  
362	 Figure 10 summarizes a series of experiments designed to explore the idea of performing algorithm selection by looking up the decision plot. A plus represents the case when DFSVoting is better and a zero sign stand for the case when GenTest is preferred. The solid lines separating the graph into two regions are derived from theoretical cost model. Points to the right of those lines are cases where GenTest algorithm is predicted to be faster. Points to the left of those solid lines are the cases where DFSVoting is predicted to be faster. As we can see in the graph, the solid line almost perfectly separate the plus signs and zero signs, with only a few exceptions near the borders, indicating that the decision plot derived from the theoretical cost model almost perfectly predicts the best algorithm.  
363	 7.4 Scalability  
364	 We now consider the scalability of the two proposed algorithms. We fixed the value of M in Sup at 70%. The percentage of `identical spectra' s/w is set to be 80%. Figure 11 shows the cost growth of each algorithm with respect to the growth of group size. Each point on the graph is the average of experimental results over 20 selected groups of spectra such that the group size w is the same for all these 20 groups. As we can see in the graph, both algorithms' costs grow linearly with respect to the group size.  
365	 Experiments with other M in Sup and s/w values have consistently shown similar results to the one shown in Figure 11, and are omitted.  
366	 0 1000 2000 3000 4000 5000 0 1 2 3 4 5 6 7 8 9 x 10 5 s/w = 80%, support=70%  
367	 Group Size #LP calls GenTest DFSVoting  
368	 Figure 11: Scalability over group size, s/w=80%, support=70%  
369	 8. FROM MASS SPECTRA TO MASS MAR 
370	 KET  
371	 In previous sections, we were focused on the spectrum labeling problem. In this section, we discuss promising connections between the spectral labeling framework and market basket analysis. An obvious connection is that after a spectrum is labeled, we can treat it as an itemset containing the detected ions, and apply the wealth of results about itemset mining for further analysis. This is a significant benefit, since it allows us to apply powerful and widely available tools to the new problem of analyzing streams of mass spectra.  
372	 There is also a deeper and surprising connection in the other direction; we might well have a promising tool for market basket analysis in spectral labeling. In the spectrum labeling framework, we have a signature database, which represents the domain knowledge, containing profiles for chemical elements of interest. Using this, for a given spectrum we compute a label, which is essentially the most likely combination in which the known chemical ions appear in the spectrum.  
373	 If we replace chemical ion signatures by customer buying patterns that indicate underlying phenomena of interest, as suggested by McCarthy [16], and substitute input spectra with a customers `market basket (purchases in a single visit to a store), then labeling offers a description of the customer by decomposing the market basket into the most plausible combination of known purchasing patterns corresponding to phenomena of interest.  
374	 For example, if we know the typical buying pattern of a doting father is a lot of toys and a few pencils, and a low income customer usually purchases a lot of chicken but very little seafood, our signature database would contain the buying patterns of these two types of customers. When a market basket containing a lot of toys, some pencils, a lot of chicken but, no seafood is encountered, labeling will categorize that particular customer as a poor man but a doting father. In another purchase where the market basket contains a lot of toys but no food, labeling will describe the customer as a doting father, but will not be able to detect whether he is poor or rich. Such analysis was suggested as a significant direction for data mining research, called phenomenal data mining, in McCarthys visionary paper [16], and labeling offers promise as a tool with which to attack this intriguing application domain.  
375	 9. RELATED WORK  
376	 To our knowledge, this is the first paper to discuss labeling of groups of mass spectra, or to address cost-based data mining algorithm selection. The idea of a data mining language or framework has been explored by many researchers. In [11], Imielinski and Mannila described their vision of a data mining system, including a language specification and a general discussion of components for query compilation and execution. [12] proposed a unified algebra for multi-step data mining. [7] proposed a universal data mining model consisting of a data view, a model view and a process view. [28, 29] proposed general data mining architectures and discussed extending a DBMS with mining capabilities.  
377	 The cost analysis methodology used in this paper is similar to the analysis of the cost of index seek in [25]. An average case analysis of branch-and-bound algorithms is presented by Zhang et. al in [27]. Various aspects of numerical optimization are studied in [18]. More details on estimating the number of labels and the volume of a spectrum's solution space can be found in [14, 13, 15]. [4, 21] discuss how to describe data distributions. Clustering based techniques are surveyed in [3].  
378	 More information about spectrum labeling and environmental monitoring is provided in [10, 6, 23]. Labeled spectra are related to market baskets, to which a number of methods based on association rule mining and can be directly applied, e.g., [1, 9, 22]. Further extensions to a broader concept of phenomenal data mining is introduced in [16].  
379	 10. REFERENCES  
380	 [1] R. Agrawal et al. Mining association rules between sets of items in large databases. In ACM SIGMOD, 1993.  
381	 [2] A. Arning et al. A linear method for deviation detection in large databases. In ACM KDD, 1996.  
382	 [3] P. Berkhin. Survey of clustering data mining techniques. Technical report, Accrue Software, San Jose, CA, 2002.  
383	 [4] K. A. D. Peter J. Bickel. Inference in the multiparameter case, Chapter 6. Prentice Hall, 2 edition, 2001.  
384	 [5] C. H. Cheng et al. Entropy-based subspace clustering for mining numerical data. In ACM KDD , 1999.  
385	 [6] E. Gard, Jet. al. Real-time analysis of individual atmospheric aerosol particles: Design and performance of a portable atofms. In Anal. Chem., pages 4083­4091, 1997.  
386	 [7] I. Geist. A framework for data mining and kdd. In SAC, 2002.  
387	 [8] S. Guha, N. Mishra, R. Motwani, and L. O'Callaghan. Clustering data streams. In IEEE Symposium on Foundations of Computer Science, 2000.  
388	 [9] J. Han, J. Pei, and Y. Yin. Mining frequent patterns without candidate generation. In 2000 ACM SIGMOD, 2000.  
389	 [10] Citation details omitted for anonymity  
390	 [11] T. Imielinski and H. Mannila. A database perspective on knowledge discovery. In Comm. Of The Acm, 39:58­64, 1996.  
391	 [12] T. Johnson et al. The 3w model and algebra for unified data mining. In The VLDB Journal, 2000.  
392	 [13] J. B. Lasserre. The integer hull of a convex rational polytope. In Math. Oper. Res., 2003.  
393	 [14] J. B. Lasserre. A laplace transform algorithm for the volume of a convex polytope. volume 48, 2003.  
394	 [15] J. B. Lasserre and E. S. Zeron. On counting integral points in a convex rational polytope. In Math. Oper. Res., 2003.  
395	 [16] J. McCarthy. Phenomenal data mining. In Communications of the ACM 43(8), 2000.  
396	 [17] T. M. Mitchell. Machine Learning. WCB/McGraw-Hill, 1997.  
397	 [18] J. Nocedal and S. J. Wright. Numerical Optimization. Springer, 1 edition, 1999.  
398	 [19] National Research Council. Research Priorities for Airborne Particulate Matter. Immediate Priorities and a Long-Range Research Portfolio. 1998, National Academy Press, Washington, DC.  
399	 [20] K. A. Prather et al. Real-time characterization of individual aerosol particles using time-of-flight mass spectrometry. Anal. Chem., 1994; 66, 1403-1407.  
400	 [21] O. P. Rud. Data Mining Cookbook: Modeling data for marketing, risk, and CRM. Wiley, 1 edition, 2001.  
401	 [22] R. Srikant and R. Agrawal. Mining quantitative association rules in large relational tables. In ACM SIGMOD, 1996.  
402	 [23] D. Suess and K. Prather. Mass spectrometry of aerosols. In Chemical Reviews, pages 3007­3035, 1999.  
403	 [24] H. Toivonen. Sampling large databases for association rules. In VLDB, 1996.  
404	 [25] S. Yao. Approximating block accesses in database organizations. In Communications of the ACM 20(4), pages 260­261, 1977.  
405	 [26] T. Zhang et al. BIRCH: an efficient data clustering method for very large databases. In ACM SIGMOD, 1996.  
406	 [27] W. Zhang and R. Korf. An average-case analysis of branch-and-bound with applications: Summary of results. In AAAI, 1992.  
407	 [28] R. Meo et al. A tightly-coupled architecture for data mining. In ICDE, pages 316­322, 1998.  
