0	 Approximate XML Query Answers  
1	 Neoklis Polyzotis Minos Garofalakis Yannis Ioannidis  
2	 University of California, Santa Cruz Bell Labs, Lucent Technologies University of Athens, Hellas  
3	 alkis@cs.ucsc.edu minos@research.bell-labs.com yannis@di.uoa.gr  
4	 ABSTRACT  
5	 The rapid adoption of XML as the standard for data representation and exchange foreshadows a massive increase in the amounts of XML data collected, maintained, and queried over the Internet or in large corporate datastores. Inevitably, this will result in the development of on-line decision support systems, where users and analysts interactively explore large XML data sets through a declarative query interface (e.g., XQuery or XSLT). Given the importance of remaining interactive, such on-line systems can employ approximate query answers as an effective mechanism for reducing response time and providing users with early feedback. This approach has been successfully used in relational systems and it becomes even more compelling in the XML world, where the evaluation of complex queries over massive tree-structured data is inherently more expensive.  
6	 In this paper, we initiate a study of approximate query answering techniques for large XML databases. Our approach is based on a novel, conceptually simple, yet very effective XML-summarization mechanism: T REE S KETCH synopses. We demonstrate that, unlike earlier techniques focusing solely on selectivity estimation, our T REE S KETCH synopses are much more effective in capturing the complete tree structure of the underlying XML database. We propose novel construction algorithms for building T REE S KETCH summaries of limited size, and describe schemes for processing general XML twig queries over a concise T REE S KETCH in order to produce very fast, approximate tree-structured query answers. To quantify the quality of such approximate answers, we propose a novel, intuitive error metric that captures the quality of the approximation in terms of both the overall structure of the XML tree and the distribution of document edges. Experimental results on real-life and synthetic data sets verify the effectiveness of our T REE S KETCH synopses in producing fast, accurate approximate answers and demonstrate their benefits over previously proposed techniques that focus solely on selectivity estimation. In particular, T REE S KETCH es yield faster, more accurate approximate answers and selectivity estimates, and are more efficient to construct. To the best of our knowledge, ours is the first work to address the timely problem of producing fast, approximate tree-structured answers for complex XML queries.  
7	 1. INTRODUCTION  
8	 Since its introduction six years ago, XML has evolved from a mark-up language for web documents to an emerging standard for data exchange and integration over the Internet. Being self-describing and hierarchical in nature, the XML data model is suitable for representing a diverse range of data sources and promises to enable the next-generation of search applications that will allow users to query effectively the information available on the Web.  
9	 Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage, and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. SIGMOD 2004 June 13-18, 2004, Paris, France. Copyright 2004 ACM 1-58113-859-8/04/06 . . . $ 5.00.  
10	 With the rapid growth of available XML data, one can expect a proliferation of on-line decision support systems that enable the interactive exploration of large-scale XML repositories. In a typical exploratory session, a domain expert poses successive queries in a declarative language, such as XQuery [4] or XSLT [7], and uses an appropriate visualization of the results in order to detect interesting patterns in the stored data. Obviously, the successful deployment of decision-support systems depends crucially on their ability to provide timely feedback to users' queries. This requirement, however, conflicts with the inherently expensive evaluation of XML queries which involve complex traversals of the data hierarchy, coupled with non-trivial predicates on the path structure and the value content.  
11	 Generating approximate answers is a cost-effective solution for offsetting the high evaluation cost of XML queries. In short, the system processes the query over a concise synopsis of the XML data and returns an approximation of the true result. Ideally, this approximate answer is computed very fast and is accurate in the sense that it preserves with low error the statistical traits of the true result. The user can then examine this "preview", assess the information content of the true answer, and decide whether it needs to be retrieved by executing the query over the base data. Overall, by providing the user with fast and accurate feedback on the form of the results, the system can reduce the number of queries that need to be evaluated in order to support effectively the data exploration task.  
12	 In a typical scenario, the result of an XML query is an XML fragment that is constructed by appropriate projections on the original data; an approximate answer, therefore, is an XML document that resembles the true answer in terms of hierarchical structure and value content. Clearly, the effectiveness of an approximate answering system hinges upon the existence of accurate synopsis structures that capture the key statistical characteristics of the base XML data and can thus produce low-error approximate answers to queries that project parts of it. Note that the problem of efficient XML summarization also arises in the context of selectivity estimation, where the synopsis is only used to estimate the size of the result. Approximating the structure of the result, however, is a strictly more complex problem since there are documents where the same query produces results of equal size but with very different structure. Summarizing, therefore, an XML document in order to compute approximate answers is more involved than building synopses for selectivity estimation, which in itself is known to be a hard problem [18].  
13	 Related Work 1 . Previous studies on approximate query answering [3, 10] have focused on the relational model, where the result  
14	 1 Due to space constraints, a more detailed overview of related work can be found in the full version of this paper [17] of a query is typically a multi-set of values. The key idea is to process a query over an appropriate relational synopsis (such as, histograms, wavelets, or sample-based summaries) and compute an approximation of the true value set. The proposed techniques and summarization methods, however, are suitable for flat relational data and are not easily extended to the case of general XML hierarchies.  
15	 As noted earlier, approximate XML query answering is closely tied to the problem of building effective XML synopses. Recent studies have looked at the related problem of summarizing XML data for estimating the selectivity of single XPath expressions [1, 12, 15, 16, 21, 22], or the number of binding tuples for twig queries [6, 9, 18]. Even though a selectivity estimate is essentially an approximate answer to an aggregate query (COUNT), the proposed summarization techniques do not store detailed enough information in order to approximate the structure of the query result.  
16	 Buneman et al. [2] have recently introduced a query-able compression scheme for tree-structured XML data. The proposed technique compresses the XML tree by using an appropriate bisimulation relation and evaluates an XPath query directly over the compressed instance. The goal, therefore, is to compute an exact answer to a path query, whereas our focus is on computing an approximate </i>answer to a <i>twig query, which typically involves the joint evaluation of multiple path expressions.  
17	 Our Contributions. In this paper, we initiate the study of approximate query answering for XML queries. In order to gain intuition on the complexity of the problem, this initial study focuses on approximate answers for twig queries with branching path expressions, i.e., we consider the structural part of the problem and ignore for now the value content of the document. As we show in this paper, even this constrained version is quite complex and requires non-trivial solutions. Our approach is based on a novel type of structural XML synopses, termed T REE S KETCH es, that capture, in limited space, the key properties of the underlying path distribution and enable low-error approximate answers for a large class of interesting XML queries. We develop a systematic query evaluation framework for generating approximate answers over concise T REE S KETCH synopses and describe an efficient construction algorithm for building an accurate T REE S KETCH summary within the constraints of a limited space budget. Finally, we present experimental results on real-life and synthetic data sets that demonstrate the effectiveness of our approach and its benefits over previously proposed techniques, not only for generating approximate answers, but also for enabling accurate selectivity estimation. To the best of our knowledge, ours is the first study to look into the problem of computing approximate answers for complex XML queries. More concretely, the key contributions of our work can be summarized as follows:  
18	   T REE S KETCH Summarization Model and Query Evaluation Framework. Our T REE S KETCH summarization model is based on the novel concept of count-stability which captures very effectively the intrinsic similarity of sub-structures in an XML document. Briefly, a T REE S KETCH summary represents a clustering of document elements, where each cluster represents elements with similarly structured sub-trees. We develop an efficient evaluation algorithm that processes a query over a concise T REE S KETCH and produces another T REE S KETCH synopsis that summarizes the structure of the result. Futhermore, we discuss how the same algorithm can be used to estimate the result size of a complex twig query.  
19	   Efficient T REE S KETCH Construction Algorithm. We describe an efficient heuristic algorithm that starts from a detailed summary and incrementally merges element clusters that are "close" in terms of element sub-structure. To make our algorithm applicable on large data sets, we devise an effective heuristic that limits the number of possible merges in every step, without compromising the quality of the resulting synopsis.  
20	   New Distance Metric for XML Documents. We argue that traditional graph-theoretic distance metrics, such as tree-edit distance, are not suitable for evaluating the quality of an approximate answer relative to the true result. To overcome this difficulty, we introduce a novel distance metric that quantifies the differences between two trees in terms of both the overall path structure and the distribution of document edges.  
21	   Experimental Study Verifying the Effectiveness of T REE S KETCH es. We validate our approach experimentally with an extensive study on real-life and synthetic data sets. Our results demonstrate that T REE S KETCH es perform consistently better than previously proposed summarization techniques: they enable more accurate approximate answers and selectivity estimates, and at the same time are more efficient to construct. Moreover, our scaling experiments with large data sets show that even small-size T REE S KETCH es are extremely effective in enabling low error selectivity estimates to complex twig queries (e.g., less than 5% estimation error for a 10KB summary of a 100MB input document). Combined with the affordable construction times of T REE S KETCH summaries, these results indicate that T REE S KETCH es constitute an effective and viable in practice solution for the structural summarization of large XML data sets.  
22	 2. BACKGROUND  
23	 XML Data Model. Following common practice, we model an XML document as a large, node-labeled tree ¡£¢¥¤§¦©¨£ . Each node  
24	  ¤ corresponds to an XML element and is characterized by a unique object identifier (oid) </i>and a <i>label </i>(or, <i>tag) assigned from some alphabet of string literals, that captures the element's semantics. Edges ¢©¦©   ¨ are used to capture the containment of (sub)element   under   in the database. (We use label ¢   ,  
25	 children ¢¥ to denote the label and set of child nodes for element node    ¤ .) As an example, Figure 1 depicts a sample XML data tree containing bibliographical data. The document consists of author elements, each comprising a name, and several  
26	 paper and book sub-elements. Each paper contains a title, a year of publication and one or more keywords, whereas a  
27	 book just gives its title. Note that element nodes in the tree are named with the first letter of the element's tag plus a unique identifier. Leaf elements in ¡ typically contain values, but our primary focus in this work is on approximately capturing and querying the label structure of an XML data tree, rather than the relevant value distributions.  
28	 !#&quot;  
29	 vvlll lll lll (( W W W  
30	 BB              
31	 $%  
32	 yyss ss s (( W W W  
33	  $'&amp;  
34	 ÒÒÕÕ Õ  
35	  (( W W W $'(  
36	 ÒÒÕÕ Õ  
37	  (( W W W  
38	 )#0  
39	 ÒÒÖÖ Ö  (( V V V 12 13 45  1 % &quot; 4 %6&amp;  
40	  7 %8(@9 %A0CB %8D )D  
41	 ÒÒÖÖ Ö  (( V V V 77 u u u u u )E  
42	 ÒÒÖÖ Ö  (( V V V 9 &amp;( ) 5 ÒÒÖÖ Ö  (( V V V 9 &amp;¥E  
43	 7 % 2 9 % 3 B %6E B % 5 7 &amp; &quot; 9 &amp;F%GB &amp;&amp; 7 &amp;60 9 &amp;DHB &amp; 2 Figure 1: Example XML Document. XML Query Model. We focus on XML twig queries, which represent the basic building block of declarative query languages for XML (including the XQuery [4] and XSLT [7] standards). Briefly, a twig query describes a complex traversal of the XML data tree and returns a tree-structured XML result constructed through the intertwined evaluation (i.e., structural join) of multiple path expressions (expressed in XPath [8]). Figure 2(a) depicts an example twig query over the document of Figure 1, where the I  's denote variable names that are bound to specific data elements during query evaluation. We model a twig query P as a node-labeled query tree ¡RQ , where (1) each node of ¡ Q is labeled with a variable name I  in P (with I#S being a distinguished root node always bound to the XML document root); and, (2) each edge ¢ I  ¦ I   of ¡TQ is annotated with an XPath expression UWVYXa` ¢ I  ¦ I   that describes the specific structural constraints specified in P between the data elements bound to I  and I  during evaluation. For instance, the query tree corresponding to our example twig query above is shown in Figure 2(b). Following the generalized tree pattern notation [5], we use dashed edges to separate paths that are specified in the twig's return clause and can thus have empty results without nullifying the result of the query.  
44	 for b'cd in //a[//b] for b'cfe in b'cd //p return  
45	 b'cd //n , for b'cg in b'c e //k return b'cg chS ii©p©q ihisrFt   
46	 c d iivu  ihisw ''  
47	 ce iisx  cy  
48	 c g ! S  
49	 ÓÓ×× ×× '' U U U U  
50	 $ e  
51	  '' U U U U $ g  
52	  (( X X X X X  
53	 )   
54	   ) 5  
55	   d S  
56	  e©e  es (a) (b) (c)  
57	 Figure 2: (a) Twig Query, (b) Query Tree, (c) Nesting Tree.  
58	 We consider twig queries using XPath expressions involving only the child and descendant-or-self axes (i.e., "/" and "//" operators) and may include existential branching predicates of the form "  l  ", where  l is, in general, a label path whose existence is required under a given parent node in the XPath expression. As an example, the "//a[//b]" predicate in Figure 2 specifies author tree nodes that are located at any depth under the current binding of variable I S (the document root) and have at least one book descendant. Intuitively, the evaluation of a twig query P proceeds by jointly evaluating all XPath expressions in P over the XML tree, and generating the full set of binding element tuples for P 's variables. Each such binding tuple essentially specifies an assignment of element nodes to all the I  query variables such that all structural constraints specified in the query's ¢ I ¦ I a edges are met. We will represent the binding tuples of a query P with a nesting tree £ ¢ P  , which contains all the elements of ¡ that appear in the bindings of different variables and in addition preserves their ancestor/descendant relationships as specified by the query paths. Figure 2(c) shows the nesting tree for the example query of Figure 2(b). Obviously, the nesting tree can be used to reproduce the binding tuples of a query and ultimately its result.  
59	 3. T REE S KETCH SYNOPSIS MODEL  
60	 3.1 General Graph-Synopsis Model  
61	 Abstractly, our general graph-synopsis model for an XML data tree ¡£¢¥¤§¦©¨ is defined by a partitioning of the element nodes in ¤ (or, equivalently, by an equivalence relation  ¤¤ ) that respects element labels; that is, if ¢ ©¦©Y   then label ¢ ¥ed label ¢   . The graph synopsis defined for ¡ by such an equivalence relation  , denoted by fhg ¢8¡i , can be represented as a graph, where: (1) each node j in f g ¢8¡i corresponds to an equivalence class of  , i.e., a subset of (identically-labeled) data elements in  
62	 ¡ (termed the extent of j and denoted by extent ¢ j  ); and, (2) an edge ¢  ¦ j  exists in f g ¢8¡k if and only if some element node in  
63	 extent ¢   has a child element in extent ¢ j  . (We use label ¢ j  to denote the common label of all data elements in extent ¢ j  .)  
64	 At a high level, several recently-proposed techniques for building path-index structures for XML (including l -indexes [14] and A( m )-indexes [11]), as well as statistical summaries for XML databases (including XS KETCH es [15, 16] and twig-XS KETCH es [18]) are all based on the abstract "node-partitioning" idea described above. As an example, the basic twig-XS KETCH summary mechanism, which targets selectivity-estimation of complex twig queries, augments our general graph-synopsis model with (1) per-node count information that records the size of each synopsis node's extent, (2) localized per-edge stability information, indicating whether the synopsis edge is backward- and/or forward-stable</i>, and (3) <i>edge distribution information, that captures the distribution of child counts for the elements in the node's extent, across different stable ancestor or descendant edges. These localized edge distributions are maintained selectively on a per-node basis in the form of edge histograms, and essentially enable the computation of selectivity estimates for twig queries. For a simple example, consider a synopsis node  and two emanating synopsis edges on j and pnrq . A two-dimensional edge histogram sut ¢6v d ¦v e  would capture the fraction of data elements in extent ¢   that have exactly v d children in extent ¢ j  and v e children in extent ¢ q  .  
65	 Limitations of Selectivity-Estimation Synopses. Given the amount of earlier work on XML summarization and the number of alreadyexisting synopsis data structures for XML, a natural question that arises is whether there is a real need for a new summarization mechanism for approximate XML query answering. Our key observation here is that the focus of all earlier work in the area has been on the problem of selectivity estimation (for XPath expressions [15, 16] or twig queries [6, 18]) and, unfortunately, even the state-of-the-art solutions for XML selectivity estimates prove to be inadequate in accurately capturing the complete tree structure of the underlying document.  
66	 We illustrate our observation with a simple example on twigXS KETCH synopses (we focus on the twig-XS KETCH model since it also uses a graph-synopsis and it is applicable in the general case of schema-less documents.) Consider the two XML document trees ¡ d and ¡ e shown in Figure 3(a,b). Both documents have the same set of distinct label-paths and differ only in the number of v children for the different w elements (the corresponding counts/multiplicities are shown along the edge). It is straightforward to verify that any twig query will have the same selectivity in either of the two documents and, in effect, both documents map to the same, zero-error twigXSKETCH synopsis, shown in Figure 3(c), with the (exact) edge histograms for nodes x and y depicted in Figure 3(d). Consider, for instance, the twig query P shown in Figure 3(e). Using the twig-XS KETCH and the methodology in [18], we can estimate its selectivity s zv¢ P  with the expression s zv¢ P hd|{ extent ¢ x '{}'~@©  su ¢ w h} s ¢6vk{ w h} w }#v , which yields the same (accurate) estimate of l' for both documents  
67	 ¡ d and ¡ e . Note, however, that the tree structure for the binding tuples of P is in fact very different across our two example documents. For example, looking at the edge distribution in the query result, for document ¡ d , each x element appears in  binding tuples, while for document ¡ e , one element (  d ) appears in  tuples and the other (  e ) appears in  tuples. This type of information is not captured by the twig-XS KETCH synopsis, since it does not affect the overall selectivity estimate.  
68	   
69	 ÔÔØØ Ø '' T T T  
70	  d ÔÔÙÙ Ù   e  &amp;&amp; S S S  
71	   
72	 d    
73	 y    
74	 d    
75	 y     d   
76	 ÔÔØØ Ø '' T T T  
77	  d ÔÔÙÙ Ù   e  &amp;&amp; S S S  
78	   
79	 d    
80	 d    
81	 y    
82	 y     e ¥  
83	 B i F   8  
84	 B i F  kA   
85	 B i F   ¥h (a) (b) (c)  
86	       2 1  
87	      f   2 1 1/2 2 4 1/2 c S  
88	 iis   
89	 c#d  
90	     
91	 ce  
92	 ¡   
93	 chg   
94	 e    
95	 d  d (( V V V V  
96	   
97	 d    
98	 y ÒÒÖÖ ÖÖ  
99	    
100	 d  d (( X X X X  
101	   
102	 e    
103	 e    
104	 d    
105	 y ÒÒÕÕ ÕÕ  
106	  ¢ g £ d  ¢ g  e   
107	 (d) (e) (f)  
108	 Figure 3: (a) Document  d , (b) Document  e , (c) TwigXSKETCH , (d) Edge-histograms, (e) Twig query ¤ , (f) Count-Stable Synopses.  
109	 Again, the key observation here is that, while twig-XS KETCH es and edge histograms provide an accurate summarization mechanism for twig selectivity estimation, they cannot model the details of the tree structure for the twig query's binding tuples; thus, we expect them to be inadequate as a general-purpose approximate query answering tool (the results of our empirical study in Section 6 clearly verify our expectations.) Furthermore, as this paper demonstrates, our new synopses are also conceptually simpler, significantly easier to build, and provide more accurate results than twig-XS KETCH es even for the simpler selectivity estimation problem.  
110	 3.2 Count-Stability and the T REE S KETCH Synopsis  
111	 Our proposed T REE S KETCH synopsis data structure is a specific instantiation of the generic graph-synopsis model outlined earlier in this section. T REE S KETCH es rely on a novel, intuitive concept of localized stability, termed count stability, defined formally as follows.  
112	 D EFINITION 3.1. Let ¥ ¤¦¤ denote a (label-respecting) equivalence relation over the nodes of ¡£¢¥¤§¦¨£ , and let ¢  ¦ j  denote a pair of equivalence classes (i.e., element-node partitions) induced by  . We say that the pair ¢  ¦ j  is m -stable (where m¨§© ) if and only if each element  ª has exactly m child elements in  
113	 j . The relation  and the graph synopsis fhg ¢8¡i resulting from the corresponding element partitioning are said to be count stable if and only if, for every possible pair of element partitions ¢  ¦ j  there exists some m¨§© such that ¢  ¦ j  is m -stable.  
114	 Note that the element partitions  , j in the above definition essentially correspond to the extents of synopsis nodes in fhg ¢8¡k ; furthermore, for m -stability, we treat the special case m d  as the absence of child elements (i.e., no synopsis edge between  and j ). As an example, the count stable summaries for the XML trees of Figure 3(a,b) are shown in Figure 3(f), where the summary edges are annotated with the corresponding m . It is easy to see that our notion of count stability is a refinement of the traditional Fstability relation for trees employed by both XS KETCH es [15, 16] and twig-XS KETCH es [18]; in other words, the equivalence classes for the count-stability relation are generated by further partitioning the equivalence classes for F-stability.  
115	 Intuitively, our concept of count stability tries to define a class of equivalence relations where element nodes are grouped together only if the data sub-tree structures underneath them are identical. As the following lemma shows, the count-stable graph-synopsis for a data tree ¡ is uniquely defined and, furthermore, it accurately captures the structure of ¡ .  
116	 L EMMA 3.1. Given a data tree ¡£¢¥¤§¦©¨ , there exists a unique minimal (in terms of the number of equivalence classes) countstable equivalence relation « ¤¬¤ . Furthermore, there exists a function ¯®W°²±Y³µ´ from stable relations to XML trees, such that  
117	 h®¶°²±Y³²´ ¢   is isomorphic to the original document tree ¡ .  
118	 Thus, the tree structure of the original document ¡ can be retrieved with zero-error from a synopsis · g ¢8¡k if  is stable. The problem, of course, is that the size of a count-stable synopsis can become very large ­ it can easily be in the order of the original document size. Given the stringent time and storage limitations typically associated with interactive approximate query answering, it is clear that perfect count-stable summaries cannot be very useful as a data-approximation tool for real-time XML data exploration. Instead, our proposed T REE S KETCH synopses try to approximately capture the underlying document-tree structure within a predefined space budget. Intuitively, the key idea behind T REE S KETCH es is to locally approximate count-stable relations in the graph-synopsis wherever structural correlations exist in the underlying data, while relaxing the count-stability requirement where such correlations are not dominant and independence/uniformity assumptions are sufficient. Our T REE S KETCH synopsis model is simply defined as follows.  
119	 D EFINITION 3.2. A T REE S KETCH synopsis ¸if for an XML data tree ¡ is a node- and edge-labeled graph-synopsis for ¡ , where: (1) each node  in ¸¹f stores an element count count ¢  §d { extent ¢  '{ ; and, (2) each edge ¢  ¦ j  in ¸if stores an (average) child count count ¢  ¦ j  equal to the average number of children in extent ¢ j  for each element in extent ¢   .  
120	 Thus, instead of storing complex histograms for edge combinations in a B/F-stable neighborhood of a node (like twig-XS KETCH es [18]), our T REE S KETCH es simply maintain a localized average child count for each edge in the synopsis (without requiring any stability properties for that edge). The interpretation of the stored average is simple: all elements in the extent of  have count ¢  ¦ j  child elements in the extent of j . Obviously, this is trivially satisfied in a stable synopsis where each edge ¢  ¦ j  is count stable for  
121	 m d count ¢  ¦ j  .  
122	 There is an interesting and intuitive connection between T REE S KETCH es and the clustering of points in multi-dimensional spaces. More specifically, let  be a synopsis node with outgoing edges  
123	 Cn j d , . . . , Cn jaº . The set of outgoing edges defines a » dimensional space, where an element  ª is mapped to a point  
124	 ¢6v d ¢ ¦¼'¼#¼'¦©v º ¢ © if it has v  ¢  children to node j  , l¾½C¿k½«» . The recorded average edge counts essentially map all points in this space to point ¢ count ¢  ¦ j d ¦f¼'¼'¼'¦ count ¢  ¦ jaº © , which actually represents the centroid of the cluster. We can thus characterize the quality of a T REE S KETCH synopsis by using a metric that quantifies the quality of the induced clustering. The metric that we adopt in our work is the squared error of the clustering, which essentially measures the euclidean distance between points and their corresponding centroid. The squared error for a single cluster  is defined as À#I ¢  ¯d ~HÁÂ t ~ d©Ã  Ã º ¢6v  ¢ RÄ count ¢  ¦ j  © e , while  
125	 the squared error À'I ¢ ¸if  for a synopsis ¸if is simply the sum of squared errors for all the induced clusters. Note, of course, that the squared error for a count-stable synopsis is zero since all edgecount centroids are exact, i.e., the child counts for any element in a given synopsis-node extent are identical (and equal to the corresponding edge counts). We have chosen the squared error metric since it captures a notion of weighted variance, but it is possible to use other metrics such as the Manhattan distance or the pairwise intra-cluster distance. Irrespective of the actual choice, the existence of a workload-independent T REE S KETCH -quality metric is a major difference from earlier summarization techniques which are also based on graph synopses, but quantify the quality of summaries on a per-workload basis (examples include both XS 
126	 KETCH es and twig-XS KETCH es.) As we will see later, this feature will enable fast construction times, since the quality of a summary in the space of possible T REE S KETCH es can be determined very efficiently, without requiring the costly evaluation of a query workload (as in the case of XS KETCH and twig-XS KETCH construction).  
127	 4. SYNOPSIS CONSTRUCTION AND QUERY  
128	 PROCESSING  
129	 In this section, we start by describing novel, efficient bottom-up construction procedures for count-stable summaries and our T REE S KETCH synopses (for a given space budget). We then introduce algorithms for approximating the results as well as the selectivities of XML twig queries over T REE S KETCH synopses.  
130	 4.1 Building the Count-Stable Summary  
131	 Our algorithm for constructing the complete count-stable summary of an input XML tree ¡ (termed B UILD S TABLE ) is depicted in Figure 4. In a nutshell, B UILD S TABLE processes element nodes in a post-order traversal of ¡ and constructs the count-stable synopsis graph f in a bottom-up fashion. A hash table sÅ zF¦hÆ  is used to maintain the collection of equivalence classes (i.e., synopsis nodes) built thus far, hashed on the (common) class label z and the identifying tuple of child counts Æ to other equivalence classes. The key observation here is that, by virtue of the post-order traversal, when visiting an element node  , its children in ¡ have already been assigned to equivalence classes in f ; thus, the equivalence clas for  can be determined (with the help of sÅ  ) based on its label and the classes and counts of its children (Step 3). If a class for  does not already exist, a new class/synopsis node is created and the appropriate edges and counts are added to f (Steps 4­8). Finally,  is added to the extent of the corresponding synopsis node (Step 9).  
132	 Algorithm B UILD S TABLE constructs the count-stable summary of an XML tree in linear Ç ¢{ ¡{  time; note that, for building the "child-count signature" in Step 3, only the element's child classes are necessary, and these can be easily accessed using a stack during the post-order traversal.  
133	 4.2 Building T REE S KETCH Synopses  
134	 As already mentioned in Section 3.2, the size of an exact countstable synopsis typically renders it useless in the context of a realProcedure B UILD S TABLE (  ) Input: XML Document  . Output: Count-Stable synopsis È of  . begin 1.  := É ; È := É 2. for each element ÊÌË  in post-order do 3.  := Í AÎ     hÏ'Î  is a node in È and Ð children  Ê µÑ extent Î   ÐÒ  hÓ  Ô 4. if  ¬Õ label  Ê  ©×Ö Ò É  then 5. Add node Î to È with label Î¶ Ò label  Ê  6. ¬Õ label  Ê  s×Ö := Î 7. for AÎ      Ë  do add edge Î sØ  
135	 ÙÚ Î  to È 8. endif 9. Î := ¬Õ label  Ê  ©×Ö ; extent AÎ¶ := extent Î¶²Û ÍfÊ Ô 10. endfor end  
136	 Figure 4: Algorithm B UILD S TABLE .  
137	 life approximate query processing system. Such systems usually place tight limits on the space budget for building synopses of the underlying data collection. Thus, there is a clear need for effectively constructing compressed T REE S KETCH synopses under a given space budget, while maintaining a high-quality XML-data approximation in order to enable meaningful approximate answers.  
138	 Given the aforementioned natural analogy between T REE S KETCH es and data clustering (Section 3.2), our goal of constructing an effective synopsis can be translated to computing an effective clustering of the XML elements. Here, of course, an element cluster is "tight" if it encompasses data elements with similar sub-trees, and "tightness" can be quantified using the squared error for the clustering (as discussed in Section 3.2). Thus, our goal is to build a T REE S KETCH synopsis ¸if that fits within a given space budget, such that the overall square error À'I ¢ ¸if  for the synopsis is minimized. The analogy with clustering also highlights the difficulty of T REE S KETCH construction, since such clustering problems are known to be ÜÞÝ -hard even in the simple case of points in a low-dimensional space [19, 23]. Furthermore, T REE S KETCH construction typically deals with a high-dimensional space which is defined by the clustering itself (i.e., the space itself changes as elements are assigned to clusters)! Thus, the problem is significantly more complex and existing clustering algorithms are not directly applicable.  
139	 Our approach is based on a generic bottom-up clustering paradigm: starting from the count-stable synopsis, our algorithm (termed TSB UILD ) incrementally reduces the synopsis size by merging nodes with similar sub-structures, until the budget constraint is met. This resembles agglomerative hierarchical clustering algorithms, which start with one cluster per input data point and successively reduce the number of clusters by merging neighboring groups (according to some appropriate distance metric). Another possible option is a top-down approach that starts from a coarse summary and gradually expands it by splitting nodes (this is actually the approach taken in the XS KETCH work [15, 16, 18]). In the clustering literature, however, bottom-up algorithms have been shown to perform better than their top-down counterparts; in addition, we have experimentally verified that bottom-up T REE S KETCH construction yields much better results, without significantly increasing construction time.  
140	 The TSB UILD Algorithm. We now describe our T REE S KETCH construction algorithm in more detail. In a nutshell, TSB UILD maintains a pool of candidate operations to be applied to the working T REE S KETCH synopsis ¸if (initialized to the count-stable graph), where each operation ß in the pool merges two nodes of ¸¹f (deProcedure TSB UILD ( à , ¢ , áTâ , ãäâ ) Input: XML document à ; space budget ¢ ; upper/lower bounds for heap size  áTâ  ãäâ  Output: T REE S KETCH synopsis åÌÈ of  of size æ ¢ begin 1. åÌÈ := B UILD S TABLE (  ) // Start with the count-stable summary 2. çéè¥É 3. while (size  åÌÈ  Ó ¢ ) do 4. ç := C REATE P OOL ( å¯È , á â ) 5. while  size  åÌÈ  Ó ¢ and size  ç  Ó ã â  do 6. ê@èëçµì íWîví¶ïñð  8 7. åÌÈ := ê  åÈ  // Apply ê on åÈ 8. Let Î¶ò be the new synopsis node 9. for each êóôËõç do 10. if ( ê ó ì  îfö Êf÷ Ñ ê¬ì  î'öÊ'÷kø Ò É ) then 11. Remove ê ó from ç 12. Add a merge between ê ó ì  î'öÊf÷ Ù ê¾ì  î'öÊ'÷ and Î ò to ç 13. endif 14. Recompute ê ó ì Ê 'hù  ê ó ì ÷hð6úÊ ù for all ê ó Ë affected  ç  ê  15. endwhile 16. endwhile 17. return åÌÈ end  
141	 Figure 5: Algorithm TSB UILD .  
142	 noted by ß ¼ »üûYý  À ). If ß ¢ ¸if  denotes the resulting synopsis after applying the merge ß on ¸if , we define ß ¼ #þYþ ù d À'I ¢ ß ¢ ¸kf ©Ä  
143	 À'I ¢ ¸if  to be the increase in squared error from ¸if to ß ¢ ¸if  , and ß ¼ À#¿¥ÿ  ù d size ¢ ¸if Ä size ¢ ß ¢ ¸if © to be the corresponding decrease in synopsis size. The pool of candidate operations is organized in a min-heap </i>according to the <i>marginal-gain ratio ß ¼ #þYþ ù¡  ß ¼ À'¿¥ÿ  ù , i.e., the operation at the top of the heap offers the least increase in squared error per unit of space that is saved. At each step of the construction algorithm, the operation at the top of the heap is applied, the pool is updated with new merge operations for the new node, and the þ þ ù ¦ À'¿Fÿ  ù metrics are recomputed for the new pool of candidate merge operations. This process is repeated until the heap is exhausted (i.e., no merge operations are possible) or the size of the ¸¹f synopsis drops below the allotted space budget.  
144	 The pseudo-code for our TSB UILD algorithm is shown in Figure 5. TSB UILD initializes the min-heap ¢ of candidate merge operations through function C REATE P OOL (discussed below), and then applies successive merges according to our marginal-gain criterion (Steps 5-15). In order to limit the memory requirements of the algorithm and increase efficiency, the size of the operations heap is bounded by the supplied parameter £ â . As operations are performed, the size of the heap is gradually reduced and when it drops below a supplied threshold ¤ â , the heap is re-generated and the process repeated.  
145	 A potential performance bottleneck for the construction process is the re-computation of the #þ þ ù and À'¿¥ÿ  ù metrics for the merge operations in the heap. To make this more efficient, our TSB UILD algorithm employs two key techniques. First, re-computation is performed only for a limited subset of the candidate merge operations. The key observation here is that the #þYþ ù and À'¿¥ÿ  ù metrics measure differences in the characteristics of the synopsis (rather than absolute quantities) and, thus, most of them can be preserved across merges. More specifically, if ß is the merge that was performed last and  ò is the newly created node, then TSB UILD only needs to compute the metrics for operations that merge parent or child nodes of  ò (we denote this set of operations as affected ¢¦¥¬ ); for the remaining operations, the #þ þ ù , À'¿Fÿ  ù metrics remain unchanged. Procedure C REATE P OOL ( å×È , áTâ ) Input: Synopsis åÌÈ ; heap-size upper bound áRâ . Output: Double-ended heap ç containing æáRâ merge operations. begin 1. çéè É , §£Ê©¨ Ê§ :=  2. while  §£Ê©¨ Ê§ height  åÈ  and size  ç  ñá â  do 3. §£Ê©¨ Ê§ := §£Ê©¨ Ê§¡  4. for all Î  ¨£ËåÈ Ï label AÎ¶ Ò label  ¨  do 5. if  ÍföÊví ç Î²  ö ÊFí ç  ¨ vÔ Ò §£Ê©¨ Ê©§  then 6. Let ê be the operation that merges Î , ¨ 7. çµì í Î ÷hç  ê  8. if  size  ç  Ó á â  then çµì í îsíWï &quot;! 8 9. endif 10. endfor 11. endwhile 12. return ç end  
146	 Figure 6: Algorithm C REATE P OOL .  
147	 Our second technique makes the computation of #þYþ ù more efficient by storing "sufficient" statistics in each synopsis node. Briefly, each node stores the sum and the sum of squares for the child counts of its elements along each outgoing edge in the synopsis. It is straightforward to show that these statistics are sufficient in order to compute the squared-error metric for the synopsis À'I ¢ ¸if  without accessing the base data. In addition, in certain cases, these statistics can be combined in order to derive the statistics of new nodes (created through merge operations). The complete details are beyond the scope of this presentation and can be found in the full paper [17]. Note that this idea is similar to the one proposed in the BIRCH clustering algorithm [23], where clusters are represented only by a collection of similar sufficient statistics throughout the computation. In our case, however, the stored statistics do not obviate the need to access a small subset of the base data (although this can be done very efficiently, by accessing only the relevant parts of the count-stable summary). Again, we defer the details to the full version of this paper [17].  
148	 Generation of Candidate Operations. We now discuss the de 
149	 tails of our C REATE P OOL algorithm for initializing a heap of at most £ â merge operations. An obvious approach would be to generate all possible pair-wise merges and keep the top £ â operations according to our ratio metric #þYþ ù   À'¿¥ÿ  ù . Unfortunately, such a solution requires evaluating Ç ¢  e  merge operations, where  is the number of nodes in the count-stable summary and, thus, becomes prohibitively expensive as the size and complexity of the data grows. Given that C REATE P OOL is invoked repeatedly during the T REE S KETCH -construction process, this increased complexity has a significant negative impact on construction times. On the other hand, reducing the number of operations considered increases the efficiency of the candidate-generation stage, but it also runs the risk of "polluting" the heap with less effective merge operations that can affect the quality of the generated T REE S KETCH es.  
150	 To overcome this difficult problem, we adopt a heuristic that limits the number of merge operations considered while ensuring that the heap only contains operations that are likely to be beneficial. The key observation here is that a merge of two nodes  and j leads to a "good" clustering of the elements involved only if  and  
151	 j have similarly structured sub-trees. Thus, our T REE S KETCH construction algorithm is much more likely to apply merge operations on the children of  and j first, before merging  and j themselves. This observation suggests a bottom-up approach for populating the heap with merge operations, starting with nodes close to the leaves of the current synopsis and proceeding upward to the root.  
152	 Figure 6 shows the pseudo-code for our C REATE P OOL algorithm that implements the aforementioned heuristic. C REATE P OOL uses the concept of a node's depth in order to examine merge operations in a bottom-up fashion. More specifically, let  be a document element. The depth of  is defined as  if  is a leaf, and l$# ¥ ±®&amp;%ý ('&amp;) ¢ ¢  10 otherwise, where the maximum is taken over all  
153	    children ¢  . Intuitively, the depth of an element is the longest path that leads to a leaf descendant. The depth of a synopsis node  is defined as ¥ ±® ÁhÂ t %ý ('&amp;) ¢ ¢ 10 . C REATE P OOL evaluates merge operations at increasing depths in the current synopsis  
154	 ¸¹f and only records the best £ â of the operations seen thus far (this can be implemented efficiently through a double-ended heap). Candidate generation terminates when the current depth has been exhausted and the heap holds the maximum allowed number of operations.  
155	 4.3 Approximate Query Processing  
156	 We now turn our attention to the problem of generating approximate answers from a concise T REE S KETCH synopsis. At an abstract level, our query evaluation algorithm, termed E VAL Q UERY , processes the input query P over an input T REE S KETCH ¸¹f and produces an output T REE S KETCH ¸if Q that summarizes the nesting tree é ¢ P  (the full nesting tree can be retrieved by expanding  
157	 ¸¹f Q ). As noted in Section 2, the full nesting tree can be used to reconstruct the binding tuples of P and ultimately its result. The evaluation algorithm uses the structure information of ¸if in order to identify matches of the query's path expressions, while the stored edge counts are used to approximate the cardinalities of the corresponding result sets. Similar to any summarization method, the use of the stored information is coupled with a set of appropriate statistical assumptions that compensate the lack of detailed distribution information at certain parts of the synopsis. As we will see, the validity of these assumptions depends on the quality of element clustering within each synopsis node and is thus directly linked to the heuristics of the TSB UILD algorithm. Intuitively, this direct relationship between the build algorithm and the query processing framework leads to the construction of summaries that compute highly accurate approximate answers.  
158	 Figure 7 shows the pseudo-code for algorithm E VAL Q UERY . The algorithm processes query P over the input synopsis ¸¹f and incrementally builds the result T REE S KETCH ¸if Q . Each node  
159	  Q  ¸if Q corresponds to a set of elements with tag label ¢  Q§ , which come from the extent of a node   ¸if and will appear in the bindings of query variable I  P . We will use the notation  Q ¢  ¦ I  to denote this association and the shorthand  Q ¢ I  when no confusion arises. In addition, w¿¥»üý I will denote the set of nodes in ¸if Q that contain bindings for I .  
160	 Initially, the approximate T REE S KETCH contains a root node  
161	 þ QÌ¢¦24353 X ¢ ¸¹f ¦ I#S  which specifies the binding of the topmost variable I S to the root of the document. The algorithm processes the query nodes in a pre-order traversal and, for each node I , evaluates the path expressions to the children of I , relative to the computed bindings in wf¿»üý I . More specifically, for each child I  and binding  Q¢  ¦ I   wf¿»üý I , the algorithm computes a list of bindings y ¢ I  ¦  Q§¬d76 ¢ j ¦ m 98 for variable I  (lines 4-9), where j  ¸if and m 8  is a descendant count. Essentially, each ¢ j ¦ m   y ¢ I  ¦  Q  specifies that every element in  Q (the current binding for I ) has exactly m descendants in j along path  
162	 U VYXa` ¢ I ¦ I   . The new bindings are recorded with the insertion of a node j Q ¢ j ¦ I   and an edge  Q n j Q . Since an element in  Q can have descendants in the same node j through multiple paths procedure E VAL Q UERY ( å¯È , ¤ ) Input: T REE S KETCH åÌÈ of document  ; twig query ¤ Output: T REE S KETCH åÈ Q that approximates the nesting tree @   ¤  begin 1. Initialize åÈ Q with root  Q A&quot;BCB 9  åÈ   c S  2. for each c Ëõ¤ in a pre-order traversal do 3. for each Î Q Î  c  Ë  ð  ö Õ c Ö6 c  Ë children  c  do 4. Let í ò be the main path of ) $ 9ED  c  c   . 5. F := ÍfÊ  Ð Ê  Ò ÎHG ììì G ¨CI is an embedding of í ò¹Ô 6. for all Ê  Ò ÎHG ììì G ¨CIRË7F do 7.  I := E VAL E MBED  í  Ê   ; k c   Î Q  è  ¨CI F I  8. done 9. for  ¨ ©  in i c   Î Q  do 10. Add node ¨ Q  ¨  c   to åÈ Q if it does not exist 11. Add edge Î Q Ú ¨ Q to åÌÈ Q if it does not exist 12. count Î Q  ¨ Q   Ò  13. done 14. done 15. if ¦P c  Ë  ç ð¦§£ö  Ê  Õ c Ö Ï  ð  ö Õ c  Ö ÒRQ  then 16. return Q // The answer is empty 17. done 18. return åÌÈ Q end  
163	 Figure 7: Algorithm E VAL Q UERY .  
164	 in the synopsis, all counts m that correspond to the same j are aggregated in count ¢  Q ¦ j Qe (line 12). Note that the algorithm inserts exactly one node  Q ¢  ¦ I  for each pair ¢  ¦ I  , thus forming a graph-structured summary ¸¹f Q . This optimization, which guarantees a worst case size of Ç ¢{ ¸¹f {v}h{ P {  for the intermediate result synopsis, stems from the interpretation of the T REE S KETCH summarization model: all elements in  contain identically structured sub-trees and thus need to be represented only once in the synopsis (regardless of their ancestor nodes.) The query node I is included in the association in order to correctly handle the case where elements of the same node appear in the bindings of different query nodes. In order to compute the set of bindings y ¢ I  ¦  Q  for variable I  , the algorithm first identifies the synopsis paths that possibly contain descendants of  Q along UWVYXY` ¢ I ¦ I   , and the number of descendants along each path is computed with algorithm E VAL E M  
165	 BED . The separate invocations of E VAL E MBED essentially apply an independence assumption between the different variables of the query, which translates to an independence assumption on the underlying path distribution. We defer this point to the end of the section, where we discuss the relationship of the processing assumptions to the general T REE S KETCH framework.  
166	 The pseudo-code for algorithm E VAL E MBED is shown in Figure 8. The final descendant count is computed as the number of descendants »TS along the main path of the embedding, scaled by the selectivity factors of the branch embeddings. The count »TS is estimated simply as the product of the corresponding edge counts, using the assumption that every element in source node   has  
167	 count ¢  ©¦  U d  children to target node  U d (this is the basic interpretation of the T REE S KETCH model.) To estimate the selectivity À  of branching predicate  l  , the algorithm calls itself recursively to compute the number of descendants for each element of node   (the source of the branch) along the different embeddings of  l  . If there exists at least one embedding such that the descendant count is § l , then all elements in   satisfy the branching predicate and the selectivity is equal to 1. In the opposite case (all descendant counts are strictly less than 1), each count is treated as the fraction of elements in  that have descendants along the corresponding embedding of the branching predicate. Since an element satisfies the branching predicate if it is the root of at least one Procedure E VAL E MBED ( í , Ê ) Input: XPath í Ò l d Õ V l d Ö G ììì G l º Õ V l º Ö ; synopsis path  
168	 Ê Ò Î S GfÎ d G ìhìì GfÎ º , where Î d G ììì GfÎ º is an embedding of l d G l e G ìhìhì G l º Output: Estimated number of descendants for each element of Î along í . begin 1.  S := W SX  Ã º count Î `Y d  Î   // Descendants along main path 2. for each V l  Ëkí do // Compute the selectivity of branches 3. F  := ÍfÊ  Ð Ê  Ò Î  G ¨ d G ììì G ¨CI is an embedding of V l  Ô 4. for all ¨ I Ï ÍfÊ  Ð Ê  Ò Î  G ììì G ¨ I ËaF  Ô ø ÒRQ do 5.  I := b ÁdcÂ eµØ E VAL E MBED  V l   Ê   6. @  è  I 7. done 8. if P   Ëa@  Ï  gf  then 9. ÷  := 1 10. else  
169	 11. ÷  := h  
170	 b i c#Â5pTØ   Ù b i c# iq Â5pTØs ¡r s I   ut  I   
171	  b i c# iq  i©v  ¡r s I r s ò   wt  I t  ò  Ù t1t1tyx // inclusion-exclusion  
172	 12. endif 13. done 14. return  S t W d©Ã  Ã º ÷  end  
173	 Figure 8: Algorithm E VAL E MBED .  
174	 matching embedding, the overall selectivity is computed using the inclusion-exclusion principle on the recorded fractions (line 11). We note that the application of the exclusion/inclusion principle essentially makes use of an independence assumption on the distribution of document edges, which, as we discuss below, is derived from the interpretation of the T REE S KETCH summarization model and is closely related to the squared error of the synopsis.  
175	 chS ii©p   
176	 c#d r    
177	  q i(¥t ihi ÒÒÕÕ ÕÕ  
178	 c g ce ii   
179	 chy    
180	 c© A  
181	 d S    ÒÒÖÖ ÖÖ  
182	 S e  e )) Y Y Y Y  
183	   
184	 e '' V V V V       ÑÑÔÔ ÔÔ      00 a a a a  
185	   
186	 d     %  
187	  &amp;  
188	  A$f c S   
189	 d S   Q  cd   
190	  }}zz zz S e   © 33 h h h h  
191	  Q  ce   
192	 e 33 h h h h  Q  cfe   
193	    Q  c g   
194	  Q  cy   
195	 d     Q  c  (a) (b) (c)  
196	 Figure 9: (a) Query P , (b) T REE S KETCH ¸if (c) Result T REE S KETCH ¸éf Q .  
197	 E XAMPLE 4.1. Consider the invocation of E VAL Q UERY on the query P and synopsis ¸if shown in Figure 4.3. Initially, the result synopsis contains a root þ Q ¢6þY¦ I S  only and w¿¥»üý I S  d þ Q . On the first iteration of E VAL Q UERY , variable IS is processed and the bindings of child variable I d are computed. In this case, it is easy to verify that each element in þYQ has 10 descendants along path  
198	 //a to node  . As a result, node  QÌ¢  ¦ I d  is inserted in ¸¹f Q along with edge 2 Q n  Q , and count ¢¦2  ¦  Q §d l# .  
199	 Let us consider now the processing of I d , and more specifically, the computation of bindings from I d to I g . Starting from node  
200	  , which appears in the bindings of I d , we can identify exactly one simple embedding of UWV Xa` ¢ I d ¦ I g õd   &quot;d   ¡ &quot;e , namely ëd   Cfg &quot;h . The bindings of I#g , therefore, will be the descendants of  along the given embedding. To compute the number of descendants for each element in  (algorithm E VAL E MBED ), we first observe that » S d count ¢  ¦ f §} count ¢ f ¦ h Ìd  }  ¼  d l . This count needs to be scaled by the selectivity of the branching predicate   $d  , for which there exist two embeddings: i % , with descendant count 0.6, and i &amp; , with descendant count 0.7. Essentially, 60% of elements in </i>D <i>have a branching embedding along i % and 70% have a branching embedding along i &amp; . The overall branch selectivity is computed as À d  ¼ j #ª ¼ k¹Ä  ¼ j¹}  ¼ kõd  ¼ a . Thus, the number of descendants along </i>d[/g]//f <i>for each binding in I d is l }  ¼ a and ¸if Q is updated accordingly. The final result synopsis ¸if Q is shown in Figure 4.3(c) (synopsis nodes are annotated with the corresponding query node).  
201	 As noted previously, the evaluation algorithm applies a set of independence assumptions during the processing of an input query over a concise T REE S KETCH summary. At a closer inspection, all the processing assumptions can be reduced to a basic independence assumption that de-correlates the distribution of document edges along different paths of the document. This assumption is essentially derived from the interpretation of the T REE S KETCH synopsis model: given a synopsis edge Þn j , all elements in  have  
202	 count ¢  ¦ j  children in j , independent of incoming or outgoing paths (Section 3). Obviously, this interpretation is trivially satisfied on a stable synopsis where, by virtue of count-stability, all elements in the extent of a node  have the same edge counts to child nodes. As a result, E VAL Q UERY will compute the exact nesting tree of a query when the accessed edges of the synopsis are count-stable. In the general case of a compressed T REE S KETCH , it is straightforward to observe that the validity of the assumption is directly related to the error of the induced element clustering: if the error is low, i.e., the clusters are tight, then the elements are closer to the centroid (which is defined by the recorded average edge counts), and the assumption becomes more valid. In essence, there is a close relationship between the squared error of the synopsis, which quantifies the tightness of the clusters, and the quality of the generated approximate answers. This observation provides the "missing link" between the construction algorithm and the evaluation framework: although the build process does not use a workload-based approach to ensure high-quality approximate answers, it achieves the same goal by keeping the squared error low and thus making the basic independence assumption more valid.  
203	 4.4 Selectivity Estimation  
204	 In this section we briefly discuss the use of T REE S KETCH es for estimating the selectivity of twig queries. As shown in earlier studies [5, 13], accurate estimation for the number of bindings tuples for twig queries is a key requirement in producing effective query plans for complex declarative queries over XML data.  
205	 Our proposed estimation framework uses the result of the E VAL Q UERY algorithm to efficiently compute an estimate of the query's selectivity. More specifically, the estimation algorithm performs a single post-order traversal of the structural summary ¸éf Q and computes, for each node, the average number of binding tuples per element in its extent. Given the bounded size of ¸if Q , it becomes clear that the estimation process has low memory requirements and can be performed very efficiently. In the interest of space, we do not discuss the estimation algorithm further. The full details can be found in the full version of this paper. 5. AN ERROR METRIC FOR APPROXIMATE  
206	 XML QUERY ANSWERS  
207	 In order to evaluate the effectiveness of the proposed approximate query answering framework, it is necessary to measure the degree of similarity between the approximate nesting tree mlon ¢ P  that is computed over a concise synopsis ¸if , and the true nesting tree  
208	 é ¢ P  of the query. More formally, this translates to computing a distance ý ¿FÀ )  ¢  lon ¢ P ¦   ¢ P © between the two XML trees which essentially quantifies the error of approximation. There are numerous proposals for distance metrics over trees, the most widely used being the tree-edit distance metric [20]. As we will see next, however, the proposed metrics essentially measure the syntactic differences between the two XML trees and thus fail to capture the semantics of approximate answers. We note that our discussion will focus on the tree-edit distance metric, but our observations hold for other graph-theoretic metrics as well.  
209	 The tree-edit distance ý ¿FÀ ) e ¢8¡ d ¦s¡ e  between two XML trees  
210	 ¡ d and ¡ e measures the minimum cost sequence of edit operations that transform ¡ d to ¡ e (or vise versa). The basic edit operations include adding, deleting, or relabeling a tree node, while more complex operations (such as copying whole sub-trees) are usually modelled as a composition of simple operations. Consider, for instance, the example of Figure 10, where ·  and · ù denote sub-trees of sizes { ·  { and { · ù { respectively and numbers along edges denote child cardinalities. We will assume that ¡ is the true nesting tree of the query, and ¡ d ¦s¡ e are two possible approximations. If we limit the edit operations to node insertion and deletion, and assuming that each operation has unit cost, it is straightforward to show that ý ¿FÀ ) e ¢8¡¦s¡ d §dqp }a{ ·  { # p }a{ · ù { (essentially, we have to add 3 ·  sub-trees to the left  element of ¡ d and delete 3 ·  sub-trees from the right  element in order to transform ¡ d to ¡ ). Similarly,  
211	 ý ¿FÀ ) e ¢8¡¦s¡ e ¯dqp}#{ ·  { # pÌ}{ · ù { . According to tree-edit distance, therefore, ¡ d and ¡ e are equally good approximations of the true result. Intuitively, however, we expect ¡ e to be a better approximation since it maintains the correlation between the number of ·  and · ù subtrees under the same parent (few ·  are combined with several · ù and vise versa); answer ¡ d , on the other hand, conveys exactly the opposite trait, that there is an equal number of ·  and  
212	 · ù sub-trees under every  .  
213	   
214	 ÔÔÙÙ Ù &amp;&amp;R R R  
215	  y ÓÓ×× × d    
216	 d  y '' U U U  
217	 r&amp;s r&amp;t r&amp;s r&amp;t   
218	 ÔÔÙÙ Ù &amp;&amp;R R R  
219	  d ÓÓ×× × d    
220	 y  y '' U U U  
221	 r&amp;s r&amp;t r&amp;s r&amp;t   
222	 ÔÔÙÙ Ù &amp;&amp; R R R  
223	   ÓÓ×× × e    
224	 e   '' U U U  
225	 r&amp;s r&amp;t r&amp;s r&amp;t   d  e Figure 10: Query answer ¡ and two approximations ¡ d , ¡ e  
226	 The previous example illustrates that the syntactic difference between two documents, as measured by tree-edit distance or other similar graph-theoretic metrics, is not a suitable similarity metric for approximate answers. Intuitively, an approximate answer is useful if it preserves the statistical traits of the true answer, without necessarily being identical to it, and the distance metric should capture this type of "approximate" similarity. Similar observations have been made in the context of approximate answers for relational queries [3, 10], where the result of a query is a multi-set of values. In short, these studies have argued convincingly that settheoretic metrics, which correspond to syntax-oriented metrics in the XML world, do not yield intuitive results when comparing two value sets (the approximate and the true answer). This has led to the introduction of new distance metrics, such as the MAC [10] and the EMD [3], in order to measure effectively the quality of approximate answers to relational queries.  
227	 A New Distance Metric for XML Trees. We introduce a novel  
228	 distance metric, termed Element Simulation Distance (ESD), that avoids the shortcomings of syntax-oriented metrics by capturing regions of approximate similarity between the compared XML trees. To the best of our knowledge, ours is the first metric that considers both the overall path structure and the distribution of document edges, when computing the distance between two XML trees.  
229	 We now describe the ESD metric in more detail. Let   ¡ d and j  ¡ e be elements of the compared trees with label ¢  d label ¢ j  . We wish to define a function ¨ ·vu ¢  ¦ j  that measures the degree of "simulation", or sub-tree similarity, between the two elements. Let £ S and ¤ S denote the children of  and j respectively that have tag ) . If we treat £wS ¦¤ S as two sets of "values", where the distance between any two elements  ó  £ S ¦ j ó  ¤ S can be measured as ¨ ·vu ¢  ó ¦ j ó  (i.e., a recursive application of the metric to the children of  ¦ j ), then we can measure the distance ý ¿FÀ )1xT¢ £vS ¦h¤ S  between £wS ¦¤ S by using any existing valueset distance metric, like MAC [10] or EMD [3]. The result is an indication of how well  's children of tag ) simulate j 's children of the same tag. The ESD distance between  and j can now be measured as the sum of distances for children of matching tags:  
230	 ¨ ·vu ¢  ¦ j ¯d ~ S ý ¿FÀ )1xT¢ £vS ¦h¤ S  . In effect, two elements are more (or less) similar if their children with matching tags are more (or less) similar themselves, which recursively extends to the whole sub-structure underneath the two elements. In the case where one of £vS ¦h¤ S is empty, we apply a straightforward transformation so that the computation of ý ¿FÀ )1xT¢ £wS ¦h¤ S  is well defined. More concretely, assume without loss of generality that ¤ S dzy . For each element   £wS , we insert a unique (artificial) element &quot;{ in ¤ S with distance ¨ ·vu ¢ ¦© { kd {  { , where {  { is the sub-tree size of  
231	  , and ¨ ·vu ¢ ó ¦${ad}|G¦d~ü ó  £vS ¦© ó d  . This transformation essentially models the insertion of the missing sub-trees under  
232	 j and allows the set-distance metric to be computed on the new non-empty set ¤ S .  
233	 E XAMPLE 5.1. Consider the example of Figure 10 and let  and j be the left  elements of ¡ and ¡ d respectively. Elements  
234	  ¦ j have children of tags v and ý (the roots of sub-trees ·  and · ù ) and thus ¨ ·vu ¢  ¦ j  d ý ¿FÀ )1xT¢ £  ¦¤   #ªý ¿FÀ )1xT¢ £ ù ¦¤ ù  . In order to compute ý ¿FÀ ) x ¢ £  ¦¤   , we observe that the pairwise distances  
235	 ¨ ·vu ¢6v  ¦©v  ¦©v   £  ¦©v   ¤  are equal to 0, since the elements have identical sub-trees. Essentially, the two value sets contain equal values but at different multiplicities. If we use the MAC metric [10], then the computed distance ý ¿FÀ )1xT¢ £  ¦¤   is equal to 8 due to the difference in value frequencies. On the other hand, sets  
236	 £ ù and ¤ ù have the same elements at the same frequencies and thus  
237	 ý ¿FÀ ) x ¢ £ ù ¦¤ ù Ìd  . Overall, ¨ ·vu ¢  ¦ j ed #© d  . Now, assume that j ó is the left  element of ¡ e . It is straightforward to show that, under the same MAC metric, ¨ ·vu ¢  ¦ j ó édj and thus, as expected intuitively, the element of ¡ e simulates better the element of the true result.  
238	 Having defined the ESD metric between any two elements, we define the ESD metric between two trees ¡ d ¦s¡ e as ¨ ·vu ¢8¡ d ¦s¡ e ¯d ¨ ·vu ¢¦24353 X ¢8¡ d ¦(2 353 X ¢8¡ e © . We note that ¨ ·vu ¢8¡ d ¦s¡ e  does not lend itself to a meaningful interpretation, except that a lower value represents increased similarity between ¡ d and ¡ e . This, however, is a common characteristic of metrics that measure the approximate distance between complex objects (e.g., a similar observation holds for the MAC and EMD metrics). We note that it is possible to compute the ESD metric efficiently by first building the stable Data Set Elements File Size (MB) Stable Synopsis Size (KB) IMDB-TX 102,754 3 77 XMark-TX 103,135 5 276 SProt-TX 182,300 4 265 IMDB 236,822 7 149 XMark 2,048,180 100 2,652 SProt 473,031 10 645 DBLP 1,594,443 48 204  
239	 Table 1: Data set characteristics  
240	 summaries of ¡ d and ¡ e on the fly and then evaluating the metric on the stable synopses. The key observation is that a stable summary preserves the path structure and the edge distributions of the original document, while containing fewer nodes. A detailed description of the computation of ESD on stable summaries can be found in the full version of the paper [17].  
241	 6. EXPERIMENTAL STUDY  
242	 In this section, we present an extensive experimental study of T REE S KETCH es on real-life and synthetic data sets. Our results verify the effectiveness, in terms of accuracy and construction time, of the T REE S KETCH synopses as structural summaries for large XML data sets. These benefits become even more apparent in a comparison to previously proposed techniques, where T REE S KETCH es perform consistently better in all aspects. Overall, this empirical study indicates that T REE S KETCH es are a viable and effective solution for the structural summarization of large XML data sets in real-world applications.  
243	 6.1 Testbed and Methodology  
244	 Techniques. We have experimented with two techniques. T REE S KETCH es. We have implemented a fully functional prototype of the T REE S KETCH framework that we describe in this paper. Throughout our experiments, the construction algorithm uses an upper limit of £ â d l' ¦ aY operations and rebuilds the heap when its size is reduced below ¤ â d l#Y operations. Twig-XS KETCH es. Twig-XS KETCH es [18] have been proposed as a summarization technique for estimating the selectivity of complex twig queries. Since the original proposal focused solely on selectivity estimation, we have developed an algorithm for producing approximate answers from a twig-XS KETCH The algorithm traverses the query tree and uses the distribution information of the recorded edge histograms in order to sample the number of descendants for each element in the approximate result tree. For the construction of twig-XS KETCH summaries, we have used the same parameters that were reported in the original study [18].  
245	 Data Sets. We have used four data sets in our experiments: IMDB, a real-life data set from the Internet Movie Database Project; XMark, a synthetic data set that models transactions on a on-line auction site; Swiss Prot, a real-life data set with annotations on proteins; and DBLP, a real-life data set with bibliographical data. The main characteristics of the corresponding XML documents are summarized in Table 1. The TX documents have been used in the twigXS KETCH study [18], and we include them here for the comparison of T REE S KETCH es against twig-XS KETCH es. Looking at the sizes of the stable summaries, we observe that count-stability is very effective in compressing, without loss, the structural information of the original documents. Still, processing a query over so large a summary becomes prohibitively expensive relative to the stringent time requirements of an approximate answering system.  
246	 Query Workloads. For each data set, we evaluate the performance IMDB-TX XMark-TX SProt-TX  
247	 Avg Number of Binding Tuples 3,477 2,436 104,592  
248	 IMDB XMark SProt DBLP  
249	 Avg Number of Binding Tuples 13,039 145,577 365,493 78,784  
250	 Table 2: Workload characteristics  
251	 of the generated summaries against a workload of 1000 positive queries, i.e., queries that have non-empty results sets. Our experiments with negative workloads have shown that T REE S KETCH es consistently produce empty answers as approximations and we therefore omit these workloads from our presentation in the interest of space. The workload is generated by sampling sub-trees from the stable synopsis and converting them to twig queries. Table 2 contains the average number of binding tuples per query in the workloads that we have generated.  
252	 Evaluation Metrics. We quantify the accuracy of approximate an 
253	 swers with the ESD metric which was defined in Section 5. More specifically, we compute the ESD between the approximate and the true nesting tree of each query in the workload and report the average over all queries. Our implementation uses a slightly revised version of MAC (kindly provided by Y. Ioannidis and V. Poosala) as the underlying set-distance metric, and limits comparisons to the binding elements of the same query variables. As always, the complete details can be found in the full paper [17].  
254	 For experiments on selectivity estimation, we measure the accuracy of the synopses with the average absolute relative error over all queries in the workload. More formally, if þ is the true and  the estimated selectivity for a query in the workload, the absolute relative error is defined as { þRÄ {   ßo4 ¢ ¦ À  . The sanity bound À is used to avoid the artificially high percentages of low-count queries. Following common practice [16, 18], we set À to the 10-percentile of true query counts.  
255	 6.2 Results  
256	 Approximate Query Answers. In this experiment, we evaluate  
257	 the effectiveness of our novel T REE S KETCH synopses as a practical solution for generating approximate answers to complex twig queries. We present a comparison against the previously proposed twig-XS KETCH synopses, focusing on two measures: the quality of the generated approximate answers, and the efficiency of the construction process.  
258	 Figure 11 shows the average ESD metric for approximate answers computed with T REE S KETCH es and twig-XS KETCH es on a workload of 1000 twig queries, and for the XMark-TX, IMDBTX, and SwissProt-TX data sets. We note that the increased distance numbers are partly due to the underlying MAC metric, which assigns a heavy penalty if the compared element sets contain the same sub-tree in different multiplicities. The interpretation of the results is therefore based on the relative performance of the two techniques, rather than on the absolute distances. Clearly, our novel T REE S KETCH synopses consistently produce approximate answers of lower error. In all three data sets, the average distance for twigXS KETCH es is at least four times higher than the one for T REE S KETCH es, and the error for a 10KB T REE S KETCH synopsis (lowest budget) is less than the error for a 50KB twig-XS KETCH (highest budget). The effectiveness of T REE S KETCH es can be attributed to our novel clustering-based summarization model, which captures very accurately the intrinsic sub-structure similarity found in XML data. The edge-histogram model used by twig-XS KETCH es,  0  2000  4000  6000  8000  10000  12000  14000  16000  
259	  10  15  20  25  30  35  40  45  50 Avg. ESD  
260	 Synopsis Size (KB) TreeSketches TwigXSketches  
261	  0  2000  4000  6000  8000  10000  12000  14000  16000  18000  
262	  10  15  20  25  30  35  40  45  50 Avg ESD  
263	 Synopsis Size (KB) TreeSketches TwigXSketches  
264	  0  20000  40000  60000  80000  100000  120000  
265	  10  15  20  25  30  35  40  45  50 Avg. ESD  
266	 Synopsis Size (KB) TreeSketches TwigXSketches  
267	 (a) (b) (c)  
268	 Figure 11: Average ESD metric for approximate answers: (a) XMark-TX, (b) IMDB-TX, (c) SwissProt-TX  
269	 on the other hand, can capture correlations within limited neighborhoods of synopsis nodes, while the typically high dimensionality of edge distributions affects negatively the quality of histogram approximation.  
270	 In terms of construction efficiency, we present a qualitative comparison between the two techniques since the twig-XS KETCH code base is not optimized for speed. The twig-XS KETCH construction algorithm starts from a coarse label-split graph, which contains exactly one node for all elements of the same tag, and gradually expands it through incremental refinement operations (basically, node splits, and histogram refinements). To evaluate the benefit of a candidate refinement, the algorithm measures the accuracy of the resulting twig-XS KETCH on a sample workload of twig queries (workload-based evaluation). Our proposed TSB UILD algorithm, on the other hand, compresses the stable summary down to the available space budget, using the squared error as a workloadindependent quality metric.  
271	 IMDB-TX XMark-TX SwissProt-TX  
272	 T REE S KETCH es 0.7 8 10 Twig-XS KETCH es 13 47 55  
273	 Table 3: Construction times (in minutes) for T REE S KETCH es and twigXSKETCH es  
274	 Table 3 compares the construction time for T REE S KETCH es and twig-XS KETCH es for the IMDB-TX, XMark-TX, and SwissProtTX data sets. All times are reported in minutes and were measured on an unloaded Pentium4 3GHz machine, running Linux. For T REE S KETCH synopses, we measure the time to compress the stable summary down to the smallest summary possible, the label split graph; for twig-XS KETCH es, we measure the time needed to expand the original coarse summary to 10KB of storage. This represents a worst case scenario for T REE S KETCH es since the distance from the stable summary to the label-split graph is certainly "longer" than the distance from the label-split-graph to 10KB. Still, a qualitative comparison of the measured times indicates that T REE S KETCH construction is much more efficient. As we described in Section 4.2, the TSB UILD algorithm uses effective heuristics to explore limited, yet promising regions of the search space, while the squared error metric, which is workload-independent, avoids the most expensive step of the twig-XS KETCH algorithm, namely evaluating the accuracy of candidate summaries against sample workloads.  
275	 We have also evaluated the accuracy of T REE S KETCH -generated approximate answers for the large datasets of Table 1. The results remain qualitatively the same as for the smaller data sets and we omit them in the interest of space. A detailed presentation can be found in the full version of this paper [17]. Note that we were not able to evaluate the performance of the twig-XS KETCH approach on the large data sets due to the high construction times.  
276	 Selectivity Estimation. In this experiment, we evaluate the ef 
277	 fectiveness of our proposed synopses in estimating the selectivity of complex twig queries with branching path expressions. Figure 12 shows the average relative estimation error on a workload of 1000 queries for T REE S KETCH es and twig-XS KETCH es, and for the XMark-TX and SwissProt-TX data sets. The results for the IMDB-TX data set are similar to XMark-TX and are omitted in the interest of space. As in the previous experiment, the results show that T REE S KETCH es are effective in summarizing the key properties of the underlying path distribution. We observe that the estimation error remains well below 10% for all three data sets, even for small space budgets of 10KB-20KB that represent a small fraction of the original document sizes. Compared to twig-XS KETCH es, our new T REE S KETCH synopses produce significantly more accurate estimates and exhibit more stable behavior.  
278	 Figure 13 shows the T REE S KETCH estimation error over a workload of 1000 queries and for the XMark, IMDB, SwissProt, and DBLP data sets (the large data sets of Table 1). The results verify the effectiveness of T REE S KETCH es in computing accurate selectivity estimates for complex twig queries and demonstrate their nice scaling properties in terms of data size. In all four data sets, the estimation error drops below 5% for a space budget of 50KB, which in turn represents an extremely small fraction of the original document size. At the same time, the construction times remain affordable given the complexity and size of the involved data sets: 38 minutes for Swiss Prot, 11 minutes for DBLP, 2.5 minutes for IMDB, while the largest XMark data set required 4 hours.  
279	 7. CONCLUSIONS  
280	 Approximate answers constitute an effective solution for offsetting the high execution cost of complex XML queries in an interactive data exploration environment. In this paper, we have initiated the study of approximate query answering for XML data. We have proposed the T REE S KETCH synopses, a novel class of structural summaries that capture very effectively the sub-structure similarity that is commonly found in XML data sets. We have developed a systematic evaluation algorithm for computing approximate answers over a concise T REE S KETCH summary, and we have described an efficient heuristic construction algorithm for building an effective T REE S KETCH for a limited space budget. To quantify the  0  10  20  30  40  50  60  70  80  90  100  
281	  10  15  20  25  30  35  40  45  50 Avg. Rel Error (%)  
282	 Synopsis Size (KB) TreeSketches TwigXSketches  
283	  0  10  20  30  40  50  60  70  80  90  100  
284	  10  15  20  25  30  35  40  45  50 Avg. Rel Error (%)  
285	 Synopsis Size (KB) TreeSketches TwigXSketches  
286	 (a) (b)  0  10  20  30  40  50  
287	  10  15  20  25  30  35  40  45  50 Avg. Rel Error (%)  
288	 Synopsis Size (KB) IMDB XMark SwissProt DBLP  
289	 Figure 12: Average selectivity estimation error: (a) XMark-TX, (b) SwissProt-TX. Figure 13: T REE S KETCH estimation error on large data sets.  
290	 quality of the generated approximate answers, we have proposed a novel distance metric between XML trees that avoids the shortcomings of existing graph-theoretic metrics. Experimental results on real-life and synthetic data sets have verified the effectiveness of our approach and have demonstrated its benefits over previously proposed techniques.  
291	 8. REFERENCES  
292	 [1] Ashraf Aboulnaga, Alaa R. Alameldeen, and Jeffrey F. Naughton. "Estimating the Selectivity of XML Path Expressions for Internet Scale Applications". In Proceedings of the 27th Intl. Conf. on Very Large Data Bases, 2001.  
293	 [2] P. Buneman, M. Grohe, and C. Koch. "Path Queries on Compressed XML". In Proceedings of the 29th Intl. Conf. on Very Large Data Bases, 2003.  
294	 [3] Kaushik Chakrabarti, Minos Garofalakis, Rajeev Rastogi, and Kyuseok Shim. "Approximate Query Processing Using Wavelets". In Proceedings of the 26th Intl. Conf. on Very Large Data Bases, 2000.  
295	 [4] Don Chamberlin, James Clark, Daniela Florescu, Jonathan Robie, J´er^ome Sim´eon, and Mugur Stefanescu. "XQuery 1.0: An XML Query Language". W3C Working Draft, 2001.  
296	 [5] Zhimin Chen, H.V. Jagadish, Laks V.S. Laksmanan, and Stelios Paparizos. "From Tree Patterns to Generalized Tree Patterns: On Efficient Eavluation of XQuery". In Proceedings of the 29th Intl. Conf. on Very Large Data Bases, 2003.  
297	 [6] Zhiyuan Chen, H. V. Jagadish, Flip Korn, Nick Koudas, S. Muthukrishnan, Raymond Ng, and Divesh Srivastava. "Counting Twig Matches in a Tree". In Proceedings of the 17th Intl. Conf. on Data Engineering, 2001.  
298	 [7] James Clark. "XSL Transformations (XSLT), Version 1.0". W3C Recommendation, November 1999.  
299	 [8] James Clark and Steve DeRose. "XML Path Language (XPath), Version 1.0". W3C Recommendation, November 1999.  
300	 [9] Juliana Freire, Jayant R. Haritsa, Maya Ramanath, Prasan Roy, and J  er  ome Sim  eon. "StatiX: Making XML Count". In Proceedings of the 2002 ACM SIGMOD Intl. Conf. on Management of Data, 2002.  
301	 [10] Yannis E. Ioannidis and Viswanath Poosala. "Histogram-Based Approximation of Set-Valued Query Answers". In Proceedings of the 25th Intl. Conf. on Very Large Data Bases, 1999. [11] Raghav Kaushik, Pradeep Shenoy, Phillip Bohannon, and Ehud Gudes. "Exploiting Local Similarity for Efficient Indexing of Paths in Graph Structured Data". In Proceedings of the 18th Intl. Conf. on Data Engineering, 2002.  
302	 [12] L. Lim, M. Wang, S. Padmanabhan, J.S. Vitter, and R. Parr. XPathLearner: An On-Line Self-Tuning Markov Histogram for XML Path Selectivity Estimation. In Proceedings of the 28th Intl. Conf. on Very Large Data Bases, 2002.  
303	 [13] Jason McHugh and Jennifer Widom. "Query Optimization for XML". In Proceedings of the 25th Intl. Conf. on Very Large Data Bases, 1999.  
304	 [14] Tova Milo and Dan Suciu. "Index structures for Path Expressions". In Proceedings of the 7th Intl. Conf. on Database Theory (ICDT'99), 1999.  
305	 [15] N. Polyzotis and M. Garofalakis. "Statistical Synopses for Graph Structured XML Databases". In Proceedings of the 2002 ACM SIGMOD Intl. Conf. on Management of Data, 2002.  
306	 [16] N. Polyzotis and M. Garofalakis. "Structure and Value Synopses for XML Data Graphs". In Proceedings of the 28th Intl. Conf. on Very Large Data Bases, 2002.  
307	 [17] Neoklis Polyzotis, Minos Garofalakis, and Yannis Ioannidis. "Approximate XML Query Answers". University of California Santa Cruz, Technical Report, 2004.  
308	 [18] Neoklis Polyzotis, Minos Garofalakis, and Yannis Ioannidis. "Selectivity Estimation for XML Twigs". In Proceedings of the 20th Intl. Conf. on Data Engineering, 2004.  
309	 [19] C. M. Procopiuc. Geometric Techniques for Clustering: Theory and Practice. PhD thesis, Duke Univ., 2001.  
310	 [20] D. Sasha and K. Zhang. Fast algorithms for the unit cost editing distance between trees. Jnl. of Algorithms, 11, 1990.  
311	 [21] Wei Wang, Haifeng Jiang, Hongjun Lu, and Jeffrey Xu Yu. Containment join size estimation: Models and methods. In Proceedings of the 2003 ACM SIGMOD Intl. Conf. on Management of Data, 2003.  
312	 [22] Yuqing Wu, Jignesh M. Patel, and H.V. Jagadish. "Estimating Answer Sizes for XML Queries". In Proceedings of the 8th Intl. Conf. on Extending Database Technology, 2002.  
